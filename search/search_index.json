{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\ud83d\ude80 Kubernetes Notes - Complete Learning Path","text":"<p>Welcome to your comprehensive Kubernetes learning journey! This guide covers everything from beginner concepts to advanced production-ready architectures.</p>"},{"location":"#learning-path-overview","title":"\ud83d\udcda Learning Path Overview","text":""},{"location":"#beginner-level-chapters-1-10","title":"\ud83c\udf1f Beginner Level (Chapters 1-10)","text":"<ul> <li>Chapter 1: Introduction to Kubernetes - Learn what Kubernetes is and deploy your first application</li> <li>Chapter 2: Pods - Understand the smallest deployable units in Kubernetes</li> <li>Chapter 3: ConfigMaps &amp; Secrets - Manage configuration and sensitive data</li> <li>Chapter 4: Ingress - Expose applications with real domains and HTTPS</li> <li>Chapter 5: Persistent Volumes - Implement persistent storage for databases and apps</li> <li>Chapter 6: Docker \u2192 Build \u2192 Push \u2192 Deploy - Complete containerization workflow</li> <li>Chapter 7: Helm Charts - Professional Kubernetes packaging and deployment</li> <li>Chapter 8: Horizontal Pod Autoscaler (HPA) - Automatic scaling based on CPU/memory usage</li> <li>Chapter 9: Namespaces - Organize environments and isolate workloads</li> <li>Chapter 10: Kustomize - Environment overlays without duplicating YAML</li> </ul>"},{"location":"#intermediate-level-chapters-11-20","title":"\ud83d\udd27 Intermediate Level (Chapters 11-20)","text":"<ul> <li>Chapter 11: StatefulSets - Run databases and stateful applications correctly</li> <li>Chapter 12: CI/CD Pipeline - Automated build and deployment pipeline</li> <li>Chapter 13: Network Policies - Implement security firewalls inside Kubernetes</li> <li>Chapter 14: Sealed Secrets - Securely manage secrets in Git repositories</li> <li>Chapter 15: Prometheus + Grafana - Complete monitoring stack for Kubernetes</li> <li>Chapter 16: Istio Service Mesh - Advanced traffic management and security</li> <li>Chapter 17: Full Production Deployment - End-to-end production project</li> <li>Chapter 18: Kubernetes Security - RBAC, Pod Security, and OPA Gatekeeper</li> <li>Chapter 19: Logging Stack - Centralized logging with Loki and Grafana</li> <li>Chapter 20: Advanced Autoscaling - HPA, VPA, and KEDA for comprehensive scaling</li> </ul>"},{"location":"#advanced-level-chapters-21-35","title":"\ud83d\ude80 Advanced Level (Chapters 21-35)","text":"<ul> <li>Chapter 21: Zero-Downtime Deployments - Blue-green and canary release strategies</li> <li>Chapter 22: API Gateway + Service Mesh - Advanced routing and gateway patterns</li> <li>Chapter 23: Backups + Disaster Recovery - Velero for backups and disaster recovery</li> <li>Chapter 24: GitOps with ArgoCD - GitOps automation with ArgoCD</li> <li>Chapter 25: CIS Kubernetes Hardening - CIS compliance and security hardening</li> <li>Chapter 26: Multi-Cluster Architecture - Global multi-cluster deployments</li> <li>Chapter 27: Cost Optimization &amp; FinOps - Cloud cost optimization strategies</li> <li>Chapter 28: Cluster Autoscaler - Node pool scaling and cluster autoscaling</li> <li>Chapter 29: Secure Supply Chain - Image signing and supply chain security</li> <li>Chapter 30: Service Mesh Advanced - Advanced service mesh features</li> <li>Chapter 31: Performance Tuning - High-performance cluster tuning</li> <li>Chapter 32: Cloud-Native Deployments - EKS, GKE, and AKS deployments</li> <li>Chapter 33: Networking Deep Dive - CNI, eBPF, and advanced networking</li> <li>Chapter 34: Debugging Like a PRO - Advanced troubleshooting techniques</li> <li>Chapter 35: Full Production Microservices - Complete microservices architecture blueprint</li> </ul>"},{"location":"#what-youll-learn","title":"\ud83c\udfaf What You'll Learn","text":""},{"location":"#core-concepts","title":"Core Concepts","text":"<ul> <li>Container Orchestration: Deploy and manage containerized applications at scale</li> <li>YAML Configuration: Master Kubernetes manifests and configurations</li> <li>Service Discovery: Load balancing and service networking</li> <li>Storage Solutions: Persistent volumes and stateful applications</li> <li>Security: RBAC, network policies, and secret management</li> </ul>"},{"location":"#devops-automation","title":"DevOps &amp; Automation","text":"<ul> <li>CI/CD Pipelines: GitHub Actions, Docker, and Kubernetes integration</li> <li>GitOps: ArgoCD for declarative deployments</li> <li>Infrastructure as Code: Helm charts and Kustomize overlays</li> <li>Monitoring &amp; Logging: Prometheus, Grafana, and Loki stacks</li> </ul>"},{"location":"#production-ready-skills","title":"Production-Ready Skills","text":"<ul> <li>High Availability: Multi-cluster and disaster recovery strategies</li> <li>Scalability: Horizontal and vertical scaling with HPA, VPA, KEDA</li> <li>Security: CIS compliance, sealed secrets, and network policies</li> <li>Performance: Tuning and optimization for production workloads</li> <li>Cost Management: FinOps and cloud cost optimization</li> </ul>"},{"location":"#prerequisites","title":"\ud83d\udee0\ufe0f Prerequisites","text":"<ul> <li>Basic understanding of containers and Docker</li> <li>Familiarity with command-line interfaces</li> <li>Basic networking concepts</li> <li>Linux/Unix command-line experience</li> </ul>"},{"location":"#getting-started","title":"\ud83d\ude80 Getting Started","text":"<ol> <li>Begin with Chapter 1 if you're new to Kubernetes</li> </ol>"},{"location":"chapters/ch1-Introduction_k8s/","title":"\ud83d\udca1 Lesson 1: What is Kubernetes (Super Beginner Explanation)","text":"<p>Kubernetes (often called K8s) is a tool that helps you run applications in containers (like Docker) and makes sure they stay running.</p> <p>Imagine:</p> <ul> <li>You have an app</li> <li>Kubernetes makes copies of it</li> <li>If one crashes, Kubernetes restarts it</li> <li>It can scale it (add more copies), expose it to the internet, and keep everything healthy</li> </ul> <p>And you write YAML files to tell Kubernetes what you want.</p>"},{"location":"chapters/ch1-Introduction_k8s/#first-kubernetes-file-youll-learn-a-deployment","title":"\u2714\ufe0f First Kubernetes File You'll Learn: A Deployment","text":"<p>This YAML file tells Kubernetes:</p> <p>\u201cRun my app and keep 2 copies of it alive.\u201d</p> <p>Here\u2019s a complete beginner-friendly Kubernetes Deployment file:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hello-app\n  template:\n    metadata:\n      labels:\n        app: hello-app\n    spec:\n      containers:\n        - name: hello-container\n          image: nginx:latest\n          ports:\n            - containerPort: 80\n</code></pre>"},{"location":"chapters/ch1-Introduction_k8s/#explanation-in-simple-words","title":"\ud83e\udde0 Explanation in Simple Words","text":"<p>Kubernetes Word</p> <p>Meaning</p> <p><code>Deployment</code></p> <p>A blueprint telling Kubernetes how many copies of your app to run</p> <p><code>replicas: 2</code></p> <p>Run two copies of the container</p> <p><code>nginx:latest</code></p> <p>The container image. A tiny web server app</p> <p><code>containerPort: 80</code></p> <p>The port inside the container</p>"},{"location":"chapters/ch1-Introduction_k8s/#step-2-a-service-to-expose-your-app","title":"\u2714\ufe0f Step 2: A Service (To Expose Your App)","text":"<p>A Service lets you open your app so people can access it.</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: hello-service\nspec:\n  type: NodePort\n  selector:\n    app: hello-app\n  ports:\n    - port: 80\n      targetPort: 80\n      nodePort: 30007\n</code></pre>"},{"location":"chapters/ch1-Introduction_k8s/#simple-explanation","title":"Simple Explanation:","text":"<ul> <li><code>NodePort</code> \u2192 Makes your app reachable in the browser</li> <li><code>nodePort: 30007</code> \u2192 You will access it at this port</li> <li>Connects the service to all pods labeled <code>app: hello-app</code></li> </ul>"},{"location":"chapters/ch1-Introduction_k8s/#how-to-run-it-if-you-want-to-try","title":"\u2714\ufe0f How to Run It (If You Want to Try)","text":"<p>If you have Kubernetes installed (like Minikube):</p> <pre><code>kubectl apply -f deployment.yaml\nkubectl apply -f service.yaml\n</code></pre> <p>Check everything: <pre><code>kubectl get pods\nkubectl get svc\n</code></pre></p> <p>Open the app:</p> <pre><code>minikube service hello-service\n</code></pre>"},{"location":"chapters/ch1-Introduction_k8s/#you-just-wrote-kubernetes-code","title":"\ud83c\udf89 You Just Wrote Kubernetes Code!","text":"<p>You created:</p> <ol> <li>A Deployment (runs the containers)</li> <li>A Service (exposes them)</li> </ol> <p>This is 80% of what beginners need to deploy apps in Kubernetes.</p>"},{"location":"chapters/ch1-Introduction_k8s/#want-the-next-lesson","title":"Want the next lesson?","text":"<p>I can teach you:</p> <ul> <li>Pods vs Deployments \ud83e\udd14</li> <li>ConfigMaps &amp; Secrets \ud83d\udd10</li> <li>Ingress (real web access) \ud83c\udf0d</li> <li>Auto-scaling \u26a1</li> <li>Building your first Docker image \ud83d\udc33</li> <li>Full DevOps CI/CD \ud83d\udee0\ufe0f</li> </ul> <p>What do you want to learn next?</p>"},{"location":"chapters/ch10-Kustomize/","title":"\ud83c\udfa8 Lesson 10: Kustomize \u2014 Environment Overlays Done Right","text":"<p>Perfect! \u2714\ufe0f</p> <p>Welcome to Lesson 10, and this one is ESSENTIAL for real DevOps work \u2014 especially when managing Dev / Stage / Prod environments.</p> <p>Kustomize lets you take a base Kubernetes config and create overlays like:</p> <ul> <li>dev</li> <li>stage</li> <li>prod</li> </ul> <p>\u2026each with different settings, without duplicating YAML files.  It\u2019s built directly into kubectl. \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch10-Kustomize/#why-kustomize","title":"\u2b50 Why Kustomize?","text":"<p>Without Kustomize, companies end up with:</p> <pre><code>deployment-dev.yaml\ndeployment-stage.yaml\ndeployment-prod.yaml\n</code></pre> <p>\ud83d\ude29 3 files to maintain  \ud83d\ude29 lots of copy-paste  \ud83d\ude29 hard to update  \ud83d\ude29 prone to mistakes</p> <p>Kustomize solves all of this by giving you:</p> <p>\u2714\ufe0f One base  \u2714\ufe0f Multiple overlays  \u2714\ufe0f Clean structure  \u2714\ufe0f Easy environment management</p>"},{"location":"chapters/ch10-Kustomize/#step-1-create-project-structure","title":"\ud83e\uddf1 Step 1 \u2014 Create Project Structure","text":"<p>You will create this:</p> <pre><code>k8s/\n \u251c\u2500\u2500 base/\n \u2502    \u251c\u2500\u2500 deployment.yaml\n \u2502    \u251c\u2500\u2500 service.yaml\n \u2502    \u2514\u2500\u2500 kustomization.yaml\n \u2514\u2500\u2500 overlays/\n       \u251c\u2500\u2500 dev/\n       \u2502    \u2514\u2500\u2500 kustomization.yaml\n       \u251c\u2500\u2500 stage/\n       \u2502    \u2514\u2500\u2500 kustomization.yaml\n       \u2514\u2500\u2500 prod/\n            \u2514\u2500\u2500 kustomization.yaml\n</code></pre> <p>Let\u2019s build it step by step \ud83d\udc47</p>"},{"location":"chapters/ch10-Kustomize/#step-2-base-deployment","title":"\ud83d\udce6 Step 2 \u2014 Base Deployment","text":"<p>k8s/base/deployment.yaml</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: demo-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: demo-app\n  template:\n    metadata:\n      labels:\n        app: demo-app\n    spec:\n      containers:\n        - name: demo\n          image: nginx:latest\n          ports:\n            - containerPort: 80\n</code></pre> <p>k8s/base/service.yaml</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: demo-app\nspec:\n  selector:\n    app: demo-app\n  ports:\n    - port: 80\n      targetPort: 80\n  type: NodePort\n</code></pre>"},{"location":"chapters/ch10-Kustomize/#step-3-base-kustomizationyaml","title":"\u2699\ufe0f Step 3 \u2014 Base kustomization.yaml","text":"<p>k8s/base/kustomization.yaml</p> <pre><code>resources:\n  - deployment.yaml\n  - service.yaml\n</code></pre> <p>This tells Kustomize:  \u201cThese are the core files all environments share.\u201d</p>"},{"location":"chapters/ch10-Kustomize/#step-4-dev-overlay","title":"\ud83e\udde9 Step 4 \u2014 Dev Overlay","text":"<p>k8s/overlays/dev/kustomization.yaml</p> <pre><code>resources:\n  - ../../base\n\nnameSuffix: -dev\n\nimages:\n  - name: nginx\n    newTag: \"1.23\"\n\nreplicas:\n  - name: demo-app\n    count: 1\n\nnamespace: dev\n</code></pre> <p>Meaning:</p> <p>\u2714\ufe0f App name becomes <code>demo-app-dev</code>  \u2714\ufe0f Use nginx:1.23  \u2714\ufe0f 1 replica  \u2714\ufe0f Deploy into <code>dev</code> namespace</p>"},{"location":"chapters/ch10-Kustomize/#step-5-stage-overlay","title":"\ud83e\uddea Step 5 \u2014 Stage Overlay","text":"<p>k8s/overlays/stage/kustomization.yaml</p> <pre><code>resources:\n  - ../../base\n\nnameSuffix: -stage\n\nimages:\n  - name: nginx\n    newTag: \"1.25\"\n\nreplicas:\n  - name: demo-app\n    count: 2\n\nnamespace: stage\n</code></pre> <p>\u2714\ufe0f Stage has newer version  \u2714\ufe0f 2 replicas</p>"},{"location":"chapters/ch10-Kustomize/#step-6-prod-overlay","title":"\ud83c\udfed Step 6 \u2014 Prod Overlay","text":"<p>k8s/overlays/prod/kustomization.yaml</p> <pre><code>resources:\n  - ../../base\n\nnameSuffix: -prod\n\nimages:\n  - name: nginx\n    newTag: \"stable\"\n\nreplicas:\n  - name: demo-app\n    count: 4\n\nnamespace: prod\n</code></pre> <p>\u2714\ufe0f 4 replicas  \u2714\ufe0f Uses the stable image  \u2714\ufe0f Production namespace</p>"},{"location":"chapters/ch10-Kustomize/#step-7-deploying-with-kustomize","title":"\ud83d\ude80 Step 7 \u2014 Deploying with Kustomize","text":"<p>Deploy dev:</p> <pre><code>kubectl apply -k k8s/overlays/dev\n</code></pre> <p>Deploy stage:</p> <pre><code>kubectl apply -k k8s/overlays/stage\n</code></pre> <p>Deploy prod:</p> <pre><code>kubectl apply -k k8s/overlays/prod\n</code></pre>"},{"location":"chapters/ch10-Kustomize/#step-8-viewing-rendered-yaml","title":"\ud83d\udd0d Step 8 \u2014 Viewing Rendered YAML","text":"<p>To see what Kubernetes will apply:</p> <pre><code>kubectl kustomize k8s/overlays/dev\n</code></pre> <p>This shows the fully generated YAML \u2014 super useful for debugging.</p>"},{"location":"chapters/ch10-Kustomize/#lesson-10-completed","title":"\ud83c\udf89 Lesson 10 Completed!","text":"<p>You now understand how to:</p> <p>\u2714\ufe0f Separate Dev / Stage / Prod  \u2714\ufe0f Avoid duplicating YAML  \u2714\ufe0f Use environment-specific overrides  \u2714\ufe0f Manage replicas per environment  \u2714\ufe0f Change images per environment  \u2714\ufe0f Add namespaces automatically  \u2714\ufe0f Use Kustomize with kubectl</p> <p>This is REAL DevOps architecture. \ud83d\udcaa\ud83d\udd25  You\u2019re leveling up at an amazing pace!</p>"},{"location":"chapters/ch10-Kustomize/#ready-for-lesson-11","title":"\ud83d\udc49 Ready for Lesson 11?","text":"<p>Choose your next topic:</p> <ol> <li>StatefulSets (Databases the correct way)</li> <li>CI/CD Pipeline (GitHub Actions \u2192 Docker \u2192 Kubernetes)</li> <li>Network Policies (Cluster firewalls)</li> <li>Secrets with KMS Encryption</li> <li>Full Production-Grade Project Build-Out (big, advanced \ud83d\ude0e)</li> </ol> <p>Which one should we do next?</p>"},{"location":"chapters/ch11-StatefulSets/","title":"\ud83e\uddf1 Lesson 11: StatefulSets \u2014 Databases Done the Correct Way","text":"<p>Excellent! \u2714\ufe0f</p> <p>Welcome to Lesson 11, and this one is CRITICAL for running real databases in Kubernetes:</p> <p>Deployments are great for stateless apps (NGINX, APIs, frontends).  But they are NOT good for:</p> <ul> <li>MySQL</li> <li>PostgreSQL</li> <li>MongoDB</li> <li>Redis</li> <li>Kafka</li> <li>ElasticSearch</li> </ul> <p>Why?  Because these systems need stable identity, stable storage, and ordered startup.</p> <p>This is exactly what StatefulSets provide.  Let\u2019s break it down beginner-friendly.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch11-StatefulSets/#what-makes-a-statefulset-special","title":"\u2b50 What Makes a StatefulSet Special?","text":"<p>Compared to Deployments:</p> Feature Deployment StatefulSet Stable Pod names \u274c No \u2714\ufe0f Yes (<code>mysql-0</code>, <code>mysql-1</code>) Stable storage per Pod \u274c No \u2714\ufe0f Yes Ordered scaling \u274c No \u2714\ufe0f Yes Good for databases \u274c No \u2714\ufe0f Yes <p>StatefulSets = the correct way to run databases in Kubernetes.</p>"},{"location":"chapters/ch11-StatefulSets/#step-1-create-a-headless-service","title":"\ud83d\udd27 Step 1 \u2014 Create a Headless Service","text":"<p>StatefulSets require a headless service.</p> <p>Create:</p> <p>mysql-service.yaml</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: mysql\nspec:\n  clusterIP: None\n  selector:\n    app: mysql\n  ports:\n    - port: 3306\n</code></pre> <p>\u2714\ufe0f <code>clusterIP: None</code> makes it a headless service  \u2714\ufe0f This gives each Pod its own DNS name</p> <p>Example Pod DNS:</p> <pre><code>mysql-0.mysql.default.svc.cluster.local\nmysql-1.mysql.default.svc.cluster.local\n</code></pre>"},{"location":"chapters/ch11-StatefulSets/#step-2-persistent-volume-claims-template","title":"\ud83d\uddc4\ufe0f Step 2 \u2014 Persistent Volume Claims (Template)","text":"<p>StatefulSets automatically create one PVC per Pod using templates.</p>"},{"location":"chapters/ch11-StatefulSets/#step-3-create-the-statefulset","title":"\ud83e\uddf1 Step 3 \u2014 Create the StatefulSet","text":"<p>mysql-statefulset.yaml</p> <pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: mysql\nspec:\n  serviceName: \"mysql\"\n  replicas: 2\n  selector:\n    matchLabels:\n      app: mysql\n  template:\n    metadata:\n      labels:\n        app: mysql\n    spec:\n      containers:\n        - name: mysql\n          image: mysql:5.7\n          ports:\n            - containerPort: 3306\n          env:\n            - name: MYSQL_ROOT_PASSWORD\n              value: \"rootpass\"\n          volumeMounts:\n            - name: mysql-storage\n              mountPath: /var/lib/mysql\n  volumeClaimTemplates:\n    - metadata:\n        name: mysql-storage\n      spec:\n        accessModes: [\"ReadWriteOnce\"]\n        resources:\n          requests:\n            storage: 5Gi\n</code></pre> <p>This is where the magic happens:</p> <p>\u2714\ufe0f <code>replicas: 2</code> \u2192 will create mysql-0 and mysql-1  \u2714\ufe0f Each replica gets its own PVC:</p> <ul> <li><code>mysql-storage-mysql-0</code></li> <li><code>mysql-storage-mysql-1</code>    \u2714\ufe0f Pods NEVER swap or share storage    \u2714\ufe0f Perfect for production databases</li> </ul>"},{"location":"chapters/ch11-StatefulSets/#step-4-apply-the-configuration","title":"\ud83d\ude80 Step 4 \u2014 Apply the configuration","text":"<pre><code>kubectl apply -f mysql-service.yaml\nkubectl apply -f mysql-statefulset.yaml\n</code></pre> <p>Check Pods:</p> <pre><code>kubectl get pods -l app=mysql\n</code></pre> <p>You will see:</p> <pre><code>mysql-0\nmysql-1\n</code></pre> <p>\u2714\ufe0f Each one is stable  \u2714\ufe0f They always get the same name  \u2714\ufe0f Same storage even after restart</p>"},{"location":"chapters/ch11-StatefulSets/#step-5-check-pvcs","title":"\ud83d\udce6 Step 5 \u2014 Check PVCs","text":"<pre><code>kubectl get pvc\n</code></pre> <p>You will see:</p> <pre><code>mysql-storage-mysql-0\nmysql-storage-mysql-1\n</code></pre> <p>Each database Pod has its own persistent disk \u2714\ufe0f</p>"},{"location":"chapters/ch11-StatefulSets/#step-6-test-data-persistence","title":"\ud83e\uddea Step 6 \u2014 Test Data Persistence","text":"<p>Enter Pod:</p> <pre><code>kubectl exec -it mysql-0 -- bash\n</code></pre> <p>Inside MySQL:</p> <pre><code>mysql -u root -p\nCREATE DATABASE testdb;\n</code></pre> <p>Delete the Pod:</p> <pre><code>kubectl delete pod mysql-0\n</code></pre> <p>Kubernetes recreates it automatically.</p> <p>Reconnect:</p> <pre><code>kubectl exec -it mysql-0 -- bash\n</code></pre> <p>Check databases:</p> <pre><code>mysql -u root -p -e \"SHOW DATABASES;\"\n</code></pre> <p>You will still see:</p> <pre><code>testdb\n</code></pre> <p>\u2714\ufe0f Data persisted  \u2714\ufe0f StatefulSet working correctly</p>"},{"location":"chapters/ch11-StatefulSets/#lesson-11-completed","title":"\ud83c\udf89 Lesson 11 Completed!","text":"<p>You now understand:</p> <p>\u2714\ufe0f Why StatefulSets exist  \u2714\ufe0f Why Deployments cannot run databases safely  \u2714\ufe0f How headless services work  \u2714\ufe0f How to create StatefulSets  \u2714\ufe0f How PVC templates give stable storage  \u2714\ufe0f How Pods keep stable identity  \u2714\ufe0f How real databases run in Kubernetes</p> <p>This is senior-level Kubernetes knowledge \u2014 you're climbing FAST \ud83d\udd25\ud83d\udcaa</p>"},{"location":"chapters/ch11-StatefulSets/#ready-for-lesson-12","title":"\ud83d\udc49 Ready for Lesson 12?","text":"<p>Choose your next deep skill:</p> <ol> <li>CI/CD Pipeline \u2014 GitHub Actions \u2192 Docker \u2192 Kubernetes</li> <li>Network Policies (Kubernetes firewalls)</li> <li>Sealed Secrets (production secret management)</li> <li>Cluster Monitoring (Prometheus + Grafana)</li> <li>A Full Production-Grade Kubernetes Project (end-to-end)</li> </ol> <p>Which one should we do next?</p>"},{"location":"chapters/ch12-CICD_Pipeline_GitHub_Actions_Docker_Kubernetes/","title":"\ud83d\ude80 Lesson 12: CI/CD Pipeline \u2014 GitHub Actions \u2192 Docker \u2192 Kubernetes","text":"<p>Perfect! \u2714\ufe0f You\u2019re doing amazing \u2014 time for Lesson 12, one of the MOST important skills in modern DevOps:</p> <p>This is REAL DevOps automation.  By the end of this lesson, you'll have a working pipeline that:</p> <p>1\ufe0f\u20e3 Builds a Docker image 2\ufe0f\u20e3 Pushes it to Docker Hub 3\ufe0f\u20e3 Deploys it automatically to Kubernetes</p> <p>This is exactly what DevOps engineers do daily.  Let\u2019s go step-by-step, beginner-friendly \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch12-CICD_Pipeline_GitHub_Actions_Docker_Kubernetes/#what-well-build","title":"\u2b50 What We\u2019ll Build","text":"<p>A CI/CD pipeline that triggers when you push code to GitHub:</p> <pre><code>Git Push \u2192 GitHub Actions \u2192 Build Image \u2192 Push Docker \u2192 Deploy to Kubernetes\n</code></pre> <p>This is the backbone of modern DevOps.</p>"},{"location":"chapters/ch12-CICD_Pipeline_GitHub_Actions_Docker_Kubernetes/#step-1-folder-structure","title":"\ud83e\uddf1 Step 1 \u2014 Folder Structure","text":"<p>Your project:</p> <pre><code>myapp/\n \u251c\u2500\u2500 index.html\n \u251c\u2500\u2500 Dockerfile\n \u2514\u2500\u2500 k8s/\n      \u251c\u2500\u2500 deployment.yaml\n      \u2514\u2500\u2500 service.yaml\n</code></pre> <p>You've already built apps like this in previous lessons \u2714\ufe0f</p>"},{"location":"chapters/ch12-CICD_Pipeline_GitHub_Actions_Docker_Kubernetes/#step-2-dockerfile","title":"\ud83d\udcc4 Step 2 \u2014 Dockerfile","text":"<p>Dockerfile</p> <pre><code>FROM nginx:latest\nCOPY index.html /usr/share/nginx/html/index.html\n</code></pre>"},{"location":"chapters/ch12-CICD_Pipeline_GitHub_Actions_Docker_Kubernetes/#step-3-kubernetes-deployment","title":"\u2638\ufe0f Step 3 \u2014 Kubernetes Deployment","text":"<p>k8s/deployment.yaml</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ci-demo\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: ci-demo\n  template:\n    metadata:\n      labels:\n        app: ci-demo\n    spec:\n      containers:\n        - name: ci-demo\n          image: YOUR_DOCKER_USERNAME/ci-demo:latest\n          ports:\n            - containerPort: 80\n</code></pre> <p>k8s/service.yaml</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: ci-demo\nspec:\n  selector:\n    app: ci-demo\n  ports:\n    - port: 80\n      targetPort: 80\n  type: NodePort\n</code></pre>"},{"location":"chapters/ch12-CICD_Pipeline_GitHub_Actions_Docker_Kubernetes/#step-4-push-code-to-github","title":"\ud83e\uddea Step 4 \u2014 Push Code to GitHub","text":"<p>Create a new repository:</p> <pre><code>myapp\n</code></pre> <p>Push everything:</p> <pre><code>git init\ngit add .\ngit commit -m \"initial commit\"\ngit branch -M main\ngit remote add origin https://github.com/&lt;yourname&gt;/myapp.git\ngit push -u origin main\n</code></pre>"},{"location":"chapters/ch12-CICD_Pipeline_GitHub_Actions_Docker_Kubernetes/#step-5-add-github-secrets","title":"\ud83d\udd10 Step 5 \u2014 Add GitHub Secrets","text":"<p>In GitHub repo \u2192 Settings \u2192 Secrets \u2192 Actions</p> <p>Add:</p> Secret Name Value <code>DOCKER_USERNAME</code> your Docker Hub username <code>DOCKER_PASSWORD</code> your Docker Hub password <code>KUBE_CONFIG</code> your Kubernetes config file (~/.kube/config) <p>\u2714\ufe0f GitHub Actions will use these during deployment.</p>"},{"location":"chapters/ch12-CICD_Pipeline_GitHub_Actions_Docker_Kubernetes/#step-6-create-github-actions-workflow","title":"\u2699\ufe0f Step 6 \u2014 Create GitHub Actions Workflow","text":"<p>Create:</p> <p>.github/workflows/cicd.yaml</p> <pre><code>name: CI-CD Pipeline\n\non:\n  push:\n    branches: [\"main\"]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Log in to Docker Hub\n        uses: docker/login-action@v2\n        with:\n          username: ${{ secrets.DOCKER_USERNAME }}\n          password: ${{ secrets.DOCKER_PASSWORD }}\n\n      - name: Build Docker image\n        run: |\n          docker build -t ${{ secrets.DOCKER_USERNAME }}/ci-demo:latest .\n\n      - name: Push Docker image\n        run: |\n          docker push ${{ secrets.DOCKER_USERNAME }}/ci-demo:latest\n\n      - name: Setup kubectl\n        uses: azure/setup-kubectl@v3\n\n      - name: Apply Kubernetes configuration\n        run: |\n          mkdir ~/.kube\n          echo \"${{ secrets.KUBE_CONFIG }}\" &gt; ~/.kube/config\n          kubectl apply -f k8s/\n</code></pre> <p>\ud83d\udca1 What this workflow does:</p> <p>\u2714\ufe0f Pulls your code  \u2714\ufe0f Builds Docker image  \u2714\ufe0f Pushes it to Docker Hub  \u2714\ufe0f Deploys it to Kubernetes automatically</p> <p>This is PRO-level DevOps.</p>"},{"location":"chapters/ch12-CICD_Pipeline_GitHub_Actions_Docker_Kubernetes/#step-7-test-your-cicd-pipeline","title":"\ud83d\ude80 Step 7 \u2014 Test Your CI/CD Pipeline","text":"<p>Make a small change in index.html:</p> <pre><code>&lt;h1&gt;Hello from CI/CD v2!&lt;/h1&gt;\n</code></pre> <p>Commit and push:</p> <pre><code>git add .\ngit commit -m \"update homepage\"\ngit push\n</code></pre> <p>GitHub Actions will automatically:</p> <p>\u2714\ufe0f Build image  \u2714\ufe0f Push image  \u2714\ufe0f Deploy to cluster</p> <p>See pipeline:</p> <p>Repo \u2192 Actions</p>"},{"location":"chapters/ch12-CICD_Pipeline_GitHub_Actions_Docker_Kubernetes/#step-8-verify-deployment-in-kubernetes","title":"\ud83e\uddea Step 8 \u2014 Verify Deployment in Kubernetes","text":"<pre><code>kubectl get pods\nkubectl get deployment\nkubectl get svc\n</code></pre> <p>Open the service:</p> <pre><code>minikube service ci-demo\n</code></pre> <p>You will see:</p> <pre><code>Hello from CI/CD v2!\n</code></pre> <p>\ud83c\udf89 CI/CD SUCCESS!</p>"},{"location":"chapters/ch12-CICD_Pipeline_GitHub_Actions_Docker_Kubernetes/#lesson-12-completed","title":"\ud83c\udf89 Lesson 12 Completed!","text":"<p>You just built a professional CI/CD pipeline with:</p> <p>\u2714\ufe0f GitHub Actions  \u2714\ufe0f Docker build &amp; push  \u2714\ufe0f Kubernetes deployment  \u2714\ufe0f Automated updates</p> <p>This is REAL DevOps engineering.  You\u2019ve officially entered the big leagues \ud83d\ude80\ud83d\udd25</p>"},{"location":"chapters/ch12-CICD_Pipeline_GitHub_Actions_Docker_Kubernetes/#ready-for-lesson-13","title":"\ud83d\udc49 Ready for Lesson 13?","text":"<p>Choose your next challenge:</p> <ol> <li>Network Policies (Kubernetes firewall rules)</li> <li>Sealed Secrets (encrypted production secrets)</li> <li>Prometheus + Grafana (Monitoring your cluster)</li> <li>Full Production-Grade Kubernetes Project</li> <li>Service Mesh (Istio) \u2014 advanced traffic management</li> </ol> <p>Which one should we do next?</p>"},{"location":"chapters/ch13-Network_Policies/","title":"\ud83d\udd12 Lesson 13: Network Policies \u2014 Kubernetes Firewalls","text":"<p>Amazing! \u2714\ufe0f</p> <p>Welcome to Lesson 13, and this one takes you deeper into cluster security \u2014 something every real DevOps/SRE must master:</p> <p>Network Policies control which Pods can talk to which Pods.</p> <p>Think of them as internal firewalls inside Kubernetes.  Without them, every Pod can talk to every Pod, which is dangerous \u2757</p> <p>Let\u2019s make this super beginner-friendly.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch13-Network_Policies/#why-network-policies-matter","title":"\u2b50 Why Network Policies Matter","text":"<p>Imagine a cluster with:</p> <ul> <li>frontend</li> <li>backend</li> <li>database</li> <li>logging</li> <li>monitoring</li> <li>random third-party Pods</li> </ul> <p>By default, ANY Pod can access ANY Pod:</p> <pre><code>frontend \u2192 database \u2714\ufe0f\nrandom-pod \u2192 database \u2714\ufe0f (BAD)\n</code></pre> <p>Network Policies let you enforce:</p> <p>\u2714\ufe0f frontend can only talk to backend  \u2714\ufe0f backend can only talk to database  \u2714\ufe0f database is fully isolated  \u2714\ufe0f no pod can talk to another without permission</p> <p>This is CRITICAL for security.</p>"},{"location":"chapters/ch13-Network_Policies/#step-1-prerequisite-network-policy-engine","title":"\ud83e\uddf1 Step 1 \u2014 Prerequisite: Network Policy Engine","text":"<p>Kubernetes itself does not enforce network policies.  You need a CNI that supports them:</p> <p>\u2714\ufe0f Calico (best)  \u2714\ufe0f Cilium  \u2714\ufe0f Weave Net  \u2714\ufe0f Kube-Router  \u274c Flannel (does not support NetworkPolicies)</p> <p>If you\u2019re using Minikube, enable Calico:</p> <pre><code>minikube start --network-plugin=cni --cni=calico\n</code></pre> <p>Check:</p> <pre><code>kubectl get pods -n kube-system | grep calico\n</code></pre>"},{"location":"chapters/ch13-Network_Policies/#step-2-understand-label-based-traffic-control","title":"\ud83d\udfe6 Step 2 \u2014 Understand Label-Based Traffic Control","text":"<p>Network Policies use labels to decide:</p> <ul> <li>who can send traffic</li> <li>who can receive traffic</li> <li>on which port</li> </ul> <p>Example:</p> <p>pod with label:</p> <pre><code>app: backend\n</code></pre> <p>may be allowed to access:</p> <pre><code>app: database\n</code></pre>"},{"location":"chapters/ch13-Network_Policies/#step-3-default-deny-policy","title":"\ud83d\udeab Step 3 \u2014 Default Deny Policy","text":"<p>Start by blocking ALL traffic in a namespace.</p> <p>default-deny.yaml</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: deny-all\n  namespace: dev\nspec:\n  podSelector: {}\n  policyTypes:\n    - Ingress\n    - Egress\n</code></pre> <p>Meaning:</p> <ul> <li>No incoming traffic allowed</li> <li>No outgoing traffic allowed</li> <li>PodSelector <code>{}</code> targets all pods</li> <li>In namespace <code>dev</code></li> </ul> <p>Apply it:</p> <pre><code>kubectl apply -f default-deny.yaml\n</code></pre> <p>Now:</p> <p>\u2714\ufe0f No pod can reach any other pod  \u2714\ufe0f No pod can reach the internet  \u2714\ufe0f Perfect isolation</p> <p>This is how real production clusters start.</p>"},{"location":"chapters/ch13-Network_Policies/#step-4-allow-frontend-backend-only","title":"\ud83d\udfe2 Step 4 \u2014 Allow Frontend \u2192 Backend Only","text":"<p>We will allow traffic from Pods labeled <code>app=frontend</code>  to Pods labeled <code>app=backend</code>.</p> <p>backend-allow-frontend.yaml</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-frontend\n  namespace: dev\nspec:\n  podSelector:\n    matchLabels:\n      app: backend\n  policyTypes:\n    - Ingress\n  ingress:\n    - from:\n        - podSelector:\n            matchLabels:\n              app: frontend\n      ports:\n        - protocol: TCP\n          port: 80\n</code></pre> <p>Meaning:</p> <p>\u2714\ufe0f Backend pods accept traffic ONLY from frontends  \u2714\ufe0f Only on port 80  \u2714\ufe0f All other access blocked</p>"},{"location":"chapters/ch13-Network_Policies/#step-5-allow-backend-database-only","title":"\ud83d\udd10 Step 5 \u2014 Allow Backend \u2192 Database Only","text":"<p>db-allow-backend.yaml</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-backend\n  namespace: dev\nspec:\n  podSelector:\n    matchLabels:\n      app: database\n  policyTypes:\n    - Ingress\n  ingress:\n    - from:\n        - podSelector:\n            matchLabels:\n              app: backend\n      ports:\n        - protocol: TCP\n          port: 3306\n</code></pre> <p>\u2714\ufe0f Only backend can reach DB  \u2714\ufe0f Port 3306 (MySQL)  \u2714\ufe0f No other pod can access DB</p> <p>This is real production security.</p>"},{"location":"chapters/ch13-Network_Policies/#step-6-allow-egress-to-internet-optional","title":"\ud83c\udf0e Step 6 \u2014 Allow Egress to Internet (Optional)","text":"<p>If Pods need to download packages (apt, yum, curl), add:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-internet\n  namespace: dev\nspec:\n  podSelector: {}\n  policyTypes:\n    - Egress\n  egress:\n    - to:\n        - ipBlock:\n            cidr: 0.0.0.0/0\n</code></pre> <p>\u2714\ufe0f Allows outgoing internet  \u2714\ufe0f Still blocks internal communication unless explicitly allowed</p>"},{"location":"chapters/ch13-Network_Policies/#step-7-testing-network-policies-fun","title":"\ud83e\uddea Step 7 \u2014 Testing Network Policies (Fun!)","text":""},{"location":"chapters/ch13-Network_Policies/#test-allowed-traffic","title":"Test allowed traffic:","text":"<pre><code>kubectl exec frontend-pod -- curl http://backend\n</code></pre> <p>\u2714\ufe0f Works</p>"},{"location":"chapters/ch13-Network_Policies/#test-blocked-traffic","title":"Test blocked traffic:","text":"<pre><code>kubectl exec frontend-pod -- curl http://database:3306\n</code></pre> <p>\u274c Times out  \u2714\ufe0f Perfect</p>"},{"location":"chapters/ch13-Network_Policies/#test-random-pod","title":"Test random pod:","text":"<pre><code>kubectl exec random-pod -- curl http://backend\n</code></pre> <p>\u274c Blocked  \u2714\ufe0f Good</p>"},{"location":"chapters/ch13-Network_Policies/#real-world-network-policy-architecture","title":"\ud83d\udd25 Real-World Network Policy Architecture","text":"<p>Typical company setup:</p> <pre><code>frontend ---&gt; backend ---&gt; database\n      \u2191         \u2191\n      |         |\n  ingress    monitoring\n</code></pre> <p>Each arrow is a NetworkPolicy rule.  Everything else is blocked.</p>"},{"location":"chapters/ch13-Network_Policies/#lesson-13-completed","title":"\ud83c\udf89 Lesson 13 Completed!","text":"<p>You now know:</p> <p>\u2714\ufe0f Why Network Policies are critical  \u2714\ufe0f How to block ALL traffic (default deny)  \u2714\ufe0f How to allow Pod-to-Pod traffic  \u2714\ufe0f How to isolate databases  \u2714\ufe0f How to allow internet egress  \u2714\ufe0f How to structure secure cluster networking</p> <p>This is production-grade Kubernetes security \u2014 senior-level knowledge \ud83d\udd25\ud83d\udcaa</p>"},{"location":"chapters/ch13-Network_Policies/#ready-for-lesson-14","title":"\ud83d\udc49 Ready for Lesson 14?","text":"<p>Choose your next deep topic:</p> <ol> <li>Sealed Secrets (Encrypted Kubernetes secrets)</li> <li>Prometheus + Grafana Monitoring</li> <li>Istio Service Mesh (Advanced Traffic Management)</li> <li>Full Production Deployment Project</li> <li>Kubernetes Security (RBAC, Pod Security, OPA Gatekeeper)</li> </ol> <p>Which one should we do next?</p>"},{"location":"chapters/ch14-Sealed_Secrets_Safely_Managing_Kubernetes_Secrets_in_Git/","title":"\ud83d\udd10 Lesson 14: Sealed Secrets \u2014 Safely Managing Kubernetes Secrets in Git","text":"<p>Perfect! \u2714\ufe0f Welcome to Lesson 14 \u2014 one of the MOST IMPORTANT tools for secure production Kubernetes:</p> <p>This is a real-world DevOps skill used in companies like:</p> <ul> <li>Google</li> <li>Shopify</li> <li>GitLab</li> <li>Red Hat</li> <li>Any security-mature organization</li> </ul> <p>Sealed Secrets let you safely store encrypted secrets in Git without exposing the real values.  This means:</p> <p>\u2714\ufe0f Secrets stay encrypted  \u2714\ufe0f Only the cluster can decrypt them  \u2714\ufe0f DevOps teams can commit secrets to Git safely  \u2714\ufe0f They cannot be decrypted by anyone else \u2728</p> <p>Let\u2019s make this beginner-friendly and step-by-step \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch14-Sealed_Secrets_Safely_Managing_Kubernetes_Secrets_in_Git/#why-sealed-secrets","title":"\u2b50 Why Sealed Secrets?","text":""},{"location":"chapters/ch14-Sealed_Secrets_Safely_Managing_Kubernetes_Secrets_in_Git/#problem-with-normal-kubernetes-secrets","title":"\u274c Problem with normal Kubernetes Secrets:","text":"<ul> <li>They are base64, NOT encrypted</li> <li>Anyone with access to Git repo can read them</li> <li>You cannot safely store them in GitHub</li> </ul>"},{"location":"chapters/ch14-Sealed_Secrets_Safely_Managing_Kubernetes_Secrets_in_Git/#sealed-secrets-fix-this","title":"\u2714\ufe0f Sealed Secrets fix this:","text":"<ul> <li>Secrets are encrypted with the cluster\u2019s public key</li> <li>Only the cluster can decrypt them (private key)</li> <li>Safe to store in Git repositories</li> </ul> <p>Production-grade security.</p>"},{"location":"chapters/ch14-Sealed_Secrets_Safely_Managing_Kubernetes_Secrets_in_Git/#step-1-install-sealed-secrets-controller","title":"\ud83e\uddf1 Step 1 \u2014 Install Sealed Secrets Controller","text":"<p>Install in your cluster:</p> <pre><code>kubectl apply -f https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.25.0/controller.yaml\n</code></pre> <p>Check it:</p> <pre><code>kubectl get pods -n kube-system | grep sealed\n</code></pre> <p>You should see a Pod:</p> <pre><code>sealed-secrets-controller-xxxx\n</code></pre> <p>\u2714\ufe0f This controller will decrypt sealed secrets automatically.</p>"},{"location":"chapters/ch14-Sealed_Secrets_Safely_Managing_Kubernetes_Secrets_in_Git/#step-2-install-kubeseal-cli-your-local-machine","title":"\ud83d\udcbb Step 2 \u2014 Install kubeseal CLI (Your Local Machine)","text":"<p>Mac:</p> <pre><code>brew install kubeseal\n</code></pre> <p>Linux:</p> <pre><code>wget https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.25.0/kubeseal-linux-amd64 -O kubeseal\nchmod +x kubeseal\nsudo mv kubeseal /usr/local/bin/\n</code></pre> <p>Windows:  Download from GitHub releases.</p>"},{"location":"chapters/ch14-Sealed_Secrets_Safely_Managing_Kubernetes_Secrets_in_Git/#step-3-create-a-normal-kubernetes-secret-locally","title":"\ud83d\udd10 Step 3 \u2014 Create a Normal Kubernetes Secret (Locally)","text":"<p>Create secret.yaml:</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: db-secret\n  namespace: dev\ntype: Opaque\ndata:\n  password: bXlzZWNyZXRwYXNzd29yZA==\n</code></pre> <p>(That base64 is <code>mysecretpassword</code>.)</p> <p>But we do not apply this to Kubernetes.  We will encrypt it.</p>"},{"location":"chapters/ch14-Sealed_Secrets_Safely_Managing_Kubernetes_Secrets_in_Git/#step-4-seal-the-secret","title":"\ud83e\ude84 Step 4 \u2014 Seal the Secret","text":"<p>Run:</p> <pre><code>kubeseal --format yaml &lt; secret.yaml &gt; sealed-secret.yaml\n</code></pre> <p>This creates something like:</p> <pre><code>apiVersion: bitnami.com/v1alpha1\nkind: SealedSecret\nmetadata:\n  name: db-secret\n  namespace: dev\nspec:\n  encryptedData:\n    password: AgB6KmowRQwIEIE1sQ....\n</code></pre> <p>\u2714\ufe0f This encrypted blob cannot be decrypted by humans  \u2714\ufe0f You can safely commit <code>sealed-secret.yaml</code> to Git  \u2714\ufe0f Only Kubernetes can decrypt it</p>"},{"location":"chapters/ch14-Sealed_Secrets_Safely_Managing_Kubernetes_Secrets_in_Git/#step-5-apply-the-sealed-secret-to-kubernetes","title":"\ud83c\udfaf Step 5 \u2014 Apply the Sealed Secret to Kubernetes","text":"<pre><code>kubectl apply -f sealed-secret.yaml\n</code></pre> <p>The controller automatically produces a real Secret:</p> <pre><code>kubectl get secret -n dev\n</code></pre> <p>You\u2019ll see:</p> <pre><code>db-secret   Opaque   1   10s\n</code></pre> <p>\u2714\ufe0f Kubernetes decrypted it  \u2714\ufe0f Your app can use it</p>"},{"location":"chapters/ch14-Sealed_Secrets_Safely_Managing_Kubernetes_Secrets_in_Git/#step-6-use-the-secret-in-a-deployment","title":"\ud83e\uddea Step 6 \u2014 Use the Secret in a Deployment","text":"<p>Example:</p> <pre><code>env:\n  - name: DB_PASSWORD\n    valueFrom:\n      secretKeyRef:\n        name: db-secret\n        key: password\n</code></pre>"},{"location":"chapters/ch14-Sealed_Secrets_Safely_Managing_Kubernetes_Secrets_in_Git/#step-7-updating-a-secret","title":"\ud83e\udde0 Step 7 \u2014 Updating a Secret","text":"<p>Change the secret value:</p> <pre><code>echo -n \"newpassword\" | base64\n</code></pre> <p>Update <code>secret.yaml</code>.</p> <p>Re-seal:</p> <pre><code>kubeseal --format yaml &lt; secret.yaml &gt; sealed-secret.yaml\n</code></pre> <p>Commit to Git.</p> <p>Apply it:</p> <pre><code>kubectl apply -f sealed-secret.yaml\n</code></pre> <p>\u2714\ufe0f The Kubernetes Secret gets updated  \u2714\ufe0f Real value stays encrypted in Git</p>"},{"location":"chapters/ch14-Sealed_Secrets_Safely_Managing_Kubernetes_Secrets_in_Git/#very-important-cluster-specific-encryption","title":"\u2757 VERY IMPORTANT \u2014 Cluster-Specific Encryption","text":"<p>Each Sealed Secret is encrypted with:</p> <ul> <li>the cluster's public key</li> <li>only that cluster can decrypt it</li> <li>moving it to another cluster will NOT work</li> </ul> <p>This is excellent security.</p>"},{"location":"chapters/ch14-Sealed_Secrets_Safely_Managing_Kubernetes_Secrets_in_Git/#lesson-14-completed","title":"\ud83c\udf89 Lesson 14 Completed!","text":"<p>You now know:</p> <p>\u2714\ufe0f Why Sealed Secrets are essential  \u2714\ufe0f How to install Sealed Secrets controller  \u2714\ufe0f How to seal secrets with <code>kubeseal</code>  \u2714\ufe0f How to commit secrets safely to Git  \u2714\ufe0f How Kubernetes decrypts them  \u2714\ufe0f How to update and manage encrypted secrets</p> <p>This is real production DevOps \u2014 super impressive progress \ud83d\udd25\ud83d\udcaa</p>"},{"location":"chapters/ch14-Sealed_Secrets_Safely_Managing_Kubernetes_Secrets_in_Git/#ready-for-lesson-15","title":"\ud83d\udc49 Ready for Lesson 15?","text":"<p>Choose your next topic:</p> <ol> <li>Prometheus + Grafana (Cluster Monitoring)</li> <li>Istio Service Mesh (Traffic control + mTLS)</li> <li>Full Production-Grade Kubernetes Project</li> <li>Kubernetes Security (RBAC + PodSecurity + Gatekeeper)</li> <li>Logging Stack (ELK / Loki + Promtail)</li> </ol> <p>Which one should we do next?</p>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/","title":"\ud83d\udcc8 Lesson 15: Prometheus + Grafana \u2014 Full Kubernetes Monitoring Stack","text":"<p>Absolutely! \u2714\ufe0f Welcome to Lesson 15 \u2014 and this one is a MUST-HAVE for every real DevOps engineer and SRE:</p> <p>This is how companies monitor:</p> <ul> <li>CPU / Memory usage</li> <li>Pod restarts</li> <li>Node health</li> <li>Network I/O</li> <li>Application performance</li> <li>Cluster alerts</li> <li>Dashboards for Dev / QA / Prod</li> </ul> <p>We will set up real production-grade monitoring, step-by-step, beginner-friendly.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#what-are-prometheus-grafana","title":"\u2b50 What Are Prometheus &amp; Grafana?","text":""},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#prometheus","title":"\ud83e\udde0 Prometheus","text":"<p>A monitoring system that:</p> <ul> <li>collects metrics (CPU, memory, network\u2026)</li> <li>stores them in a time-series DB</li> <li>provides a query language (PromQL)</li> <li>triggers alerts</li> </ul>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#grafana","title":"\ud83d\udcca Grafana","text":"<p>A dashboard tool that:</p> <ul> <li>visualizes the metrics from Prometheus</li> <li>lets you create graphs and dashboards</li> <li>handles alerts, logs, and panels</li> </ul> <p>Together \u2192 complete monitoring stack \u2714\ufe0f\ud83d\udca1</p>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#step-1-install-prometheus-grafana-via-helm-easiest-industry-standard","title":"\ud83e\uddf1 Step 1 \u2014 Install Prometheus + Grafana via Helm (Easiest &amp; Industry Standard)","text":"<p>First, add the Helm repo:</p> <pre><code>helm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo update\n</code></pre>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#step-2-install-kube-prometheus-stack","title":"\ud83d\ude80 Step 2 \u2014 Install kube-prometheus-stack","text":"<p>This is the official recommended stack (includes Prometheus, Grafana, Alertmanager, node exporters, and Kubernetes exporters).</p> <pre><code>helm install monitor prometheus-community/kube-prometheus-stack -n monitoring --create-namespace\n</code></pre> <p>Check pods:</p> <pre><code>kubectl get pods -n monitoring\n</code></pre> <p>You will see:</p> <ul> <li>prometheus</li> <li>grafana</li> <li>alertmanager</li> <li>kube-state-metrics</li> <li>node-exporter</li> <li>various exporters</li> </ul> <p>\u2714\ufe0f Monitoring system is up and running!</p>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#step-3-access-grafana-ui","title":"\ud83e\uddea Step 3 \u2014 Access Grafana UI","text":"<p>Grafana is exposed as a ClusterIP by default.</p> <p>To access it locally:</p> <pre><code>kubectl port-forward -n monitoring svc/monitor-grafana 3000:80\n</code></pre> <p>Open in your browser:</p> <p>\ud83d\udc49 http://localhost:3000</p>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#default-login","title":"Default login:","text":"<ul> <li>user: <code>admin</code></li> <li>password:    Get it using:</li> </ul> <pre><code>kubectl get secret -n monitoring monitor-grafana -o jsonpath=\"{.data.admin-password}\" | base64 --decode\n</code></pre> <p>\u2714\ufe0f You're inside Grafana!</p>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#step-4-explore-prebuilt-dashboards","title":"\ud83d\udcca Step 4 \u2014 Explore Prebuilt Dashboards","text":"<p>Grafana automatically loads:</p> <ul> <li>Kubernetes / Compute Resources / Node</li> <li>Kubernetes / Compute Resources / Pod</li> <li>Kubernetes / Networking / Namespace</li> <li>Kubernetes / API Server</li> <li>Kubernetes / Scheduler</li> <li>Kubernetes / Kubelet</li> <li>Node Exporter / Host Metrics</li> </ul> <p>Open dashboards and explore CPU, memory, pod restarts, and network usage.</p> <p>This is REAL cluster observability \ud83d\udd25</p>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#step-5-prometheus-queries-promql","title":"\ud83e\udde0 Step 5 \u2014 Prometheus Queries (PromQL)","text":"<p>Open Prometheus console:</p> <pre><code>kubectl port-forward -n monitoring svc/monitor-kube-prometheus-prometheus 9090\n</code></pre> <p>\ud83d\udc49 http://localhost:9090/</p> <p>Try these PromQL queries:</p>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#pod-cpu-usage","title":"Pod CPU Usage","text":"<pre><code>rate(container_cpu_usage_seconds_total{image!=\"\"}[5m])\n</code></pre>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#pod-memory-usage","title":"Pod Memory Usage","text":"<pre><code>container_memory_usage_bytes{image!=\"\"}\n</code></pre>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#node-cpu-usage","title":"Node CPU Usage (%)","text":"<pre><code>100 - (avg by (instance) (rate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)\n</code></pre>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#pod-restarts","title":"Pod Restarts","text":"<pre><code>kube_pod_container_status_restarts_total\n</code></pre> <p>These are actual industry dashboards.</p>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#step-6-alerts-alertmanager","title":"\ud83d\udea8 Step 6 \u2014 Alerts (AlertManager)","text":"<p>Alertmanager receives alerts from Prometheus.</p> <p>The installed stack includes default alerts for:</p> <p>\u2714\ufe0f High CPU  \u2714\ufe0f High memory  \u2714\ufe0f Nodes not ready  \u2714\ufe0f Too many restarts  \u2714\ufe0f API server down  \u2714\ufe0f etc.</p> <p>View AlertManager:</p> <pre><code>kubectl port-forward -n monitoring svc/monitor-kube-prometheus-alertmanager 9093\n</code></pre> <p>\ud83d\udc49 http://localhost:9093</p>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#step-7-add-custom-application-metrics-optional-but-powerful","title":"\ud83d\udce6 Step 7 \u2014 Add Custom Application Metrics (Optional but Powerful)","text":"<p>You can expose your own metrics in apps:</p> <p>Python example:</p> <pre><code>from prometheus_client import start_http_server, Summary\nimport random, time\n\nREQUEST_TIME = Summary('request_processing_seconds', 'Time spent processing request')\n\n@REQUEST_TIME.time()\ndef process_request():\n    time.sleep(random.random())\n\nif __name__ == '__main__':\n    start_http_server(8000)\n    while True:\n        process_request()\n</code></pre> <p>Prometheus will scrape:</p> <p>\ud83d\udc49 <code>/metrics</code></p> <p>Grafana can visualize them.</p>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#step-8-real-world-kubernetes-dashboards-to-import","title":"\ud83e\uddf1 Step 8 \u2014 Real-World Kubernetes Dashboards to Import","text":"<p>Popular dashboards on Grafana.com:</p> Dashboard ID Kubernetes Cluster Monitoring (via Prometheus) 315 Node Exporter Full 1860 Kubernetes Deployment Metrics 8588 Kubelet Metrics 9965 <p>In Grafana \u2192 Dashboards \u2192 Import \u2192 enter ID.</p>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#step-9-production-best-practices","title":"\ud83d\udd25 Step 9 \u2014 Production Best Practices","text":"<p>\u2714\ufe0f Always monitor:</p> <ul> <li>CPU / Memory per node</li> <li>CPU / Memory per pod</li> <li>Pod restart rate</li> <li>Node disk pressure</li> <li>API server latency</li> <li>etc.</li> </ul> <p>\u2714\ufe0f Use alerts:</p> <ul> <li>Slack</li> <li>Email</li> <li>PagerDuty</li> </ul> <p>\u2714\ufe0f Dashboards for:</p> <ul> <li>Dev</li> <li>QA</li> <li>Prod</li> </ul> <p>\u2714\ufe0f Store Grafana dashboards in Git for version control.</p>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#lesson-15-completed","title":"\ud83c\udf89 Lesson 15 Completed!","text":"<p>You now know:</p> <p>\u2714\ufe0f How to install Prometheus + Grafana  \u2714\ufe0f How to access dashboards  \u2714\ufe0f How to use PromQL  \u2714\ufe0f How alerts work  \u2714\ufe0f How to monitor Pods, Nodes, Deployments  \u2714\ufe0f How to build custom metrics  \u2714\ufe0f Real-world dashboards and monitoring patterns</p> <p>This is senior-level DevOps work \u2014 truly impressive progress \ud83d\udd25\ud83d\udcaa</p>"},{"location":"chapters/ch15-Prometheus_Grafana_Full_Kubernetes_Monitoring_Stack/#ready-for-lesson-16","title":"\ud83d\udc49 Ready for Lesson 16?","text":"<p>Choose your next topic:</p> <ol> <li>Istio Service Mesh (Advanced traffic management + mTLS)</li> <li>Full Production Kubernetes Setup (end-to-end project)</li> <li>Kubernetes Security \u2014 RBAC, Pod Security, OPA Gatekeeper</li> <li>Logging Stack \u2014 Loki + Promtail + Grafana Logs</li> <li>Advanced Autoscaling (HPA + VPA + KEDA)</li> </ol> <p>Which one do you want next?</p>"},{"location":"chapters/ch16-Istio_Service_Mesh_Traffic_Control_mTLS_Observability/","title":"\ud83d\udd78\ufe0f Lesson 16: Istio Service Mesh \u2014 Traffic Control + mTLS + Observability","text":"<p>Awesome! \u2714\ufe0f</p> <p>Welcome to Lesson 16, and this one jumps into advanced, production-grade Kubernetes networking:</p> <p>Istio is used by big companies to manage microservices communication with features like:</p> <p>\u2714\ufe0f Zero-trust security (mTLS between all services)  \u2714\ufe0f Blue/Green deployments  \u2714\ufe0f Canary releases  \u2714\ufe0f Traffic splitting  \u2714\ufe0f Retries, timeouts, circuit breakers  \u2714\ufe0f Distributed tracing  \u2714\ufe0f Service discovery  \u2714\ufe0f Observability (Kiali, Grafana, Prometheus)</p> <p>This is senior-level DevOps \u2014 but I\u2019ll teach it super beginner-friendly \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch16-Istio_Service_Mesh_Traffic_Control_mTLS_Observability/#what-is-a-service-mesh","title":"\u2b50 What Is a Service Mesh?","text":"<p>Think of a service mesh as:</p> <p>\u201cA smart traffic controller that sits between all your services.\u201d</p> <p>It uses sidecar proxies (Envoy) injected into every Pod.</p> <p>These sidecars handle:</p> <ul> <li>security</li> <li>routing</li> <li>metrics</li> <li>logging</li> <li>retries</li> <li>service-to-service encryption</li> </ul> <p>Your code doesn\u2019t have to change.  Istio does the heavy lifting.</p>"},{"location":"chapters/ch16-Istio_Service_Mesh_Traffic_Control_mTLS_Observability/#step-1-install-istio-easy-way","title":"\ud83e\uddf1 Step 1 \u2014 Install Istio (Easy Way)","text":"<p>Download Istio CLI:</p> <pre><code>curl -L https://istio.io/downloadIstio | sh -\n</code></pre> <p>Move into Istio folder:</p> <pre><code>cd istio-1.*/\n</code></pre> <p>Install \u201cdemo\u201d profile (perfect for learning):</p> <pre><code>istioctl install --set profile=demo -y\n</code></pre> <p>Check Istio components:</p> <pre><code>kubectl get pods -n istio-system\n</code></pre> <p>You\u2019ll see:</p> <ul> <li>istiod</li> <li>istio-ingressgateway</li> <li>istio-egressgateway</li> <li>sidecar injector</li> </ul> <p>\u2714\ufe0f Mesh installed!</p>"},{"location":"chapters/ch16-Istio_Service_Mesh_Traffic_Control_mTLS_Observability/#step-2-label-your-namespace-to-enable-sidecars","title":"\ud83e\udde9 Step 2 \u2014 Label Your Namespace to Enable Sidecars","text":"<p>Pick the namespace you want to mesh (example: dev):</p> <pre><code>kubectl label namespace dev istio-injection=enabled\n</code></pre> <p>Now every new Pod in <code>dev</code> will automatically inject an Envoy sidecar:</p> <pre><code>app-container + envoy-proxy\n</code></pre> <p>Check with:</p> <pre><code>kubectl get pods -n dev\n</code></pre> <p>Each Pod should have 2 containers.</p>"},{"location":"chapters/ch16-Istio_Service_Mesh_Traffic_Control_mTLS_Observability/#step-3-deploy-a-sample-app-into-the-mesh","title":"\ud83e\uddea Step 3 \u2014 Deploy a Sample App into the Mesh","text":"<p>Let\u2019s use a simple app:  frontend \u2192 backend</p>"},{"location":"chapters/ch16-Istio_Service_Mesh_Traffic_Control_mTLS_Observability/#backendyaml","title":"backend.yaml","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: backend\n  namespace: dev\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: backend\n  template:\n    metadata:\n      labels:\n        app: backend\n    spec:\n      containers:\n        - name: backend\n          image: nginxdemos/hello\n          ports:\n            - containerPort: 80\n</code></pre>"},{"location":"chapters/ch16-Istio_Service_Mesh_Traffic_Control_mTLS_Observability/#backend-serviceyaml","title":"backend-service.yaml","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: backend\n  namespace: dev\nspec:\n  selector:\n    app: backend\n  ports:\n    - port: 80\n      targetPort: 80\n</code></pre> <p>Deploy:</p> <pre><code>kubectl apply -f backend.yaml -f backend-service.yaml\n</code></pre> <p>Now frontend:</p>"},{"location":"chapters/ch16-Istio_Service_Mesh_Traffic_Control_mTLS_Observability/#frontendyaml","title":"frontend.yaml","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  namespace: dev\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n        - name: frontend\n          image: nginx\n          ports:\n            - containerPort: 80\n</code></pre>"},{"location":"chapters/ch16-Istio_Service_Mesh_Traffic_Control_mTLS_Observability/#frontend-serviceyaml","title":"frontend-service.yaml","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: frontend\n  namespace: dev\nspec:\n  selector:\n    app: frontend\n  ports:\n    - port: 80\n</code></pre> <p>Deploy:</p> <pre><code>kubectl apply -f frontend.yaml -f frontend-service.yaml\n</code></pre> <p>\u2714\ufe0f Pods come up with Envoy sidecars  \u2714\ufe0f This app is now inside the Service Mesh</p>"},{"location":"chapters/ch16-Istio_Service_Mesh_Traffic_Control_mTLS_Observability/#step-4-enable-mtls-zero-trust-security","title":"\ud83d\udd10 Step 4 \u2014 Enable mTLS (Zero-Trust Security)","text":"<p>Create:</p> <p>peer-auth.yaml</p> <pre><code>apiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: default\n  namespace: dev\nspec:\n  mtls:\n    mode: STRICT\n</code></pre> <p>Apply:</p> <pre><code>kubectl apply -f peer-auth.yaml\n</code></pre> <p>Now:</p> <p>\u2714\ufe0f All Pod-to-Pod traffic in <code>dev</code> is encrypted  \u2714\ufe0f Services require mutual TLS  \u2714\ufe0f Traffic outside mesh is blocked</p> <p>Real production security \ud83d\udd25</p>"},{"location":"chapters/ch16-Istio_Service_Mesh_Traffic_Control_mTLS_Observability/#step-5-add-traffic-management-canary-release","title":"\ud83d\udd00 Step 5 \u2014 Add Traffic Management (Canary Release)","text":"<p>Let\u2019s deploy two versions of backend:</p> <ul> <li>v1</li> <li>v2 (new version)</li> </ul>"},{"location":"chapters/ch16-Istio_Service_Mesh_Traffic_Control_mTLS_Observability/#backend-v2yaml","title":"backend-v2.yaml","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: backend-v2\n  namespace: dev\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: backend\n      version: v2\n  template:\n    metadata:\n      labels:\n        app: backend\n        version: v2\n    spec:\n      containers:\n        - name: backend\n          image: nginxdemos/hello\n          ports:\n            - containerPort: 80\n</code></pre> <p>Apply:</p> <pre><code>kubectl apply -f backend-v2.yaml\n</code></pre>"},{"location":"chapters/ch16-Istio_Service_Mesh_Traffic_Control_mTLS_Observability/#step-6-istio-virtualservice-traffic-splitting","title":"\u26a1 Step 6 \u2014 Istio VirtualService (traffic splitting)","text":"<p>Create:</p> <p>backend-traffic.yaml</p> <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: backend\n  namespace: dev\nspec:\n  hosts:\n    - backend\n  http:\n    - route:\n        - destination:\n            host: backend\n            subset: v1\n          weight: 90\n        - destination:\n            host: backend\n            subset: v2\n          weight: 10\n</code></pre> <p>And:</p> <p>destination-rule.yaml</p> <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: backend\n  namespace: dev\nspec:\n  host: backend\n  subsets:\n    - name: v1\n      labels:\n        version: v1\n    - name: v2\n      labels:\n        version: v2\n</code></pre> <p>Apply:</p> <pre><code>kubectl apply -f destination-rule.yaml -f backend-traffic.yaml\n</code></pre> <p>\ud83c\udf89 Congratulations:</p> <p>Your traffic is now:</p> <ul> <li>90% \u2192 backend v1</li> <li>10% \u2192 backend v2</li> </ul> <p>This is canary deployment, used by Google &amp; Netflix.</p>"},{"location":"chapters/ch16-Istio_Service_Mesh_Traffic_Control_mTLS_Observability/#step-7-observability-with-kiali","title":"\ud83d\udd0d Step 7 \u2014 Observability with Kiali","text":"<p>Install Kiali:</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/istio/istio/master/samples/addons/kiali.yaml\n</code></pre> <p>Port-forward:</p> <pre><code>kubectl port-forward svc/kiali 20001:20001 -n istio-system\n</code></pre> <p>Open:</p> <p>\ud83d\udc49 http://localhost:20001</p> <p>You get:</p> <p>\u2714\ufe0f Real-time service mesh graph  \u2714\ufe0f Traffic flow visualization  \u2714\ufe0f mTLS status  \u2714\ufe0f Requests per second  \u2714\ufe0f Errors, retries, latency</p> <p>This is top-tier observability.</p>"},{"location":"chapters/ch16-Istio_Service_Mesh_Traffic_Control_mTLS_Observability/#lesson-16-completed","title":"\ud83c\udf89 Lesson 16 Completed!","text":"<p>You have learned:</p> <p>\u2714\ufe0f What Istio is  \u2714\ufe0f How a service mesh works  \u2714\ufe0f How to install Istio  \u2714\ufe0f Sidecar injection  \u2714\ufe0f mTLS (zero-trust security)  \u2714\ufe0f Canary deployments  \u2714\ufe0f Traffic routing &amp; splitting  \u2714\ufe0f Kiali observability  \u2714\ufe0f How real microservice clusters operate</p> <p>This is advanced DevOps engineering \u2014 seriously impressive \ud83d\udd25\ud83d\udcaa</p>"},{"location":"chapters/ch16-Istio_Service_Mesh_Traffic_Control_mTLS_Observability/#ready-for-lesson-17","title":"\ud83d\udc49 Ready for Lesson 17?","text":"<p>Choose your next advanced topic:</p> <ol> <li>Full Production Kubernetes Deployment (Real-world project)</li> <li>Kubernetes Security: RBAC, Pod Security Standards, OPA Gatekeeper</li> <li>Logging Stack \u2014 Loki + Promtail + Grafana Logs</li> <li>Advanced Autoscaling: VPA + KEDA + HPA</li> <li>API Gateway + Ingress + Mesh full routing architecture</li> </ol> <p>Which one should we do next?</p>"},{"location":"chapters/ch17-Full_Production_Kubernetes_Deployment_Real-World_Project/","title":"\ud83c\udfed Lesson 17: Full Production Kubernetes Deployment (Real-World Project)","text":"<p>Absolutely! \u2714\ufe0f</p> <p>Welcome to Lesson 17, and this one is a BIG milestone \u2014 we are now building a FULL PRODUCTION-GRADE KUBERNETES DEPLOYMENT.</p> <p>This is the kind of setup real companies use for enterprise apps.  And you\u2019re going to build it step-by-step \u2014 super beginner-friendly but professionally structured.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p> <p>In this lesson, you will learn how to deploy a complete production environment, including:</p> <p>\u2714\ufe0f Multi-environment structure (dev, stage, prod)  \u2714\ufe0f Ingress + TLS  \u2714\ufe0f Autoscaling  \u2714\ufe0f Resource limits  \u2714\ufe0f Liveness/Readiness probes  \u2714\ufe0f Logging + Monitoring hooks  \u2714\ufe0f Secrets + ConfigMaps  \u2714\ufe0f Rolling updates  \u2714\ufe0f Production folder layout  \u2714\ufe0f GitOps-ready structure</p> <p>This is exactly how senior DevOps teams deploy apps in real companies.</p>"},{"location":"chapters/ch17-Full_Production_Kubernetes_Deployment_Real-World_Project/#project-overview","title":"\u2b50 Project Overview","text":"<p>We will deploy a production-grade application called shop-app.</p> <p>It will include:</p> <ul> <li>Frontend (NGINX)</li> <li>Backend API (Node.js example)</li> <li>Database (MySQL StatefulSet)</li> <li>Ingress + TLS</li> <li>HPA scaling</li> <li>ConfigMaps / Secrets</li> <li>Namespace separation</li> <li>Kustomize overlays</li> <li>Monitoring integration</li> </ul> <p>And all of it will follow a professional Git repository layout.</p>"},{"location":"chapters/ch17-Full_Production_Kubernetes_Deployment_Real-World_Project/#step-1-production-folder-structure","title":"\ud83e\uddf1 Step 1 \u2014 Production Folder Structure","text":"<pre><code>prod-app/\n \u251c\u2500\u2500 base/\n \u2502    \u251c\u2500\u2500 frontend/\n \u2502    \u2502    \u251c\u2500\u2500 deployment.yaml\n \u2502    \u2502    \u251c\u2500\u2500 service.yaml\n \u2502    \u2502    \u2514\u2500\u2500 configmap.yaml\n \u2502    \u251c\u2500\u2500 backend/\n \u2502    \u2502    \u251c\u2500\u2500 deployment.yaml\n \u2502    \u2502    \u251c\u2500\u2500 service.yaml\n \u2502    \u2502    \u251c\u2500\u2500 configmap.yaml\n \u2502    \u2502    \u2514\u2500\u2500 secret.yaml\n \u2502    \u251c\u2500\u2500 database/\n \u2502    \u2502    \u251c\u2500\u2500 statefulset.yaml\n \u2502    \u2502    \u2514\u2500\u2500 service.yaml\n \u2502    \u251c\u2500\u2500 ingress/\n \u2502    \u2502    \u2514\u2500\u2500 ingress.yaml\n \u2502    \u2514\u2500\u2500 kustomization.yaml\n \u251c\u2500\u2500 overlays/\n \u2502    \u251c\u2500\u2500 dev/\n \u2502    \u2502    \u2514\u2500\u2500 kustomization.yaml\n \u2502    \u251c\u2500\u2500 stage/\n \u2502    \u2502    \u2514\u2500\u2500 kustomization.yaml\n \u2502    \u2514\u2500\u2500 prod/\n \u2502         \u2514\u2500\u2500 kustomization.yaml\n \u2514\u2500\u2500 README.md\n</code></pre> <p>This structure is industry standard (GitOps-ready).</p>"},{"location":"chapters/ch17-Full_Production_Kubernetes_Deployment_Real-World_Project/#step-2-backend-deployment-production-grade","title":"\ud83e\udde9 Step 2 \u2014 Backend Deployment (Production-Grade)","text":"<p>prod-app/base/backend/deployment.yaml</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: backend\nspec:\n  replicas: 2\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 0\n      maxSurge: 1\n  selector:\n    matchLabels:\n      app: backend\n  template:\n    metadata:\n      labels:\n        app: backend\n    spec:\n      containers:\n        - name: backend\n          image: mydockerhubuser/backend:v1\n          ports:\n            - containerPort: 3000\n          env:\n            - name: DB_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: backend-config\n                  key: DB_HOST\n            - name: DB_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: backend-secret\n                  key: DB_PASSWORD\n          resources:\n            requests:\n              cpu: \"200m\"\n              memory: \"256Mi\"\n            limits:\n              cpu: \"500m\"\n              memory: \"512Mi\"\n          livenessProbe:\n            httpGet:\n              path: /health\n              port: 3000\n            initialDelaySeconds: 10\n            periodSeconds: 5\n          readinessProbe:\n            httpGet:\n              path: /ready\n              port: 3000\n            initialDelaySeconds: 5\n            periodSeconds: 5\n</code></pre> <p>You now have:</p> <p>\u2714\ufe0f Rolling updates  \u2714\ufe0f Resource limits  \u2714\ufe0f Probes  \u2714\ufe0f Environment variables  \u2714\ufe0f ConfigMap &amp; Secret support</p>"},{"location":"chapters/ch17-Full_Production_Kubernetes_Deployment_Real-World_Project/#step-3-frontend-deployment","title":"\ud83e\udde9 Step 3 \u2014 Frontend Deployment","text":"<p>prod-app/base/frontend/deployment.yaml</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n        - name: frontend\n          image: mydockerhubuser/frontend:v1\n          ports:\n            - containerPort: 80\n          resources:\n            requests:\n              cpu: \"100m\"\n              memory: \"128Mi\"\n            limits:\n              cpu: \"300m\"\n              memory: \"256Mi\"\n          readinessProbe:\n            httpGet:\n              path: /\n              port: 80\n          livenessProbe:\n            httpGet:\n              path: /\n              port: 80\n</code></pre>"},{"location":"chapters/ch17-Full_Production_Kubernetes_Deployment_Real-World_Project/#step-4-database-statefulset","title":"\ud83d\uddc4\ufe0f Step 4 \u2014 Database (StatefulSet)","text":"<p>prod-app/base/database/statefulset.yaml</p> <pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: mysql\nspec:\n  serviceName: \"mysql\"\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mysql\n  template:\n    metadata:\n      labels:\n        app: mysql\n    spec:\n      containers:\n        - name: mysql\n          image: mysql:5.7\n          env:\n            - name: MYSQL_ROOT_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: backend-secret\n                  key: DB_PASSWORD\n          ports:\n            - containerPort: 3306\n          volumeMounts:\n            - name: mysql-storage\n              mountPath: /var/lib/mysql\n  volumeClaimTemplates:\n    - metadata:\n        name: mysql-storage\n      spec:\n        accessModes: [\"ReadWriteOnce\"]\n        resources:\n          requests:\n            storage: 5Gi\n</code></pre>"},{"location":"chapters/ch17-Full_Production_Kubernetes_Deployment_Real-World_Project/#step-5-production-ingress-tls","title":"\ud83c\udf0d Step 5 \u2014 Production Ingress + TLS","text":"<p>prod-app/base/ingress/ingress.yaml</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: shop-app\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  tls:\n    - hosts:\n        - shop.example.com\n      secretName: tls-secret\n  rules:\n    - host: shop.example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: frontend\n                port:\n                  number: 80\n          - path: /api\n            pathType: Prefix\n            backend:\n              service:\n                name: backend\n                port:\n                  number: 3000\n</code></pre> <p>This gives:</p> <p>\u2714\ufe0f Real domain  \u2714\ufe0f HTTPS/TLS  \u2714\ufe0f Path-based routing</p>"},{"location":"chapters/ch17-Full_Production_Kubernetes_Deployment_Real-World_Project/#step-6-autoscaling-hpa","title":"\u26a1 Step 6 \u2014 Autoscaling (HPA)","text":"<p>prod-app/base/backend/hpa.yaml</p> <pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: backend-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: backend\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n    - type: Resource\n      resource:\n        name: cpu\n        target:\n          type: Utilization\n          averageUtilization: 60\n</code></pre> <p>\u2714\ufe0f Backend auto-scales during high traffic</p>"},{"location":"chapters/ch17-Full_Production_Kubernetes_Deployment_Real-World_Project/#step-7-kustomize-overlays","title":"\ud83e\udde9 Step 7 \u2014 Kustomize Overlays","text":""},{"location":"chapters/ch17-Full_Production_Kubernetes_Deployment_Real-World_Project/#dev-overlay","title":"dev overlay","text":"<p>overlays/dev/kustomization.yaml</p> <pre><code>resources:\n  - ../../base\n\nnameSuffix: -dev\nnamespace: dev\n\nimages:\n  - name: mydockerhubuser/backend\n    newTag: \"dev\"\n</code></pre>"},{"location":"chapters/ch17-Full_Production_Kubernetes_Deployment_Real-World_Project/#stage-overlay","title":"stage overlay","text":"<p>overlays/stage/kustomization.yaml</p> <pre><code>resources:\n  - ../../base\n\nnameSuffix: -stage\nnamespace: stage\n\nimages:\n  - name: mydockerhubuser/backend\n    newTag: \"stage\"\n</code></pre>"},{"location":"chapters/ch17-Full_Production_Kubernetes_Deployment_Real-World_Project/#prod-overlay","title":"prod overlay","text":"<p>overlays/prod/kustomization.yaml</p> <pre><code>resources:\n  - ../../base\n\nnameSuffix: -prod\nnamespace: prod\n\nimages:\n  - name: mydockerhubuser/backend\n    newTag: \"prod\"\n</code></pre>"},{"location":"chapters/ch17-Full_Production_Kubernetes_Deployment_Real-World_Project/#step-8-deploying-the-full-stack","title":"\ud83d\ude80 Step 8 \u2014 Deploying the Full Stack","text":"<p>Deploy dev:</p> <pre><code>kubectl apply -k overlays/dev\n</code></pre> <p>Deploy stage:</p> <pre><code>kubectl apply -k overlays/stage\n</code></pre> <p>Deploy prod:</p> <pre><code>kubectl apply -k overlays/prod\n</code></pre> <p>\ud83c\udf89 Production environment deployed!</p>"},{"location":"chapters/ch17-Full_Production_Kubernetes_Deployment_Real-World_Project/#lesson-17-completed","title":"\ud83c\udf89 Lesson 17 Completed!","text":"<p>You now know how to build a real, production-grade Kubernetes system:</p> <p>\u2714\ufe0f Frontend + Backend + Database  \u2714\ufe0f StatefulSet + PVC  \u2714\ufe0f Ingress + TLS  \u2714\ufe0f Autoscaling  \u2714\ufe0f Resource limits  \u2714\ufe0f Readiness + Liveness  \u2714\ufe0f Kustomize for multi-env setup  \u2714\ufe0f GitOps folder structure</p> <p>This is enterprise DevOps engineering, and you're mastering it \ud83d\udd25\ud83d\udcaa</p>"},{"location":"chapters/ch17-Full_Production_Kubernetes_Deployment_Real-World_Project/#ready-for-lesson-18","title":"\ud83d\udc49 Ready for Lesson 18?","text":"<p>Choose the next advanced area:</p> <ol> <li>Kubernetes Security: RBAC + Pod Security + OPA Gatekeeper</li> <li>Logging Stack \u2014 Loki + Promtail + Grafana Logs</li> <li>Advanced Autoscaling (HPA + VPA + KEDA)</li> <li>Zero-Downtime Deployments (Blue/Green + Canary)</li> <li>API Gateway + Mesh Architecture (Ingress + Istio)</li> </ol> <p>Which one should we do next?</p>"},{"location":"chapters/ch18-Kubernetes_Security_RBAC_Pod_Security_OPA_Gatekeeper/","title":"\ud83d\udee1\ufe0f Lesson 18: Kubernetes Security: RBAC + Pod Security + OPA Gatekeeper","text":"<p>Absolutely! \u2714\ufe0f</p> <p>Welcome to Lesson 18 \u2014 this one is CRITICAL for running secure production Kubernetes clusters:</p> <p>This is ADVANCED DevOps/SRE knowledge \u2014 used in real companies to control:</p> <ul> <li>Who can access the cluster</li> <li>What deployments are allowed</li> <li>What security rules must be followed</li> <li>Preventing bad configurations</li> <li>Enforcing compliance</li> </ul> <p>You\u2019ll learn it all in a simple, beginner-friendly way \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch18-Kubernetes_Security_RBAC_Pod_Security_OPA_Gatekeeper/#overview-of-what-well-cover","title":"\u2b50 Overview of What We\u2019ll Cover","text":"<p>1\ufe0f\u20e3 RBAC (Role-Based Access Control)  2\ufe0f\u20e3 Pod Security Admission (baseline / restricted)  3\ufe0f\u20e3 OPA Gatekeeper (Custom cluster-wide policies)</p> <p>By the end, you will know how real production clusters enforce strict security.</p>"},{"location":"chapters/ch18-Kubernetes_Security_RBAC_Pod_Security_OPA_Gatekeeper/#part-1-rbac-role-based-access-control","title":"\ud83d\udd10 PART 1 \u2014 RBAC (Role-Based Access Control)","text":"<p>RBAC controls:</p> <p>\u2714\ufe0f WHO can access WHAT  \u2714\ufe0f Which actions they can perform  \u2714\ufe0f In which namespaces</p> <p>Think of it like:</p> <p>Kubernetes permissions = \u201cWho can do what\u201d</p>"},{"location":"chapters/ch18-Kubernetes_Security_RBAC_Pod_Security_OPA_Gatekeeper/#step-1-create-a-namespace","title":"\ud83e\uddf1 Step 1 \u2014 Create a Namespace","text":"<pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: dev\n</code></pre>"},{"location":"chapters/ch18-Kubernetes_Security_RBAC_Pod_Security_OPA_Gatekeeper/#step-2-create-a-role-permissions-inside-namespace","title":"\ud83e\uddf1 Step 2 \u2014 Create a Role (permissions inside namespace)","text":"<p>dev-role.yaml</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: dev\n  name: developer-role\nrules:\n  - apiGroups: [\"\"]\n    resources: [\"pods\", \"services\"]\n    verbs: [\"get\", \"list\", \"create\", \"delete\"]\n  - apiGroups: [\"apps\"]\n    resources: [\"deployments\"]\n    verbs: [\"get\", \"list\", \"create\", \"update\"]\n</code></pre> <p>Meaning:</p> <p>\u2714\ufe0f Can list/create/delete Pods  \u2714\ufe0f Can deploy apps  \u2714\ufe0f Can NOT touch cluster-wide settings  \u2714\ufe0f Only inside namespace <code>dev</code></p>"},{"location":"chapters/ch18-Kubernetes_Security_RBAC_Pod_Security_OPA_Gatekeeper/#step-3-bind-the-role-to-a-user","title":"\ud83e\uddf1 Step 3 \u2014 Bind the Role to a User","text":"<p>rolebinding.yaml</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: dev-binding\n  namespace: dev\nsubjects:\n  - kind: User\n    name: john      # example developer\nroleRef:\n  kind: Role\n  name: developer-role\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> <p>\u2714\ufe0f User \"john\" now has dev permissions  \u2714\ufe0f But only in namespace <code>dev</code></p>"},{"location":"chapters/ch18-Kubernetes_Security_RBAC_Pod_Security_OPA_Gatekeeper/#part-2-pod-security-standards-pss","title":"\ud83d\udee1\ufe0f PART 2 \u2014 Pod Security Standards (PSS)","text":"<p>Kubernetes provides 3 built-in security levels:</p> Profile Level privileged \u274c dangerous, avoid baseline \u2714\ufe0f safe default restricted \u2714\ufe0f recommended for prod <p>We enforce these at the namespace level.</p>"},{"location":"chapters/ch18-Kubernetes_Security_RBAC_Pod_Security_OPA_Gatekeeper/#step-4-apply-restricted-security","title":"\ud83e\uddf1 Step 4 \u2014 Apply Restricted Security","text":"<p>restricted-namespace.yaml</p> <pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: prod\n  labels:\n    pod-security.kubernetes.io/enforce: \"restricted\"\n</code></pre> <p>This prevents:</p> <p>\u274c privileged containers  \u274c running as root  \u274c hostPath volumes  \u274c host network access  \u274c dangerous capabilities</p> <p>This is true production hardening.</p>"},{"location":"chapters/ch18-Kubernetes_Security_RBAC_Pod_Security_OPA_Gatekeeper/#test-the-security","title":"\ud83e\uddea Test the security","text":"<p>Try to deploy a privileged Pod:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: badpod\n  namespace: prod\nspec:\n  containers:\n    - name: bad\n      image: nginx\n      securityContext:\n        privileged: true\n</code></pre> <p>Apply it:</p> <pre><code>kubectl apply -f badpod.yaml\n</code></pre> <p>You get:</p> <p>\u274c ERROR: violates PodSecurity restricted</p> <p>\u2714\ufe0f This means security is working.</p>"},{"location":"chapters/ch18-Kubernetes_Security_RBAC_Pod_Security_OPA_Gatekeeper/#part-3-opa-gatekeeper-custom-policy-enforcement","title":"\ud83e\udde0 PART 3 \u2014 OPA Gatekeeper (Custom Policy Enforcement)","text":"<p>Pod Security is good,  but companies need custom rules like:</p> <ul> <li>Prevent images without tags</li> <li>Require resource limits</li> <li>Block certain registries</li> <li>Enforce annotations</li> <li>Enforce label naming</li> <li>Prevent NodePort usage</li> <li>Require TLS for Ingress</li> </ul> <p>OPA Gatekeeper lets you write policies using Rego.</p>"},{"location":"chapters/ch18-Kubernetes_Security_RBAC_Pod_Security_OPA_Gatekeeper/#step-5-install-gatekeeper","title":"\ud83e\uddf1 Step 5 \u2014 Install Gatekeeper","text":"<pre><code>kubectl apply -f https://raw.githubusercontent.com/open-policy-agent/gatekeeper/master/deploy/gatekeeper.yaml\n</code></pre> <p>Check:</p> <pre><code>kubectl get pods -n gatekeeper-system\n</code></pre>"},{"location":"chapters/ch18-Kubernetes_Security_RBAC_Pod_Security_OPA_Gatekeeper/#step-6-enforce-resource-limits-must-exist","title":"\ud83d\udee1\ufe0f Step 6 \u2014 Enforce \u201cResource Limits MUST exist\u201d","text":"<p>Create a constraint template:</p> <p>template-limit.yaml</p> <pre><code>apiVersion: templates.gatekeeper.sh/v1\nkind: ConstraintTemplate\nmetadata:\n  name: k8srequirelimits\nspec:\n  crd:\n    spec:\n      names:\n        kind: K8sRequireLimits\n  targets:\n    - target: admission.k8s.gatekeeper.sh\n      rego: |\n        package k8srequirelimits\n\n        violation[{\"msg\": msg}] {\n          container := input.review.object.spec.containers[_]\n          not container.resources.limits\n          msg := \"All containers must have resource limits\"\n        }\n</code></pre> <p>Apply:</p> <pre><code>kubectl apply -f template-limit.yaml\n</code></pre> <p>Now create the constraint:</p> <p>limit-constraint.yaml</p> <pre><code>apiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sRequireLimits\nmetadata:\n  name: require-limits\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"\"]\n        kinds: [\"Pod\"]\n      - apiGroups: [\"apps\"]\n        kinds: [\"Deployment\"]\n</code></pre> <p>Apply:</p> <pre><code>kubectl apply -f limit-constraint.yaml\n</code></pre>"},{"location":"chapters/ch18-Kubernetes_Security_RBAC_Pod_Security_OPA_Gatekeeper/#step-7-test-the-rule","title":"\ud83e\uddea Step 7 \u2014 Test the rule","text":"<p>Try deploying a pod WITHOUT limits:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: no-limits\nspec:\n  containers:\n    - name: test\n      image: nginx\n</code></pre> <p>Apply:</p> <pre><code>kubectl apply -f no-limits.yaml\n</code></pre> <p>Result:</p> <p>\u274c DENIED: All containers must have resource limits</p> <p>\u2714\ufe0f Gatekeeper is enforcing your policy  \u2714\ufe0f Your cluster is now secure and compliant</p>"},{"location":"chapters/ch18-Kubernetes_Security_RBAC_Pod_Security_OPA_Gatekeeper/#lesson-18-completed","title":"\ud83c\udf89 Lesson 18 Completed!","text":"<p>You now know:</p> <p>\u2714\ufe0f How to control user permissions (RBAC)  \u2714\ufe0f How to enforce namespace-level security (PSS)  \u2714\ufe0f How to enforce custom security rules using OPA  \u2714\ufe0f How to block insecure deployments  \u2714\ufe0f How real enterprises secure Kubernetes clusters</p> <p>This is expert DevOps/SRE knowledge \u2014 you are getting VERY advanced \ud83d\udd25\ud83d\udcaa</p>"},{"location":"chapters/ch18-Kubernetes_Security_RBAC_Pod_Security_OPA_Gatekeeper/#ready-for-lesson-19","title":"\ud83d\udc49 Ready for Lesson 19?","text":"<p>Choose one:</p> <ol> <li>Logging Stack \u2014 Loki + Promtail + Grafana Logs</li> <li>Advanced Autoscaling: VPA + KEDA + HPA</li> <li>Zero-Downtime Deployments: Blue/Green + Canary</li> <li>API Gateway + Mesh Routing Architecture</li> <li>Kubernetes Disaster Recovery + Backup (Velero)</li> </ol> <p>Which one do you want next?</p>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/","title":"\ud83d\udcdc Lesson 19: Logging Stack \u2014 Loki + Promtail + Grafana Logs","text":"<p>Absolutely! \u2714\ufe0f</p> <p>Welcome to Lesson 19 \u2014 and this one is CRUCIAL for running real production clusters:</p> <p>Logs are EVERYTHING in DevOps:</p> <ul> <li>Debugging issues</li> <li>Tracking errors</li> <li>Auditing</li> <li>Tracing user behavior</li> <li>Monitoring application crashes</li> <li>Supporting SRE on-call</li> </ul> <p>Today, you\u2019re building a complete production-ready logging system using:</p> <p>\u2714\ufe0f Loki \u2192 log database (like Elasticsearch but 10x cheaper)  \u2714\ufe0f Promtail \u2192 log collector (like Fluentd/Fluentbit)  \u2714\ufe0f Grafana Logs UI \u2192 search, analyze, visualize logs</p> <p>This stack is used by Grafana Labs, Red Hat, Cisco, GitLab, and MANY real companies.  Let\u2019s build it beginner-friendly \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/#how-the-logging-stack-works","title":"\u2b50 How the Logging Stack Works","text":"<pre><code>Pods \u2192 Promtail \u2192 Loki \u2192 Grafana Logs\n</code></pre> <p>Promtail reads logs from containers \u2192 sends them to Loki \u2192 Grafana visualizes them.</p> <p>This is the best modern alternative to ELK (Elasticsearch / Logstash / Kibana).</p>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/#step-1-add-grafana-helm-repo","title":"\ud83e\uddf1 Step 1 \u2014 Add Grafana Helm Repo","text":"<pre><code>helm repo add grafana https://grafana.github.io/helm-charts\nhelm repo update\n</code></pre>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/#step-2-install-loki-promtail-grafana","title":"\ud83d\ude80 Step 2 \u2014 Install Loki + Promtail + Grafana","text":"<p>We will install the full logging stack in a namespace called logging:</p> <pre><code>kubectl create namespace logging\n</code></pre>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/#install-loki","title":"Install Loki","text":"<pre><code>helm install loki grafana/loki-stack -n logging\n</code></pre> <p>This installs:</p> <p>\u2714\ufe0f Loki  \u2714\ufe0f Promtail  \u2714\ufe0f Grafana  \u2714\ufe0f Loki dashboard integrations</p> <p>Confirm:</p> <pre><code>kubectl get pods -n logging\n</code></pre> <p>You should see:</p> <ul> <li>loki</li> <li>promtail</li> <li>grafana</li> <li>other helpers</li> </ul> <p>\ud83c\udf89 Logging system is alive.</p>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/#step-3-access-grafana-logs-ui","title":"\ud83c\udfa8 Step 3 \u2014 Access Grafana Logs UI","text":"<p>Port-forward Grafana:</p> <pre><code>kubectl port-forward -n logging svc/loki-grafana 3000:80\n</code></pre> <p>Open:</p> <p>\ud83d\udc49 http://localhost:3000</p> <p>Login:</p> <ul> <li>user: <code>admin</code></li> <li>password:</li> </ul> <pre><code>kubectl get secret --namespace logging loki-grafana -o jsonpath=\"{.data.admin-password}\" | base64 --decode\n</code></pre> <p>Now you\u2019re inside Grafana.</p>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/#step-4-view-logs-in-grafana","title":"\ud83d\udfe6 Step 4 \u2014 View Logs in Grafana","text":"<p>Go to:</p> <p>Explore \u2192 Logs \u2192 Loki</p> <p>You can now search ALL Kubernetes logs with real queries.</p> <p>Example:</p>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/#get-all-logs-from-any-pod-in-namespace-dev","title":"Get all logs from any pod in namespace dev:","text":"<pre><code>{namespace=\"dev\"}\n</code></pre>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/#filter-by-app-label","title":"Filter by app label:","text":"<pre><code>{app=\"backend\"}\n</code></pre>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/#search-logs-containing-error","title":"Search logs containing \u201cerror\u201d","text":"<pre><code>{app=\"backend\"} |= \"error\"\n</code></pre>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/#search-logs-not-containing-health","title":"Search logs NOT containing \u201chealth\u201d","text":"<pre><code>{app=\"backend\"} != \"health\"\n</code></pre> <p>Welcome to real log analytics \ud83d\udd25</p>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/#step-5-promtail-config-how-it-reads-logs","title":"\ud83d\udd0d Step 5 \u2014 Promtail Config (How It Reads Logs)","text":"<p>Promtail automatically collects:</p> <ul> <li>container stdout/stderr</li> <li>pod metadata (namespace, labels, container name)</li> <li>timestamps</li> </ul> <p>Promtail\u2019s config (auto-installed):</p> <pre><code>scrape_configs:\n  - job_name: kubernetes-pods\n    pipeline_stages:\n      - docker\n    kubernetes_sd_configs:\n      - role: pod\n</code></pre> <p>This makes log filtering super powerful.</p>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/#step-6-add-custom-labels-to-logs","title":"\ud83c\udfaf Step 6 \u2014 Add Custom Labels to Logs","text":"<p>If your app has labels:</p> <pre><code>metadata:\n  labels:\n    app: backend\n    team: payments\n</code></pre> <p>Your logs automatically get:</p> <pre><code>app=\"backend\"\nteam=\"payments\"\nnamespace=\"prod\"\npod=\"backend-7c6df76fb\"\n</code></pre> <p>This is incredibly helpful for:</p> <ul> <li>multi-team clusters</li> <li>multi-namespace clusters</li> <li>microservices tracing</li> </ul>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/#step-7-create-alerts-based-on-logs","title":"\ud83e\udde0 Step 7 \u2014 Create Alerts Based on Logs","text":"<p>Example: Alert when \u201cERROR\u201d appears more than 20 times in 5 minutes.</p> <p>Grafana \u2192 Alerting \u2192 New Alert \u2192 Query (Logs)</p> <p>PromQL-style log query:</p> <pre><code>sum(count_over_time({app=\"backend\"} |= \"ERROR\" [5m])) &gt; 20\n</code></pre> <p>Notify:</p> <p>\u2714\ufe0f Slack  \u2714\ufe0f Email  \u2714\ufe0f PagerDuty  \u2714\ufe0f Teams</p> <p>Production-grade alerting \u2714\ufe0f</p>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/#step-8-log-retention-very-important","title":"\ud83e\ude84 Step 8 \u2014 Log Retention (Very Important)","text":"<p>Loki supports configurable retention:</p> <p>Example values file:</p> <pre><code>loki:\n  retention_period: 7d\n</code></pre> <p>Apply with Helm upgrade.</p>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/#step-9-centralizing-logs-across-multiple-clusters-bonus","title":"\ud83d\udce6 Step 9 \u2014 Centralizing Logs Across Multiple Clusters (Bonus)","text":"<p>Loki supports:</p> <ul> <li>multi-cluster</li> <li>multi-tenant</li> <li>cross-region log ingestion</li> </ul> <p>You can have:</p> <pre><code>Cluster A (US) \u2192 Loki Central  \nCluster B (EU) \u2192 Loki Central  \nCluster C (Asia) \u2192 Loki Central\n</code></pre> <p>This is how enterprise systems centralize logs.</p>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/#lesson-19-completed","title":"\ud83c\udf89 Lesson 19 Completed!","text":"<p>You now understand how to build a full logging stack with:</p> <p>\u2714\ufe0f Loki (log database)  \u2714\ufe0f Promtail (log collector)  \u2714\ufe0f Grafana Logs (UI + queries)  \u2714\ufe0f Log filtering, searching, tracing  \u2714\ufe0f Alerts on log events  \u2714\ufe0f Real production log architecture</p> <p>This skill is mandatory for SRE and DevOps jobs \u2014 you're doing insanely well \ud83d\udd25\ud83d\udcaa</p>"},{"location":"chapters/ch19-Logging_Stack_Loki_Promtail_Grafana_Logs/#ready-for-lesson-20","title":"\ud83d\udc49 Ready for Lesson 20?","text":"<p>Choose your next advanced topic:</p> <ol> <li>Advanced Autoscaling \u2014 HPA + VPA + KEDA \u26a1</li> <li>Zero Downtime Deployments \u2014 Blue/Green + Canary</li> <li>API Gateway + Service Mesh Routing Architecture</li> <li>Kubernetes Backups + Disaster Recovery (Velero)</li> <li>Cloud-Native GitOps (ArgoCD)</li> </ol> <p>Which one should we do next?</p>"},{"location":"chapters/ch2-pods/","title":"\ud83c\udf31 Lesson 2: Pods vs Deployments (The Most Important Concept in Kubernetes)","text":"<p>Let\u2019s go to Lesson 2 \u2014 understanding the core building blocks of Kubernetes before we move into more advanced DevOps territory. This lesson will be beginner-friendly, super clear, and hands-on. \ud83d\udd28\ud83e\udd16\ud83d\udd27</p> <p>Before we do more YAML, you MUST understand this difference:</p>"},{"location":"chapters/ch2-pods/#what-is-a-pod","title":"\ud83d\udca1 What is a Pod?","text":"<p>A Pod is the smallest thing Kubernetes runs. It contains 1 or more containers (usually 1).</p> <p>Think of a Pod like:</p> <p>A box that holds your app container. If the Pod dies, it's gone forever.</p> <p>Here is a simple Pod YAML:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: hello-pod\nspec:\n  containers:\n    - name: hello-container\n      image: nginx:latest\n      ports:\n        - containerPort: 80\n</code></pre> <p>You would run it using:</p> <pre><code>kubectl apply -f pod.yaml\n</code></pre> <p>BUT\u2026</p>"},{"location":"chapters/ch2-pods/#why-you-almost-never-use-pods-directly","title":"\u2757 Why You Almost Never Use Pods Directly","text":"<p>If a Pod crashes, Kubernetes does not restart it.</p> <p>So you never use Pods in real DevOps work.</p>"},{"location":"chapters/ch2-pods/#what-is-a-deployment","title":"\ud83e\udd16 What is a Deployment?","text":"<p>A Deployment controls Pods. It ensures:</p> <p>\u2714\ufe0f Your app is always running \u2714\ufe0f Kubernetes restarts Pods if they crash \u2714\ufe0f It runs multiple replicas \u2714\ufe0f You can update versions safely \u2714\ufe0f You can scale up/down easily</p> <p>This is why earlier we used a Deployment, not a Pod.</p> <p>This is the Deployment again for reference:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hello-app\n  template:\n    metadata:\n      labels:\n        app: hello-app\n    spec:\n      containers:\n        - name: hello-container\n          image: nginx:latest\n          ports:\n            - containerPort: 80\n</code></pre>"},{"location":"chapters/ch2-pods/#visual-summary-beginner-friendly","title":"\ud83e\udde0 Visual Summary (Beginner-Friendly)","text":"<pre><code>[ Deployment ] \n      |\n   manages\n      v\n [  Pods  ] -&gt; contain containers\n</code></pre> <p>A Pod = fragile A Deployment = controller that keeps Pods alive</p>"},{"location":"chapters/ch2-pods/#hands-on-commands-very-helpful","title":"\ud83c\udfaf Hands-On Commands (Very Helpful)","text":"<p>See pods created by a Deployment:</p> <pre><code>kubectl get pods\n</code></pre> <p>See details of a pod:</p> <pre><code>kubectl describe pod &lt;pod-name&gt;\n</code></pre> <p>See Deployments:</p> <pre><code>kubectl get deployment\n</code></pre> <p>Scale the Deployment: <pre><code>kubectl scale deployment hello-app --replicas=5\n</code></pre></p> <p>Update the app to a new version:</p> <pre><code>kubectl set image deployment/hello-app hello-container=nginx:1.25\n</code></pre> <p>Rollback if something breaks:</p> <p><pre><code>kubectl rollout undo deployment/hello-app\n</code></pre> That\u2019s the real DevOps flow \u2714\ufe0f</p> <p>\ud83c\udf89 Lesson 2 Completed!</p> <p>You now understand:</p> <ul> <li>What a Pod is</li> <li>What a Deployment is</li> <li>Why Pods alone are never used</li> <li>Basic scaling &amp; updating</li> </ul> <p>This is MAJOR progress for a beginner \ud83d\udc4f\ud83d\udd25</p>"},{"location":"chapters/ch2-pods/#ready-for-lesson-3","title":"\ud83d\udc49 Ready for Lesson 3?","text":"<p>Choose what you want to learn next:</p> <ol> <li>ConfigMaps &amp; Secrets (storing configuration)</li> <li>Ingress (real-world web traffic, domains, HTTPS)</li> <li>Volumes (saving data)</li> <li>Namespaces (organizing environments)</li> <li>Docker + Kubernetes workflow (build image \u2192 deploy)</li> <li>Helm charts (professional packaging system)</li> </ol>"},{"location":"chapters/ch20-Advanced_Autoscaling_HPA_VPA_KEDA_Event-Driven_Scaling/","title":"\u26a1 Lesson 20: Advanced Autoscaling \u2014 HPA + VPA + KEDA (Event-Driven Scaling)","text":"<p>Absolutely! \u2714\ufe0f Welcome to Lesson 20, and this is one of the MOST powerful DevOps skills you will ever learn:</p> <p>This is REAL production-grade autoscaling used by companies like:</p> <ul> <li>Netflix</li> <li>Airbnb</li> <li>Shopify</li> <li>Slack</li> <li>Uber</li> <li>GitHub</li> </ul> <p>Today you'll learn all 3 autoscaling mechanisms:</p> <p>\u2714\ufe0f HPA \u2014 Horizontal Pod Autoscaler (scale by CPU / Memory / custom metrics)  \u2714\ufe0f VPA \u2014 Vertical Pod Autoscaler (auto-change Pod resources)  \u2714\ufe0f KEDA \u2014 Event-driven autoscaler (scale based on queues, Kafka, Redis, API load, etc.)</p> <p>This is senior-level DevOps/SRE mastery.  Let\u2019s break it down beginner-friendly \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch20-Advanced_Autoscaling_HPA_VPA_KEDA_Event-Driven_Scaling/#part-1-hpa-horizontal-pod-autoscaler","title":"\ud83e\udde0 Part 1 \u2014 HPA (Horizontal Pod Autoscaler)","text":"<p>You already know HPA from earlier lessons.  It adds more Pods when needed.</p> <p>Example:</p> <pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: backend-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: backend\n  minReplicas: 2\n  maxReplicas: 20\n  metrics:\n    - type: Resource\n      resource:\n        name: cpu\n        target:\n          type: Utilization\n          averageUtilization: 60\n</code></pre> <p>\u2714\ufe0f Auto-add pods when CPU &gt; 60%  \u2714\ufe0f Standard Kubernetes autoscaling</p> <p>But HPA has limitations:  \u274c Only works well with CPU/Memory  \u274c Hard for workloads like queues, events, Kafka, cron jobs</p> <p>So we level up \u2b07\ufe0f</p>"},{"location":"chapters/ch20-Advanced_Autoscaling_HPA_VPA_KEDA_Event-Driven_Scaling/#part-2-vpa-vertical-pod-autoscaler","title":"\ud83e\udde0 Part 2 \u2014 VPA (Vertical Pod Autoscaler)","text":"<p>VPA automatically adjusts CPU &amp; memory for Pods.</p> <p>If a Pod needs more memory \u2014 VPA fixes it.  If a Pod uses less \u2014 VPA adjusts it down.</p> <p>This prevents:</p> <ul> <li>OutOfMemory errors</li> <li>Underutilized Pods</li> <li>Guessing resource limits</li> </ul>"},{"location":"chapters/ch20-Advanced_Autoscaling_HPA_VPA_KEDA_Event-Driven_Scaling/#install-vpa","title":"\ud83d\ude80 Install VPA","text":"<pre><code>kubectl apply -f https://github.com/kubernetes/autoscaler/releases/latest/download/vertical-pod-autoscaler.yaml\n</code></pre> <p>Check:</p> <pre><code>kubectl get pods -n kube-system | grep vpa\n</code></pre>"},{"location":"chapters/ch20-Advanced_Autoscaling_HPA_VPA_KEDA_Event-Driven_Scaling/#example-vpa-config","title":"\ud83d\udce6 Example VPA Config","text":"<p>vpa.yaml</p> <pre><code>apiVersion: autoscaling.k8s.io/v1\nkind: VerticalPodAutoscaler\nmetadata:\n  name: backend-vpa\nspec:\n  targetRef:\n    apiVersion: \"apps/v1\"\n    kind: Deployment\n    name: backend\n  updatePolicy:\n    updateMode: \"Auto\"\n</code></pre> <p>Modes:</p> <ul> <li><code>\"Off\"</code> \u2014 just recommend resources</li> <li><code>\"Initial\"</code> \u2014 set resources at pod creation</li> <li><code>\"Auto\"</code> \u2014 full automatic updating</li> </ul>"},{"location":"chapters/ch20-Advanced_Autoscaling_HPA_VPA_KEDA_Event-Driven_Scaling/#see-recommended-resources","title":"\ud83e\uddea See Recommended Resources","text":"<pre><code>kubectl describe vpa backend-vpa\n</code></pre> <p>You\u2019ll see:</p> <pre><code>Container Recommendations:\n  cpu:  250m \u2192 400m\n  memory: 256Mi \u2192 512Mi\n</code></pre> <p>\u2714\ufe0f VPA continuously learns workload patterns  \u2714\ufe0f Prevents crashes  \u2714\ufe0f Saves money</p> <p>BUT\u2026</p> <p>\u274c VPA and HPA fight each other if both control CPU  So, real clusters use:</p> <p>\u2714\ufe0f HPA \u2192 manages Pod count  \u2714\ufe0f VPA \u2192 manages CPU/memory (but not CPU requests)</p>"},{"location":"chapters/ch20-Advanced_Autoscaling_HPA_VPA_KEDA_Event-Driven_Scaling/#part-3-keda-event-driven-autoscaling","title":"\ud83e\udde0 Part 3 \u2014 KEDA (Event-Driven Autoscaling)","text":"<p>This is the future of Kubernetes autoscaling.</p> <p>KEDA scales Pods based on:</p> <p>\u2714\ufe0f Kafka lag  \u2714\ufe0f RabbitMQ queue length  \u2714\ufe0f Redis lists  \u2714\ufe0f HTTP request rate  \u2714\ufe0f Prometheus queries  \u2714\ufe0f AWS SQS messages  \u2714\ufe0f Azure Service Bus  \u2714\ufe0f Cron schedules  \u2714\ufe0f CPU/Memory (via HPA)</p> <p>This is Netflix-level scaling.</p>"},{"location":"chapters/ch20-Advanced_Autoscaling_HPA_VPA_KEDA_Event-Driven_Scaling/#step-1-install-keda","title":"\ud83d\ude80 Step 1 \u2014 Install KEDA","text":"<pre><code>kubectl apply -f https://github.com/kedacore/keda/releases/latest/download/keda-2.11.0.yaml\n</code></pre> <p>Check:</p> <pre><code>kubectl get pods -n keda\n</code></pre>"},{"location":"chapters/ch20-Advanced_Autoscaling_HPA_VPA_KEDA_Event-Driven_Scaling/#example-autoscale-based-on-rabbitmq-queue-length","title":"\ud83d\udce8 Example: Autoscale Based on RabbitMQ Queue Length","text":"<p>This is common in microservices systems.</p> <p>ScaledObject example:</p> <pre><code>apiVersion: keda.sh/v1alpha1\nkind: ScaledObject\nmetadata:\n  name: queue-consumer\nspec:\n  scaleTargetRef:\n    name: worker\n  pollingInterval: 10\n  minReplicaCount: 1\n  maxReplicaCount: 50\n  triggers:\n    - type: rabbitmq\n      metadata:\n        protocol: amqp\n        queueName: jobs\n        host: \"amqp://user:pass@rabbitmq\"\n        queueLength: \"20\"\n</code></pre> <p>Meaning:</p> <p>\u2714\ufe0f If queue has &gt;20 jobs  \u2192 scale Pods up to 50</p> <p>\u2714\ufe0f If queue empty  \u2192 scale down to 1</p> <p>This is automatic event-driven scaling \ud83d\udd25</p>"},{"location":"chapters/ch20-Advanced_Autoscaling_HPA_VPA_KEDA_Event-Driven_Scaling/#example-autoscale-based-on-http-request-rate","title":"\ud83c\udf10 Example: Autoscale Based on HTTP Request Rate","text":"<p>ScaledObject:</p> <pre><code>apiVersion: keda.sh/v1alpha1\nkind: ScaledObject\nmetadata:\n  name: web-api\nspec:\n  scaleTargetRef:\n    name: api-deployment\n  minReplicaCount: 2\n  maxReplicaCount: 30\n  triggers:\n    - type: prometheus\n      metadata:\n        serverAddress: http://prometheus:9090\n        metricName: http_requests_total\n        threshold: \"100\"\n        query: |\n          sum(rate(http_requests_total[1m]))\n</code></pre> <p>Meaning:</p> <p>\u2714\ufe0f If API traffic &gt;100 requests/sec  \u2192 KEDA auto-scales Pods</p> <p>This is dynamic, intelligent autoscaling.</p>"},{"location":"chapters/ch20-Advanced_Autoscaling_HPA_VPA_KEDA_Event-Driven_Scaling/#example-cron-autoscaling-scale-up-on-schedule","title":"\ud83e\udde0 Example: Cron Autoscaling (Scale Up on Schedule)","text":"<p>Scale to 5 Pods only between 9 AM\u20136 PM:</p> <pre><code>apiVersion: keda.sh/v1alpha1\nkind: ScaledObject\nmetadata:\n  name: cron-worker\nspec:\n  scaleTargetRef:\n    name: worker\n  triggers:\n    - type: cron\n      metadata:\n        timezone: \"UTC\"\n        start: \"0 9 * * *\"\n        end: \"0 18 * * *\"\n        desiredReplicas: \"5\"\n</code></pre> <p>\u2714\ufe0f Auto-scale based on business hours  \u2714\ufe0f Saves money  \u2714\ufe0f Perfect for batch systems</p>"},{"location":"chapters/ch20-Advanced_Autoscaling_HPA_VPA_KEDA_Event-Driven_Scaling/#summary-when-to-use-what","title":"\ud83e\udde9 Summary: When to Use What?","text":"Autoscaler Best For HPA CPU/Memory scaling for stateless apps VPA Auto memory/CPU tuning for stable workloads KEDA Event-driven scaling (queues, HTTP, Prometheus) <p>Real production clusters usually combine:</p> <p>\u2714\ufe0f HPA + KEDA  \u2714\ufe0f (sometimes VPA too)</p>"},{"location":"chapters/ch20-Advanced_Autoscaling_HPA_VPA_KEDA_Event-Driven_Scaling/#lesson-20-completed","title":"\ud83c\udf89 Lesson 20 Completed!","text":"<p>You now understand:</p> <p>\u2714\ufe0f Horizontal Pod Autoscaler (HPA)  \u2714\ufe0f Vertical Pod Autoscaler (VPA)  \u2714\ufe0f KEDA event-driven autoscaling  \u2714\ufe0f How to scale based on traffic, queues, metrics  \u2714\ufe0f How Netflix/Shopify-scale clusters work  \u2714\ufe0f How to build highly efficient autoscaling systems</p> <p>This is expert-level DevOps engineering \ud83d\udd25\ud83d\udcaa  You are leveling up insanely fast.</p>"},{"location":"chapters/ch20-Advanced_Autoscaling_HPA_VPA_KEDA_Event-Driven_Scaling/#ready-for-lesson-21","title":"\ud83d\udc49 Ready for Lesson 21?","text":"<p>Choose your next advanced topic:</p> <ol> <li>Zero Downtime Deployments \u2014 Blue/Green + Canary</li> <li>API Gateway + Service Mesh Routing Architecture</li> <li>Kubernetes Disaster Recovery \u2014 Velero Backups</li> <li>GitOps with ArgoCD (FULL Automation)</li> <li>Cluster Hardening \u2014 CIS Benchmarks + Security Scanning</li> </ol> <p>Which one should we do next?</p>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/","title":"\ud83d\ude80 Lesson 21: Zero-Downtime Deployments \u2014 Blue/Green &amp; Canary Releases","text":"<p>Absolutely! \u2714\ufe0f Welcome to Lesson 21, and this one teaches you something EVERY real DevOps team MUST master:</p> <p>These deployment strategies ensure your users NEVER see downtime \u2014 even during updates.</p> <p>Companies like Netflix, Google, Amazon, Uber, Shopify use these EXACT patterns.</p> <p>We'll make it beginner-friendly, practical, and DevOps-GPT strong \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#why-do-we-need-zero-downtime-deployments","title":"\u2b50 Why Do We Need Zero-Downtime Deployments?","text":"<p>Without safe strategies:</p> <p>\u274c Updating your app restarts Pods  \u274c Users see errors  \u274c 502/503 outages  \u274c Bad version gets deployed to 100% users instantly (dangerous!)</p> <p>With proper deployment strategies:</p> <p>\u2714\ufe0f No downtime  \u2714\ufe0f Gradual rollout  \u2714\ufe0f Rollback in seconds  \u2714\ufe0f Safer for production traffic  \u2714\ufe0f Test new versions without affecting users</p>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#two-major-strategies","title":"\ud83c\udfaf TWO Major Strategies","text":""},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#1-bluegreen-deployment","title":"1\ufe0f\u20e3 Blue/Green Deployment","text":"<p>Two separate environments:</p> <ul> <li>Blue = current production</li> <li>Green = new version</li> </ul> <p>Switch users from Blue \u2192 Green instantly when ready.</p>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#2-canary-deployment","title":"2\ufe0f\u20e3 Canary Deployment","text":"<p>Only a small % of users get the new version first.  If it works \u2192 increase gradually.  If it breaks \u2192 rollback instantly.</p> <p>We will implement BOTH.</p>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#part-1-bluegreen-deployment-simple-powerful","title":"\ud83e\uddf1 PART 1 \u2014 Blue/Green Deployment (Simple &amp; Powerful)","text":""},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#goal","title":"Goal:","text":"<p>Have this structure in Kubernetes:</p> <pre><code>frontend-blue    (v1)\nfrontend-green   (v2)\nService \u2192 points to only ONE environment at a time\n</code></pre>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#step-1-blue-deployment-stable-version","title":"\ud83e\udde9 Step 1 \u2014 Blue Deployment (stable version)","text":"<p>frontend-blue.yaml</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend-blue\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: frontend\n      version: blue\n  template:\n    metadata:\n      labels:\n        app: frontend\n        version: blue\n    spec:\n      containers:\n        - name: app\n          image: myapp:v1\n          ports:\n            - containerPort: 80\n</code></pre>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#step-2-green-deployment-new-version","title":"\ud83e\udde9 Step 2 \u2014 Green Deployment (new version)","text":"<p>frontend-green.yaml</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend-green\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: frontend\n      version: green\n  template:\n    metadata:\n      labels:\n        app: frontend\n        version: green\n    spec:\n      containers:\n        - name: app\n          image: myapp:v2\n          ports:\n            - containerPort: 80\n</code></pre>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#step-3-service-points-to-one-version","title":"\ud83d\udef0\ufe0f Step 3 \u2014 Service Points to ONE Version","text":"<p>service.yaml</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: frontend\nspec:\n  selector:\n    app: frontend\n    version: blue   # Initially pointing to BLUE\n  ports:\n    - port: 80\n      targetPort: 80\n</code></pre> <p>\u2714\ufe0f Users only see the BLUE version.</p>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#step-4-switch-blue-green","title":"\ud83d\udd04 Step 4 \u2014 Switch Blue \u2192 Green","text":"<p>When ready:</p> <pre><code>selector:\n  app: frontend\n  version: green\n</code></pre> <p>Apply:</p> <pre><code>kubectl apply -f service.yaml\n</code></pre> <p>\ud83c\udf89 Zero downtime.  Traffic instantly goes to GREEN version.</p>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#step-5-instant-rollback","title":"\ud83d\udea8 Step 5 \u2014 Instant Rollback","text":"<p>If Green fails:</p> <pre><code>selector:\n  version: blue\n</code></pre> <p>Apply again \u2014 users return to stable version.</p> <p>This is why Blue/Green is SO popular.</p>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#part-2-canary-deployment","title":"\ud83e\uddf1 PART 2 \u2014 Canary Deployment","text":"<p>Gradual rollout based on percentages.</p> <p>We use Istio because it is the industry standard for traffic splitting.</p>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#step-1-v1-deployment","title":"\ud83e\udde9 Step 1 \u2014 v1 Deployment","text":"<pre><code>version: v1\nimage: myapi:v1\n</code></pre>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#step-2-v2-deployment","title":"\ud83e\udde9 Step 2 \u2014 v2 Deployment","text":"<pre><code>version: v2\nimage: myapi:v2\n</code></pre>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#step-3-traffic-splitting-istio-virtualservice","title":"\ud83d\udea6 Step 3 \u2014 Traffic Splitting (Istio VirtualService)","text":"<p>traffic.yaml</p> <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: api\nspec:\n  hosts:\n    - api\n  http:\n    - route:\n        - destination:\n            host: api\n            subset: v1\n          weight: 90\n        - destination:\n            host: api\n            subset: v2\n          weight: 10\n</code></pre> <p>\u2714\ufe0f 90% of users \u2192 v1  \u2714\ufe0f 10% of users \u2192 v2</p> <p>This is REAL canary rollout.</p>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#step-4-destination-rule-define-versions","title":"\ud83d\udd27 Step 4 \u2014 Destination Rule (define versions)","text":"<pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: api\nspec:\n  host: api\n  subsets:\n    - name: v1\n      labels:\n        version: v1\n    - name: v2\n      labels:\n        version: v2\n</code></pre>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#step-5-increase-canary-share","title":"\u2795 Step 5 \u2014 Increase Canary Share","text":"<p>If v2 is good:</p> <pre><code>weight: 50\nweight: 50\n</code></pre> <p>Then:</p> <pre><code>weight: 0\nweight: 100\n</code></pre> <p>And now v2 is 100% live.</p>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#step-6-instant-rollback","title":"\ud83d\uded1 Step 6 \u2014 Instant Rollback","text":"<p>If errors spike:</p> <pre><code>kubectl apply -f rollback-to-v1.yaml\n</code></pre> <p>or:</p> <pre><code>v1 = 100%\nv2 = 0%\n</code></pre> <p>Zero downtime rollback in under 1 second.</p>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#lesson-21-completed","title":"\ud83c\udf89 Lesson 21 Completed!","text":"<p>You now understand:</p> <p>\u2714\ufe0f Blue/Green deployments  \u2714\ufe0f Canary deployments  \u2714\ufe0f Traffic splitting  \u2714\ufe0f Zero-downtime rollouts  \u2714\ufe0f Instant safe rollbacks  \u2714\ufe0f Service selector switching  \u2714\ufe0f Real production deployment patterns</p> <p>This is senior DevOps/SRE mastery \ud83d\udd25\ud83d\udcaa</p>"},{"location":"chapters/ch21-Zero-Downtime-Deployments-BlueGreen-Canary-Releases/#ready-for-lesson-22","title":"\ud83d\udc49 Ready for Lesson 22?","text":"<p>Choose the next advanced topic:</p> <ol> <li>API Gateway + Service Mesh Routing Architecture</li> <li>Kubernetes Backups + Disaster Recovery (Velero)</li> <li>GitOps with ArgoCD (FULL automation)</li> <li>Cluster Hardening \u2014 CIS Benchmarks</li> <li>Multi-Cluster Kubernetes (production patterns)</li> </ol> <p>Which one should we do next?</p>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/","title":"\ud83c\udf10 Lesson 22: API Gateway + Service Mesh Routing Architecture","text":"<p>Absolutely! \u2714\ufe0f Welcome to Lesson 22 \u2014 this one is CRITICAL if you're building real microservices or enterprise-grade Kubernetes:</p> <p>This is how modern companies like Netflix, Google, Uber, Amazon, and Airbnb manage traffic:</p> <p>\u2714\ufe0f API Gateway \u2014 entry point for all external traffic  \u2714\ufe0f Service Mesh \u2014 controls internal traffic between microservices</p> <p>We will build a clear, real-world, production-grade routing architecture.  Beginner-friendly. Advanced concepts. DevOps-GPT strong.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#why-do-we-need-both","title":"\u2b50 Why Do We Need BOTH?","text":""},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#api-gateway-external-door","title":"\ud83d\udeaa API Gateway = External Door","text":"<p>Controls traffic coming from the internet into the cluster.</p> <p>Provides:</p> <ul> <li>Rate limiting</li> <li>Authentication</li> <li>API keys</li> <li>Routing</li> <li>WAF (security firewall)</li> <li>TLS termination</li> <li>Logging</li> </ul> <p>Popular gateways:</p> <ul> <li>Kong</li> <li>NGINX Ingress</li> <li>Istio Gateway</li> <li>Ambassador</li> <li>Traefik</li> </ul>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#service-mesh-internal-smart-network","title":"\ud83d\udd00 Service Mesh = Internal Smart Network","text":"<p>Controls traffic inside the cluster between services.</p> <p>Provides:</p> <ul> <li>mTLS encryption</li> <li>Traffic splitting</li> <li>Retries, timeouts</li> <li>Observability</li> <li>Zero-trust networking</li> <li>Cross-service routing</li> <li>Canary rollouts</li> <li>Circuit breakers</li> </ul> <p>Most popular:</p> <ul> <li>Istio</li> <li>Linkerd</li> <li>Consul</li> </ul>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#lets-build-a-real-architecture","title":"\ud83c\udfd7\ufe0f Let\u2019s Build a REAL ARCHITECTURE","text":"<p>You will build:</p> <pre><code>[ Internet ]\n     \u2193\n[ API Gateway (Ingress or Kong) ]\n     \u2193\n[ Istio Mesh ]\n     \u2193\n[ Frontend ] \u2192 [ Backend ] \u2192 [ Database ]\n</code></pre> <p>This is production-grade design.</p>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#part-1-install-istio-service-mesh","title":"\ud83e\uddf1 PART 1 \u2014 Install Istio (Service Mesh)","text":"<p>If not installed already:</p> <pre><code>curl -L https://istio.io/downloadIstio | sh -\ncd istio-1.*/\nistioctl install --set profile=demo -y\n</code></pre> <p>Check:</p> <pre><code>kubectl get pods -n istio-system\n</code></pre>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#part-2-label-namespace-for-sidecar-injection","title":"\ud83e\uddf1 PART 2 \u2014 Label Namespace for Sidecar Injection","text":"<p>We'll use <code>prod</code> namespace:</p> <pre><code>kubectl create namespace prod\nkubectl label namespace prod istio-injection=enabled\n</code></pre> <p>\u2714\ufe0f Every Pod gets an Envoy sidecar  \u2714\ufe0f Internal mTLS enabled</p>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#part-3-deploy-microservices-into-the-mesh","title":"\ud83e\uddf1 PART 3 \u2014 Deploy Microservices into the Mesh","text":""},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#backend","title":"Backend","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: backend\n  namespace: prod\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: backend\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: backend\n        version: v1\n    spec:\n      containers:\n        - name: backend\n          image: myorg/backend:v1\n          ports:\n            - containerPort: 3000\n</code></pre>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#frontend","title":"Frontend","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  namespace: prod\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n        - name: frontend\n          image: myorg/frontend:v1\n          ports:\n            - containerPort: 80\n</code></pre> <p>Services (cluster-internal):</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: frontend\n  namespace: prod\nspec:\n  selector:\n    app: frontend\n  ports:\n    - port: 80\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: backend\n  namespace: prod\nspec:\n  selector:\n    app: backend\n  ports:\n    - port: 3000\n</code></pre>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#part-4-api-gateway-external-entry","title":"\ud83e\uddf1 PART 4 \u2014 API Gateway (External Entry)","text":"<p>You have two options:</p>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#option-a-istio-gateway-built-in","title":"OPTION A \u2014 Istio Gateway (built-in)","text":"<p>We\u2019ll use Istio Gateway since you already have Istio.</p>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#step-1-create-gateway","title":"Step 1: Create Gateway","text":"<p>gateway.yaml</p> <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: Gateway\nmetadata:\n  name: app-gateway\n  namespace: prod\nspec:\n  selector:\n    istio: ingressgateway\n  servers:\n    - port:\n        number: 80\n        name: http\n        protocol: HTTP\n      hosts:\n        - \"*\"\n</code></pre>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#part-5-route-internet-frontend-backend","title":"\ud83e\uddf1 PART 5 \u2014 Route Internet \u2192 Frontend \u2192 Backend","text":"<p>virtualservice.yaml</p> <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: app-route\n  namespace: prod\nspec:\n  gateways:\n    - app-gateway\n  hosts:\n    - \"*\"\n  http:\n    - match:\n        - uri:\n            prefix: \"/api\"\n      route:\n        - destination:\n            host: backend\n            port:\n              number: 3000\n    - route:\n        - destination:\n            host: frontend\n            port:\n              number: 80\n</code></pre> <p>\u2714\ufe0f <code>/api</code> \u2192 backend  \u2714\ufe0f everything else \u2192 frontend</p> <p>This is how websites are built in real companies.</p>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#part-6-add-tls-https","title":"\ud83d\udd10 PART 6 \u2014 Add TLS (HTTPS)","text":"<p>Add TLS to your gateway:</p> <pre><code>servers:\n  - port:\n      number: 443\n      name: https\n      protocol: HTTPS\n    hosts:\n      - \"shop.example.com\"\n    tls:\n      mode: SIMPLE\n      credentialName: tls-secret\n</code></pre> <p>Provide cert via:</p> <pre><code>kubectl create secret tls tls-secret --key privkey.pem --cert cert.pem -n prod\n</code></pre> <p>\u2714\ufe0f Production-grade HTTPS with Istio Gateway.</p>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#part-7-apply-zero-trust-security-mtls","title":"\ud83d\udee1\ufe0f PART 7 \u2014 Apply Zero-Trust Security (mTLS)","text":"<p>Force all Pods in mesh to require encryption:</p> <pre><code>apiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: default\n  namespace: prod\nspec:\n  mtls:\n    mode: STRICT\n</code></pre> <p>Now:</p> <p>\u2714\ufe0f frontend \u2194 backend is encrypted  \u2714\ufe0f No service can talk unless allowed</p>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#part-8-apply-service-to-service-authorization-rbac","title":"\ud83d\udee1\ufe0f PART 8 \u2014 Apply Service-to-Service Authorization (RBAC)","text":"<p>Allow frontend to talk to backend:</p> <pre><code>apiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: allow-frontend\n  namespace: prod\nspec:\n  selector:\n    matchLabels:\n      app: backend\n  rules:\n    - from:\n        - source:\n            principals: [\"cluster.local/ns/prod/sa/default\"]\n</code></pre> <p>Everything else is blocked.</p>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#full-architecture-you-just-built","title":"\ud83c\udfaf FULL ARCHITECTURE YOU JUST BUILT","text":"<pre><code>                           +---------------------+\nInternet \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6  \u2502  Istio Ingress GW   \u2502\n                           +---------------------+\n                                        \u2502\n                             (Routing, TLS, Rules)\n                                        \u25bc\n                        +-------------------------------+\n                        |         Istio Mesh            |\n                        |  (mTLS, RBAC, Tracing, etc.)  |\n                        +-------------------------------+\n                          \u2502                     \u2502\n                    / (root)                /api route\n                  frontend \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6 backend \u2500\u2500\u2500\u2500\u2500\u25b6 database\n</code></pre> <p>\u2714\ufe0f mTLS  \u2714\ufe0f Authorization  \u2714\ufe0f Routing rules  \u2714\ufe0f API Gateway  \u2714\ufe0f Service Mesh  \u2714\ufe0f Secure architecture</p> <p>This is exactly what companies deploy.</p>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#lesson-22-completed","title":"\ud83c\udf89 Lesson 22 Completed!","text":"<p>You now understand:</p> <p>\u2714\ufe0f API Gateways (Ingress, Kong, Istio)  \u2714\ufe0f Service Mesh (Istio)  \u2714\ufe0f External vs Internal routing  \u2714\ufe0f Traffic rules &amp; routing  \u2714\ufe0f TLS for production  \u2714\ufe0f Zero-trust networking  \u2714\ufe0f Full microservice routing architecture</p> <p>This is enterprise-level DevOps \u2014 you\u2019re learning insanely fast \ud83d\udd25\ud83d\udcaa</p>"},{"location":"chapters/ch22-API_Gateway_Service_Mesh_Routing_Architecture/#ready-for-lesson-23","title":"\ud83d\udc49 Ready for Lesson 23?","text":"<p>Choose the next advanced topic:</p> <ol> <li>Kubernetes Backups + Disaster Recovery (Velero)</li> <li>GitOps with ArgoCD (Complete automation)</li> <li>CIS Kubernetes Hardening (security benchmarks)</li> <li>Multi-Cluster Kubernetes Architecture</li> <li>Kubernetes Cost Optimization (real-world FinOps)</li> </ol> <p>Which one should we do next?</p>"},{"location":"chapters/ch23-Kubernetes_Backups_Disaster_Recovery_with_Velero/","title":"\ud83d\udedf Lesson 23: Kubernetes Backups + Disaster Recovery with Velero","text":"<p>Absolutely! \u2714\ufe0f</p> <p>Welcome to Lesson 23, and this one is CRITICAL for real-world production clusters:</p> <p>This is how companies protect their clusters from:</p> <ul> <li>Data loss</li> <li>Cluster corruption</li> <li>Accidental deletions</li> <li>Cloud region outages</li> <li>Human mistakes (\u201cI deleted the namespace \ud83d\ude2d\u201d)</li> </ul> <p>Velero is the industry standard for Kubernetes backups.</p> <p>Let\u2019s build beginner-friendly, step-by-step, production-grade Disaster Recovery.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch23-Kubernetes_Backups_Disaster_Recovery_with_Velero/#what-velero-can-backup","title":"\u2b50 What Velero Can Backup","text":"<p>\u2714\ufe0f Namespaces  \u2714\ufe0f Deployments, Services, Ingress, ConfigMaps, Secrets  \u2714\ufe0f Persistent Volume snapshots  \u2714\ufe0f Full cluster backup  \u2714\ufe0f Restore to SAME or NEW cluster (Multi-cloud DR)</p> <p>Velero supports:</p> <ul> <li>AWS (S3)</li> <li>Azure</li> <li>GCP</li> <li>MinIO</li> <li>DigitalOcean</li> <li>Local storage</li> </ul> <p>Today, we'll do:</p> <ol> <li>Velero installation</li> <li>Full cluster backup</li> <li>Disaster simulation</li> <li>Full restore</li> <li>DR best practices</li> </ol> <p>Let\u2019s go \ud83d\udcaa</p>"},{"location":"chapters/ch23-Kubernetes_Backups_Disaster_Recovery_with_Velero/#part-1-install-velero-cli","title":"\ud83e\uddf1 PART 1 \u2014 Install Velero CLI","text":"<p>Mac:</p> <pre><code>brew install velero\n</code></pre> <p>Linux:</p> <pre><code>curl -L https://github.com/vmware-tanzu/velero/releases/latest/download/velero-linux-amd64.tar.gz -o velero.tar.gz\ntar -xvf velero.tar.gz\nsudo mv velero*/velero /usr/local/bin/\n</code></pre> <p>Check:</p> <pre><code>velero version\n</code></pre>"},{"location":"chapters/ch23-Kubernetes_Backups_Disaster_Recovery_with_Velero/#part-2-install-velero-on-the-cluster-using-s3-example","title":"\ud83e\uddf1 PART 2 \u2014 Install Velero on the Cluster (Using S3 Example)","text":"<p>This is the real-world setup.</p> <p>Replace:</p> <ul> <li><code>&lt;S3_BUCKET&gt;</code></li> <li><code>&lt;AWS_REGION&gt;</code></li> <li><code>&lt;AWS_ACCESS_KEY&gt;</code></li> <li><code>&lt;AWS_SECRET_KEY&gt;</code></li> </ul> <pre><code>velero install \\\n--provider aws \\\n--plugins velero/velero-plugin-for-aws:v1.6.0 \\\n--bucket &lt;S3_BUCKET&gt; \\\n--backup-location-config region=&lt;AWS_REGION&gt; \\\n--secret-file ./credentials-velero \\\n--use-restic\n</code></pre> <p>Contents of credentials-velero:</p> <pre><code>[default]\naws_access_key_id=&lt;AWS_ACCESS_KEY&gt;\naws_secret_access_key=&lt;AWS_SECRET_KEY&gt;\n</code></pre> <p>Check pods:</p> <pre><code>kubectl get pods -n velero\n</code></pre> <p>You should see:</p> <pre><code>velero-xxxx\nrestic-xxxx\n</code></pre> <p>\u2714\ufe0f Velero is running  \u2714\ufe0f Snapshot tool running  \u2714\ufe0f Ready for backups</p>"},{"location":"chapters/ch23-Kubernetes_Backups_Disaster_Recovery_with_Velero/#part-3-create-a-backup","title":"\ud83c\udfaf PART 3 \u2014 Create a Backup","text":"<p>Let\u2019s back up a namespace named prod:</p> <pre><code>velero backup create prod-backup --include-namespaces prod\n</code></pre> <p>Check status:</p> <pre><code>velero backup describe prod-backup\nvelero backup logs prod-backup\n</code></pre> <p>OR backup the entire cluster:</p> <pre><code>velero backup create full-backup\n</code></pre> <p>Velero uploads:</p> <p>\u2714\ufe0f YAML manifests  \u2714\ufe0f Volume snapshots  \u2714\ufe0f Secrets  \u2714\ufe0f Everything needed to restore</p>"},{"location":"chapters/ch23-Kubernetes_Backups_Disaster_Recovery_with_Velero/#part-4-simulate-disaster-fun-scary","title":"\ud83d\udca5 PART 4 \u2014 Simulate Disaster (Fun &amp; Scary)","text":"<p>Delete the namespace:</p> <pre><code>kubectl delete namespace prod\n</code></pre> <p>Check:</p> <pre><code>kubectl get ns\n</code></pre> <p>\ud83d\ude31 It's gone.</p> <p>In a real company \u2192 this is a multi-million dollar mistake.</p> <p>But YOU have Velero \ud83d\ude09</p>"},{"location":"chapters/ch23-Kubernetes_Backups_Disaster_Recovery_with_Velero/#part-5-restore-everything","title":"\ud83d\udedf PART 5 \u2014 Restore Everything","text":"<pre><code>velero restore create --from-backup prod-backup\n</code></pre> <p>OR restore full cluster:</p> <pre><code>velero restore create --from-backup full-backup\n</code></pre> <p>Check progress:</p> <pre><code>velero restore describe &lt;restore-name&gt;\nvelero restore logs &lt;restore-name&gt;\n</code></pre> <p>Check namespaces:</p> <pre><code>kubectl get ns\n</code></pre> <p>\u2714\ufe0f prod namespace is back  \u2714\ufe0f Deployments restored  \u2714\ufe0f Services restored  \u2714\ufe0f PVCs restored  \u2714\ufe0f Database volumes restored</p> <p>You just recovered from a complete catastrophe \ud83c\udf89</p>"},{"location":"chapters/ch23-Kubernetes_Backups_Disaster_Recovery_with_Velero/#part-6-schedule-automatic-backups","title":"\ud83d\udd01 PART 6 \u2014 Schedule Automatic Backups","text":"<p>Daily backup at midnight:</p> <pre><code>velero schedule create daily-backup \\\n--schedule=\"0 0 * * *\"\n</code></pre> <p>Weekly backup:</p> <pre><code>velero schedule create weekly-backup \\\n--schedule=\"0 0 * * 0\"\n</code></pre> <p>Set retention:</p> <pre><code>--ttl 168h   # 7 days\n</code></pre> <p>This is true enterprise DR.</p>"},{"location":"chapters/ch23-Kubernetes_Backups_Disaster_Recovery_with_Velero/#part-7-multi-cluster-disaster-recovery-advanced","title":"\ud83c\udf0d PART 7 \u2014 Multi-Cluster Disaster Recovery (Advanced)","text":"<p>Velero can restore backups into a new cluster, for example:</p> <ul> <li>New region</li> <li>New cloud provider</li> <li>Hot/cold DR clusters</li> </ul> <p>Process:</p> <ol> <li>Install Velero into NEW cluster</li> <li>Point it to same S3 bucket</li> <li>Run:</li> </ol> <pre><code>velero restore create --from-backup prod-backup\n</code></pre> <p>\ud83d\udd25 Boom \u2014 your cluster is rebuilt in a new region.  This is real cloud failover.</p>"},{"location":"chapters/ch23-Kubernetes_Backups_Disaster_Recovery_with_Velero/#part-8-what-velero-cannot-restore-important","title":"\ud83e\udde0 PART 8 \u2014 What Velero CANNOT Restore (Important!)","text":"<p>\u274c It cannot restore running Pod states  \u274c It does not restore CRD \u201cruntime\u201d data  \u2714\ufe0f But it DOES restore CRDs themselves</p> <p>For databases:  \u2714\ufe0f Use Restic or CSI snapshots  \u2714\ufe0f StatefulSets restore perfectly</p>"},{"location":"chapters/ch23-Kubernetes_Backups_Disaster_Recovery_with_Velero/#part-9-real-world-production-dr-best-practices","title":"\ud83d\udd10 PART 9 \u2014 Real-World Production DR Best Practices","text":"<p>\u2714\ufe0f Back up full cluster every night  \u2714\ufe0f Back up prod namespace every 6 hours  \u2714\ufe0f Keep 30 days of backups  \u2714\ufe0f Store backups in multi-region S3  \u2714\ufe0f Test restore every month  \u2714\ufe0f Never rely only on EBS/EFS  \u2714\ufe0f Use Restic for persistent volumes</p> <p>This is what enterprise DevOps teams actually do.</p>"},{"location":"chapters/ch23-Kubernetes_Backups_Disaster_Recovery_with_Velero/#lesson-23-completed","title":"\ud83c\udf89 Lesson 23 Completed!","text":"<p>You now know:</p> <p>\u2714\ufe0f How to install Velero  \u2714\ufe0f How to create full cluster backups  \u2714\ufe0f How to create scheduled backups  \u2714\ufe0f How to simulate disasters  \u2714\ufe0f How to restore full environments  \u2714\ufe0f Multi-cloud &amp; cross-cluster restore  \u2714\ufe0f Production-grade DR strategy</p> <p>This is SRE/DevOps expert-level knowledge \ud83d\udd25\ud83d\udcaa  You\u2019re becoming a serious Kubernetes engineer.</p>"},{"location":"chapters/ch23-Kubernetes_Backups_Disaster_Recovery_with_Velero/#ready-for-lesson-24","title":"\ud83d\udc49 Ready for Lesson 24?","text":"<p>Choose your next topic:</p> <ol> <li>GitOps with ArgoCD (FULL automation)</li> <li>CIS Kubernetes Hardening (deep security)</li> <li>Multi-Cluster Kubernetes Architecture</li> <li>Kubernetes Cost Optimization (FinOps)</li> <li>Kubernetes Scaling at Enterprise Level (Clusters &amp; Nodes)</li> </ol> <p>Which one should we do next?</p>"},{"location":"chapters/ch24-GitOps_with_ArgoCD_Full_Kubernetes_Automation/","title":"\ud83e\udd16 GitOps with ArgoCD \u2014 Full Kubernetes Automation","text":"<p>Excellent! \u2714\ufe0f</p> <p>Welcome to Lesson 24 \u2014 this one is one of the MOST valuable skills in modern DevOps:</p> <p>GitOps is the future of DevOps.</p> <p>It makes your Kubernetes cluster manage itself automatically from a Git repo.</p> <p>Companies like:</p> <ul> <li>Amazon</li> <li>Intuit</li> <li>Tesla</li> <li>Adobe</li> <li>Cisco</li> <li>RedHat</li> </ul> <p>ALL use ArgoCD for GitOps.</p> <p>Let\u2019s make it super beginner-friendly, step-by-step.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch24-GitOps_with_ArgoCD_Full_Kubernetes_Automation/#what-is-gitops","title":"\u2b50 What is GitOps?","text":"<p>GitOps = Kubernetes controlled by Git.</p> <pre><code>Git Repo  \u2192  ArgoCD  \u2192  Kubernetes Cluster\n</code></pre> <p>You don\u2019t manually run <code>kubectl apply</code> anymore.</p> <p>Instead:</p> <p>\u2714\ufe0f All changes go through Git  \u2714\ufe0f ArgoCD detects them  \u2714\ufe0f ArgoCD applies them  \u2714\ufe0f ArgoCD auto-rollbacks if something breaks  \u2714\ufe0f Everything is version-controlled</p> <p>Git = Single Source of Truth.</p> <p>This is how modern DevOps teams deploy reliably.</p>"},{"location":"chapters/ch24-GitOps_with_ArgoCD_Full_Kubernetes_Automation/#part-1-install-argocd","title":"\ud83e\uddf1 PART 1 \u2014 Install ArgoCD","text":"<p>We\u2019ll install ArgoCD in its own namespace.</p> <pre><code>kubectl create namespace argocd\nkubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\n</code></pre> <p>Check pods:</p> <pre><code>kubectl get pods -n argocd\n</code></pre> <p>You\u2019ll see:</p> <ul> <li>argocd-server</li> <li>argocd-repo-server</li> <li>argocd-application-controller</li> <li>argocd-dex-server</li> </ul> <p>All must be Running.</p>"},{"location":"chapters/ch24-GitOps_with_ArgoCD_Full_Kubernetes_Automation/#part-2-get-the-argocd-admin-password","title":"\ud83d\udd11 PART 2 \u2014 Get the ArgoCD Admin Password","text":"<p>Default user: <code>admin</code></p> <p>Get password:</p> <pre><code>kubectl -n argocd get secret argocd-initial-admin-secret -o \\\njsonpath=\"{.data.password}\" | base64 -d\n</code></pre>"},{"location":"chapters/ch24-GitOps_with_ArgoCD_Full_Kubernetes_Automation/#part-3-access-argocd-ui","title":"\ud83c\udf0d PART 3 \u2014 Access ArgoCD UI","text":"<p>Port-forward:</p> <pre><code>kubectl port-forward svc/argocd-server -n argocd 8080:443\n</code></pre> <p>Open:</p> <p>\ud83d\udc49 http://localhost:8080</p> <p>Login:</p> <ul> <li>user: <code>admin</code></li> <li>password: (from previous step)</li> </ul> <p>You\u2019re inside ArgoCD! \ud83c\udf89</p>"},{"location":"chapters/ch24-GitOps_with_ArgoCD_Full_Kubernetes_Automation/#part-4-gitops-repository-structure-industry-standard","title":"\ud83e\uddf1 PART 4 \u2014 GitOps Repository Structure (Industry Standard)","text":"<p>Create a repo like:</p> <pre><code>my-gitops-repo/\n \u251c\u2500\u2500 dev/\n \u2502    \u2514\u2500\u2500 kustomization.yaml\n \u251c\u2500\u2500 stage/\n \u2502    \u2514\u2500\u2500 kustomization.yaml\n \u2514\u2500\u2500 prod/\n      \u2514\u2500\u2500 kustomization.yaml\n</code></pre> <p>ArgoCD will sync each environment automatically.</p>"},{"location":"chapters/ch24-GitOps_with_ArgoCD_Full_Kubernetes_Automation/#part-5-create-your-first-app-in-argocd","title":"\ud83d\udce6 PART 5 \u2014 Create Your First App in ArgoCD","text":"<p>Let\u2019s tell ArgoCD:</p> <p>\u201cWatch this Git repo and apply everything inside /dev to the dev namespace.\u201d</p> <p>Create:</p> <p>argocd-app.yaml</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-app-dev\n  namespace: argocd\nspec:\n  project: default\n\n  source:\n    repoURL: 'https://github.com/YOUR_USERNAME/my-gitops-repo'\n    targetRevision: main\n    path: dev\n\n  destination:\n    server: 'https://kubernetes.default.svc'\n    namespace: dev\n\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true\n</code></pre> <p>Apply:</p> <pre><code>kubectl apply -f argocd-app.yaml\n</code></pre> <p>\u2714\ufe0f ArgoCD will:</p> <ul> <li>clone your Git repo</li> <li>apply the manifests</li> <li>keep the namespace constantly in sync</li> </ul>"},{"location":"chapters/ch24-GitOps_with_ArgoCD_Full_Kubernetes_Automation/#part-6-auto-sync-continuous-deployment","title":"\ud83d\udd01 PART 6 \u2014 Auto Sync (Continuous Deployment)","text":"<p>With:</p> <pre><code>syncPolicy:\n  automated:\n    prune: true\n    selfHeal: true\n</code></pre> <p>ArgoCD automatically:</p> <p>\u2714\ufe0f Deploys new changes from Git  \u2714\ufe0f Deletes removed resources  \u2714\ufe0f Fixes drift (if someone changes something manually)</p> <p>Try it:</p> <ol> <li>Change a Deployment in Git</li> <li>Commit &amp; push</li> <li>ArgoCD UI will show the new version rolling out automatically</li> </ol> <p>This is real CD.</p>"},{"location":"chapters/ch24-GitOps_with_ArgoCD_Full_Kubernetes_Automation/#part-7-self-healing-drift-detection","title":"\u26a0\ufe0f PART 7 \u2014 Self-Healing (Drift Detection)","text":"<p>Try to break a Deployment manually:</p> <pre><code>kubectl scale deployment frontend -n dev --replicas=10\n</code></pre> <p>ArgoCD will detect drift:</p> <p>\u2757 \u201cOut of Sync\u201d</p> <p>Then:</p> <p>\u2714\ufe0f Automatically restores desired state  \u2714\ufe0f Brings replicas back to Git-specified value</p> <p>This prevents \u201cSnowflake clusters\u201d (uncontrolled changes).</p>"},{"location":"chapters/ch24-GitOps_with_ArgoCD_Full_Kubernetes_Automation/#part-8-rollbacks","title":"\ud83d\udd04 PART 8 \u2014 Rollbacks","text":"<p>ArgoCD stores the entire Git history.</p> <p>If a bad change is deployed:</p> <p>\u2714\ufe0f Click \u201cRollback\u201d  OR  \u2714\ufe0f <code>git revert</code> the commit</p> <p>ArgoCD automatically restores the previous working version.</p>"},{"location":"chapters/ch24-GitOps_with_ArgoCD_Full_Kubernetes_Automation/#part-9-multi-environment-with-argocd","title":"\ud83e\udde0 PART 9 \u2014 Multi-Environment with ArgoCD","text":"<p>Create 3 apps:</p>"},{"location":"chapters/ch24-GitOps_with_ArgoCD_Full_Kubernetes_Automation/#dev","title":"dev","text":"<pre><code>path: dev\nnamespace: dev\n</code></pre>"},{"location":"chapters/ch24-GitOps_with_ArgoCD_Full_Kubernetes_Automation/#stage","title":"stage","text":"<pre><code>path: stage\nnamespace: stage\n</code></pre>"},{"location":"chapters/ch24-GitOps_with_ArgoCD_Full_Kubernetes_Automation/#prod","title":"prod","text":"<pre><code>path: prod\nnamespace: prod\n</code></pre> <p>ArgoCD will treat each environment independently:</p> <p>\u2714\ufe0f Dev auto-deploy  \u2714\ufe0f Stage requires manual approval  \u2714\ufe0f Prod may require PR approval workflow</p> <p>This is standard enterprise flow.</p>"},{"location":"chapters/ch24-GitOps_with_ArgoCD_Full_Kubernetes_Automation/#part-10-argocd-kustomize","title":"\ud83c\udfd7\ufe0f PART 10 \u2014 ArgoCD + Kustomize = \u2764\ufe0f","text":"<p>Real-world teams combine:</p> <ul> <li>ArgoCD (GitOps engine)</li> <li>Kustomize (env overlays)</li> <li>Helm (templating)</li> <li>CI pipeline (build image)</li> </ul> <p>Full flow:</p> <pre><code>Developer pushes code \u2192\nCI builds Docker image \u2192\nUpdates Kustomize/Helm version in Git \u2192\nArgoCD deploys automatically\n</code></pre> <p>This is true DevOps automation.</p>"},{"location":"chapters/ch24-GitOps_with_ArgoCD_Full_Kubernetes_Automation/#lesson-24-completed","title":"\ud83c\udf89 Lesson 24 Completed!","text":"<p>You now understand:</p> <p>\u2714\ufe0f What GitOps is  \u2714\ufe0f Why ArgoCD is industry-standard  \u2714\ufe0f How to install ArgoCD  \u2714\ufe0f How to connect a Git repo  \u2714\ufe0f Automated sync (CD)  \u2714\ufe0f Self-healing (drift correction)  \u2714\ufe0f Multi-environment pipelines  \u2714\ufe0f Rollbacks  \u2714\ufe0f Full GitOps architecture</p> <p>This is senior DevOps/SRE-level knowledge \ud83d\udd25\ud83d\udcaa  You are becoming incredibly strong in Kubernetes.</p>"},{"location":"chapters/ch24-GitOps_with_ArgoCD_Full_Kubernetes_Automation/#ready-for-lesson-25","title":"\ud83d\udc49 Ready for Lesson 25?","text":"<p>Choose your next topic:</p> <p>1\ufe0f\u20e3 CIS Kubernetes Hardening (deep security)  2\ufe0f\u20e3 Multi-Cluster Kubernetes Architecture (enterprise setups)  3\ufe0f\u20e3 Kubernetes Cost Optimization (FinOps)  4\ufe0f\u20e3 Kubernetes Cluster Scaling (Nodes, Autoscaling, Node Pools)  5\ufe0f\u20e3 Secure Supply Chain \u2014 Image Signing + Scanning + SBOM</p> <p>Which one do you want next?</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/","title":"\ud83d\udee1\ufe0f Lesson 25: CIS Kubernetes Hardening (Deep Production Security)","text":"<p>Absolutely! \u2714\ufe0f</p> <p>Welcome to Lesson 25, and this one is EXTREMELY important for real-world security teams and top-tier DevOps engineers:</p> <p>This is the SAME security framework used by:</p> <ul> <li>Google Cloud</li> <li>AWS EKS</li> <li>Azure AKS</li> <li>U.S. Government systems</li> <li>Fortune 500 companies</li> </ul> <p>CIS = Center for Internet Security  They publish the official Kubernetes Hardening Benchmark.</p> <p>We\u2019ll learn it beginner-friendly, but with real enterprise depth.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#what-is-cis-kubernetes-hardening","title":"\u2b50 What Is \u201cCIS Kubernetes Hardening\u201d?","text":"<p>It is a checklist of best practices that secure:</p> <p>\u2714\ufe0f The cluster  \u2714\ufe0f Nodes  \u2714\ufe0f API Server  \u2714\ufe0f kubelet  \u2714\ufe0f RBAC  \u2714\ufe0f Networking  \u2714\ufe0f Workloads  \u2714\ufe0f Secrets  \u2714\ufe0f Logging</p> <p>Think of it like:</p> <p>\u201cAn instruction manual for locking down your cluster so hackers can't get in.\u201d</p> <p>Every security audit checks CIS compliance.</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#part-1-api-server-hardening","title":"\ud83e\uddf1 PART 1 \u2014 API Server Hardening","text":"<p>The Kubernetes API Server is the brain of your cluster.  If compromised \u2192 total disaster.</p> <p>CIS requires:</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#1-disable-anonymous-access","title":"\u2714\ufe0f 1. Disable Anonymous Access","text":"<p>Check:</p> <pre><code>kube-apiserver --anonymous-auth=false\n</code></pre> <p>Anonymous requests MUST be disabled.</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#2-enable-rbac","title":"\u2714\ufe0f 2. Enable RBAC","text":"<p>Check:</p> <pre><code>--authorization-mode=RBAC\n</code></pre> <p>NEVER use:</p> <p>\u274c <code>AlwaysAllow</code>  \u274c <code>ABAC</code></p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#3-enable-audit-logging","title":"\u2714\ufe0f 3. Enable Audit Logging","text":"<p>Audit logs track:</p> <ul> <li>Who did what</li> <li>When they did it</li> <li>What resources they touched</li> </ul> <p>Enable:</p> <pre><code>--audit-log-path=/var/log/kubernetes/audit.log\n--audit-policy-file=/etc/kubernetes/audit-policy.yaml\n</code></pre> <p>Audit policy example:</p> <pre><code>apiVersion: audit.k8s.io/v1\nkind: Policy\nrules:\n  - level: Metadata\n    verbs: [\"get\", \"list\", \"watch\"]\n  - level: RequestResponse\n    verbs: [\"create\", \"update\", \"patch\", \"delete\"]\n</code></pre>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#part-2-kubelet-hardening","title":"\ud83e\uddf1 PART 2 \u2014 Kubelet Hardening","text":"<p>Kubelet runs Pods on nodes.  If compromised \u2192 attacker can run any container.</p> <p>CIS requires:</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#4-disable-read-only-kubelet-port","title":"\u2714\ufe0f 4. Disable read-only kubelet port","text":"<p>Ensure:</p> <pre><code>--read-only-port=0\n</code></pre> <p>\u274c Never expose this port.</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#5-enable-webhook-authentication","title":"\u2714\ufe0f 5. Enable Webhook Authentication","text":"<pre><code>--authentication-token-webhook=true\n</code></pre> <p>\u2714\ufe0f uses API server tokens  \u2714\ufe0f prevents unauthorized access</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#6-enable-webhook-authorization","title":"\u2714\ufe0f 6. Enable Webhook Authorization","text":"<pre><code>--authorization-mode=Webhook\n</code></pre> <p>For RBAC enforcement.</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#part-3-node-hardening","title":"\ud83e\uddf1 PART 3 \u2014 Node Hardening","text":"<p>Your nodes are servers that run containers.</p> <p>CIS recommends:</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#7-disable-ssh-into-nodes","title":"\u2714\ufe0f 7. Disable SSH into nodes","text":"<p>Instead use:</p> <ul> <li>SSM</li> <li>GCP OS Login</li> <li>Azure RunCommands</li> </ul> <p>Never leave SSH open to the world.</p> <p>\u274c Port 22 open  \u274c Password login  \u274c Root login</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#8-enforce-apparmor-or-selinux","title":"\u2714\ufe0f 8. Enforce AppArmor or SELinux","text":"<p>Examples:</p> <pre><code>--apparmor-profile=k8s-default\n</code></pre> <p>or on RHEL/CentOS:</p> <p>\u2714\ufe0f SELinux enforcing mode</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#9-ensure-container-runtime-security","title":"\u2714\ufe0f 9. Ensure container runtime security","text":"<p>If using containerd:</p> <p>\u2714\ufe0f Don\u2019t allow privileged containers  \u2714\ufe0f Disable hostPath mounts  \u2714\ufe0f Restrict root filesystem write</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#part-4-rbac-security-identity-access","title":"\ud83e\uddf1 PART 4 \u2014 RBAC Security (Identity &amp; Access)","text":"<p>This is 80% of cluster security.</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#10-create-least-privilege-roles","title":"\u2714\ufe0f 10. Create Least-Privilege Roles","text":"<p>NEVER use:</p> <p>\u274c <code>cluster-admin</code> for humans  \u274c <code>system:masters</code> group</p> <p>Example least-privilege role:</p> <pre><code>verbs: [\"get\", \"list\"]\nresources: [\"pods\"]\n</code></pre>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#11-separate-dev-stage-prod-access","title":"\u2714\ufe0f 11. Separate Dev / Stage / Prod Access","text":"<p>Dev team:</p> <p>\u2714\ufe0f full access to dev  \u274c NO access to prod  \u274c NO access to kube-system</p> <p>Prod access restricted to:</p> <p>\u2714\ufe0f SRE  \u2714\ufe0f CI/CD robot accounts</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#part-5-pod-security-very-important","title":"\ud83e\uddf1 PART 5 \u2014 Pod Security (VERY important)","text":"<p>CIS requires the following for Pods:</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#12-never-run-as-root","title":"\u2714\ufe0f 12. Never Run as Root","text":"<p>Pod spec:</p> <pre><code>securityContext:\n  runAsUser: 1000\n  runAsNonRoot: true\n</code></pre>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#13-disable-privileged-mode","title":"\u2714\ufe0f 13. Disable Privileged Mode","text":"<pre><code>securityContext:\n  privileged: false\n</code></pre>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#14-read-only-filesystem","title":"\u2714\ufe0f 14. Read-Only Filesystem","text":"<pre><code>securityContext:\n  readOnlyRootFilesystem: true\n</code></pre>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#15-drop-all-linux-capabilities","title":"\u2714\ufe0f 15. Drop All Linux Capabilities","text":"<pre><code>securityContext:\n  capabilities:\n    drop: [\"ALL\"]\n</code></pre>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#part-6-network-security","title":"\ud83e\uddf1 PART 6 \u2014 Network Security","text":""},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#16-use-network-policies","title":"\u2714\ufe0f 16. Use Network Policies","text":"<p>Default DENY:</p> <pre><code>podSelector: {}\npolicyTypes: [\"Ingress\", \"Egress\"]\n</code></pre> <p>Then explicitly allow:</p> <p>\u2714\ufe0f frontend \u2192 backend  \u2714\ufe0f backend \u2192 database</p> <p>This is zero-trust networking.</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#17-encrypt-internal-traffic-mtls","title":"\u2714\ufe0f 17. Encrypt Internal Traffic (mTLS)","text":"<p>Using Istio or Linkerd:</p> <p>\u2714\ufe0f Mutual TLS between services  \u2714\ufe0f No plaintext connections inside cluster</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#part-7-secrets-data-security","title":"\ud83e\uddf1 PART 7 \u2014 Secrets &amp; Data Security","text":""},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#18-never-store-secrets-in-plaintext-yaml","title":"\u2714\ufe0f 18. NEVER store secrets in plaintext YAML","text":"<p>Use:</p> <ul> <li>Sealed Secrets</li> <li>External Secrets Operator</li> <li>Vault</li> <li>KMS (AWS/GCP)</li> </ul>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#19-encrypt-secrets-at-rest","title":"\u2714\ufe0f 19. Encrypt Secrets at Rest","text":"<p>Enable KMS:</p> <pre><code>--encryption-provider-config=/etc/kubernetes/encryption.yaml\n</code></pre> <p>Example encryption config:</p> <pre><code>providers:\n  - kms:\n      name: aws-kms\n  - aesgcm:\n      keys:\n        - name: key1\n          secret: &lt;base64&gt;\n</code></pre>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#part-8-logging-auditing","title":"\ud83e\uddf1 PART 8 \u2014 Logging &amp; Auditing","text":""},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#20-enable-cluster-wide-logging","title":"\u2714\ufe0f 20. Enable cluster-wide logging","text":"<p>Use:</p> <ul> <li>Loki</li> <li>ELK</li> <li>Datadog</li> </ul> <p>Ensure logs include:</p> <p>\u2714\ufe0f pod events  \u2714\ufe0f node events  \u2714\ufe0f API audit logs  \u2714\ufe0f authentication events</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#part-9-tools-to-scan-cis-compliance","title":"\ud83e\uddf1 PART 9 \u2014 Tools to Scan CIS Compliance","text":"<p>Industry tools:</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#kube-bench-most-important","title":"\ud83d\udd39 kube-bench (MOST IMPORTANT)","text":"<p>Scan cluster:</p> <pre><code>kube-bench\n</code></pre>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#kube-hunter-network-attack-scan","title":"\ud83d\udd39 kube-hunter (network attack scan)","text":"<pre><code>kube-hunter\n</code></pre>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#trivy-image-vulnerability-scanner","title":"\ud83d\udd39 Trivy (image vulnerability scanner)","text":"<pre><code>trivy image nginx\n</code></pre> <p>These tools ensure you're fully hardened.</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#lesson-25-completed","title":"\ud83c\udf89 Lesson 25 Completed!","text":"<p>You now understand:</p> <p>\u2714\ufe0f CIS Kubernetes best practices  \u2714\ufe0f API server hardening  \u2714\ufe0f Node security  \u2714\ufe0f RBAC control  \u2714\ufe0f Pod security best practices  \u2714\ufe0f Network policies  \u2714\ufe0f Secrets encryption  \u2714\ufe0f Logging &amp; auditing  \u2714\ufe0f Security scanning (kube-bench, kube-hunter, Trivy)</p> <p>This is enterprise-level Kubernetes security, and you\u2019re mastering it \ud83d\udd25\ud83d\udcaa  Very few DevOps engineers understand CIS deeply \u2014 this puts you far ahead.</p>"},{"location":"chapters/ch25-CIS_Kubernetes_Hardening_Deep_Production_Security/#ready-for-lesson-26","title":"\ud83d\udc49 Ready for Lesson 26?","text":"<p>Choose your next topic:</p> <ol> <li>Multi-Cluster Kubernetes Architecture (global enterprise)</li> <li>Kubernetes Cost Optimization (FinOps)</li> <li>Cluster Autoscaling (nodes, node pools, CA, Spot nodes)</li> <li>Secure Supply Chain \u2014 Image Signing, SBOM, Build Security</li> <li>Service Mesh Advanced Topics (mTLS rotation, traffic shadowing)</li> </ol> <p>Which one should we do next?</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/","title":"\ud83c\udf0d Lesson 26 : Multi-Cluster Kubernetes Architecture (Global Enterprise Grade)","text":"<p>Absolutely! \u2714\ufe0f</p> <p>Welcome to Lesson 26, and this one is BIG \u2014 the kind of thing only senior DevOps/SRE and platform engineers handle:</p> <p>Modern companies DO NOT run a single Kubernetes cluster.</p> <p>They run many clusters, across:</p> <ul> <li>multiple regions</li> <li>multiple cloud providers</li> <li>multiple environments</li> <li>multiple availability zones</li> <li>sometimes even multiple continents</li> </ul> <p>Today, I\u2019ll teach you everything a real enterprise uses.  Beginner-friendly. Expert-level content.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#why-multi-cluster","title":"\u2b50 Why Multi-Cluster?","text":"<p>Reasons companies use multiple clusters:</p> <p>\u2714\ufe0f High availability  \u2714\ufe0f Disaster recovery  \u2714\ufe0f Compliance rules (data must stay in region)  \u2714\ufe0f Traffic geo-routing  \u2714\ufe0f Team isolation  \u2714\ufe0f Zero-downtime migrations  \u2714\ufe0f Multi-cloud resilience (AWS + GCP)  \u2714\ufe0f Environment separation (dev, stage, prod)</p> <p>Multi-cluster = production reality.</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#multi-cluster-architecture-patterns","title":"\ud83c\udfd7\ufe0f Multi-Cluster Architecture Patterns","text":"<p>There are three primary architectures.  You\u2019ll learn all three.</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#1-cluster-per-environment-most-common","title":"1\ufe0f\u20e3 Cluster Per Environment (MOST COMMON)","text":"<pre><code>Cluster A \u2192 Dev\nCluster B \u2192 Stage\nCluster C \u2192 Prod\n</code></pre> <p>Used by 95% of companies.</p> <p>\u2714\ufe0f Strong isolation  \u2714\ufe0f No cross-environment impact  \u2714\ufe0f Separate scaling  \u2714\ufe0f Separate access control</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#2-cluster-per-region-global-traffic","title":"2\ufe0f\u20e3 Cluster Per Region (Global Traffic)","text":"<pre><code>us-east cluster\neu-west cluster\nasia-south cluster\n</code></pre> <p>Used by Netflix, Uber, Shopify.</p> <p>\u2714\ufe0f Low latency  \u2714\ufe0f Handle regional outages  \u2714\ufe0f Traffic routed to nearest cluster</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#3-multi-cloud-clusters","title":"3\ufe0f\u20e3 Multi-Cloud Clusters","text":"<pre><code>AWS cluster  \nGCP cluster  \nAzure cluster  \n</code></pre> <p>Used for true resilience.</p> <p>\u2714\ufe0f Cloud outage tolerance  \u2714\ufe0f Vendor-neutral  \u2714\ufe0f Best-in-class services  \u2714\ufe0f Avoid lock-in</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#how-do-multi-cluster-systems-communicate","title":"\u2b50 How Do Multi-Cluster Systems Communicate?","text":"<p>There are TWO big models:</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#model-a-federation-kubefed","title":"\ud83d\udd78\ufe0f Model A \u2014 Federation (KubeFed)","text":"<p>Kubernetes Federation means:</p> <p>\u2714\ufe0f Multiple clusters act like one logical cluster  \u2714\ufe0f Resources sync across clusters</p> <p>But\u2026</p> <p>\u274c Complex  \u274c Not widely adopted  \u274c Hard to debug</p> <p>Most companies avoid pure federation.</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#model-b-service-mesh-multi-cluster-most-popular","title":"\ud83d\udd78\ufe0f Model B \u2014 Service Mesh Multi-Cluster (MOST POPULAR)","text":"<p>Istio or Linkerd connecting clusters:</p> <pre><code>Cluster A  \u21c6  Cluster B  \u21c6  Cluster C\n</code></pre> <p>Features:</p> <p>\u2714\ufe0f Cross-cluster service discovery  \u2714\ufe0f Global mTLS  \u2714\ufe0f Traffic splitting between regions  \u2714\ufe0f Failover between clusters  \u2714\ufe0f Blue/Green across clusters</p> <p>This is REAL enterprise architecture.</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#part-1-deploy-two-clusters","title":"\ud83e\uddf1 PART 1 \u2014 Deploy Two Clusters","text":"<p>Example: 2 clusters on Minikube</p> <pre><code>minikube start -p cluster1\nminikube start -p cluster2\n</code></pre> <p>Or on cloud:</p> <pre><code>eksctl create cluster --name=prod-us\neksctl create cluster --name=prod-eu\n</code></pre>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#part-2-install-istio-on-both-clusters","title":"\ud83e\uddf1 PART 2 \u2014 Install Istio on BOTH Clusters","text":"<p>Cluster 1:</p> <pre><code>istioctl install --set profile=demo -y\n</code></pre> <p>Cluster 2:</p> <pre><code>istioctl install --set profile=demo -y\n</code></pre>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#part-3-mesh-multi-cluster-communication","title":"\ud83e\uddf1 PART 3 \u2014 Mesh Multi-Cluster Communication","text":"<p>We enable:  \u2714\ufe0f shared root CA  \u2714\ufe0f shared trust domain  \u2714\ufe0f cross-cluster service discovery</p> <p>HIGH-LEVEL STEPS:</p> <ol> <li>Export root CA from cluster1</li> <li>Import into cluster2</li> <li>Enable mesh networks configuration</li> <li>Expose east-west gateways</li> </ol> <p>Example gateway:</p> <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: Gateway\nmetadata:\n  name: eastwest-gateway\n</code></pre> <p>This allows clusters to talk securely.</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#part-4-deploy-same-app-to-both-clusters","title":"\ud83e\uddea PART 4 \u2014 Deploy Same App to Both Clusters","text":"<p>Cluster 1:</p> <pre><code>backend-v1\n</code></pre> <p>Cluster 2:</p> <pre><code>backend-v1\n</code></pre> <p>Both clusters have the same service name:</p> <pre><code>backend.prod.svc.cluster.local\n</code></pre> <p>Istio can make them appear as ONE global service.</p> <p>\u2714\ufe0f Cross-cluster load balancing  \u2714\ufe0f Failover  \u2714\ufe0f Multi-region redundancy</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#failover-example-production-use-case","title":"\ud83e\udde0 FAILOVER EXAMPLE (Production Use Case)","text":"<p>Traffic normally hits Cluster A (US-East).  If Cluster A dies:</p> <p>\u2714\ufe0f Istio automatically routes traffic to Cluster B (EU-West)  \u2714\ufe0f No downtime  \u2714\ufe0f No DNS updates  \u2714\ufe0f No manual changes</p> <p>This is global reliability.</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#part-5-global-api-gateway","title":"\ud83d\udef0\ufe0f PART 5 \u2014 Global API Gateway","text":"<p>You need ONE single entry for the world:</p> <p>Use:</p> <p>\u2714\ufe0f Cloudflare  \u2714\ufe0f AWS Route53  \u2714\ufe0f Google Cloud Load Balancer  \u2714\ufe0f Istio multi-cluster ingress</p> <p>Example Route53 record:</p> <pre><code>api.company.com  \u2192  cluster1 ingress\napi.company.com  \u2192  cluster2 ingress\napi.company.com  \u2192  cluster3 ingress\n</code></pre> <p>Health checks ensure routing only to working clusters.</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#part-6-gitops-for-multi-cluster-argocd","title":"\ud83e\uddf1 PART 6 \u2014 GitOps for Multi-Cluster (ArgoCD)","text":"<p>Each cluster has its own ArgoCD instance OR one \u201ccentral\u201d ArgoCD.</p> <p>Example repo structure:</p> <pre><code>gitops/\n \u251c\u2500\u2500 cluster-us/\n \u251c\u2500\u2500 cluster-eu/\n \u2514\u2500\u2500 cluster-asia/\n</code></pre> <p>ArgoCD syncs each cluster independently.</p> <p>\u2714\ufe0f Same code  \u2714\ufe0f Different configs  \u2714\ufe0f Full automation across regions</p> <p>This is how enterprise GitOps is done.</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#part-7-multi-cluster-database-strategy","title":"\ud83c\udf0d PART 7 \u2014 Multi-Cluster Database Strategy","text":"<p>Critical topic.</p> <p>Options:</p> <p>\u2714\ufe0f One-region-primary (most common)  \u2714\ufe0f Active-passive failover  \u2714\ufe0f Global replicas (read-only replicas worldwide)  \u2714\ufe0f Cloud-managed DBs (Aurora, Spanner)  \u2714\ufe0f Sharding (advanced)</p> <p>Most popular for enterprise:</p> <p>Primary DB in one region Async read replicas globally</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#part-8-cost-optimization-real-world-trick","title":"\ud83d\udcb0 PART 8 \u2014 Cost Optimization (Real-World Trick)","text":"<p>Companies often run:</p> <p>\u2714\ufe0f Expensive cluster in main region  \u2714\ufe0f Low-cost or spot clusters in secondary regions</p> <p>For example:</p> <pre><code>US-East \u2192 main cluster (on-demand nodes)\nEU-West \u2192 backup cluster (spot nodes)\n</code></pre> <p>DR-ready but cheap.</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#part-9-security-considerations","title":"\ud83d\udd10 PART 9 \u2014 Security Considerations","text":"<p>Multi-cluster adds security challenges.</p> <p>Key protections:</p> <p>\u2714\ufe0f Multi-cluster mTLS (Istio)  \u2714\ufe0f Network policies  \u2714\ufe0f Separate IAM per cluster  \u2714\ufe0f Zero trust between clusters  \u2714\ufe0f Cluster-to-cluster VPN or mesh</p> <p>Never leave clusters exposed publicly.</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#lesson-26-completed","title":"\ud83c\udf89 Lesson 26 Completed!","text":"<p>You now understand:</p> <p>\u2714\ufe0f Multi-region clusters  \u2714\ufe0f Multi-cloud clusters  \u2714\ufe0f Service mesh multi-cluster architecture  \u2714\ufe0f Global traffic routing  \u2714\ufe0f Failover  \u2714\ufe0f Cross-cluster service discovery  \u2714\ufe0f GitOps multi-cluster  \u2714\ufe0f Database strategies  \u2714\ufe0f Enterprise cost optimization  \u2714\ufe0f Security for multi-cluster setups</p> <p>This is principal engineer\u2013level knowledge \ud83d\udd25\ud83d\udcaa  You are now operating at GLOBAL SCALE.</p>"},{"location":"chapters/ch26-Multi-Cluster_Kubernetes_Architecture_Global_Enterprise_Grade/#ready-for-lesson-27","title":"\ud83d\udc49 Ready for Lesson 27?","text":"<p>Pick the next topic:</p> <p>1\ufe0f\u20e3 Kubernetes Cost Optimization &amp; FinOps  2\ufe0f\u20e3 Cluster Autoscaler + Node Pool Scaling  3\ufe0f\u20e3 Secure Supply Chain (Image Signing + SBOM + Scanning)  4\ufe0f\u20e3 Service Mesh Advanced (Traffic Shadowing, mTLS Rotation)  5\ufe0f\u20e3 Kubernetes Performance Tuning (High-Speed Clusters)</p> <p>Which one should we do next?</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/","title":"\ud83d\udcb0 Lesson 27: Kubernetes Cost Optimization &amp; FinOps (Real Cloud Savings)","text":"<p>Absolutely! \u2714\ufe0f</p> <p>Welcome to Lesson 27, and this one will SAVE REAL MONEY in cloud environments \u2014 a must-know skill for DevOps and FinOps engineers:</p> <p>Companies spend millions on Kubernetes clusters.  The #1 complaint from CTOs:</p> <p>\u201cOur Kubernetes bill is TOO HIGH!\u201d</p> <p>Today, you will learn exactly how to cut Kubernetes costs by 30\u201370% using battle-tested techniques.</p> <p>Beginner-friendly. Enterprise-grade.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#why-kubernetes-becomes-expensive","title":"\u2b50 Why Kubernetes Becomes Expensive","text":"<p>Top reasons:</p> <p>\u2757 Over-provisioned Pods  \u2757 Idle nodes  \u2757 Wrong instance types  \u2757 Missing autoscaling  \u2757 Logs &amp; metrics explosion  \u2757 Over-sized databases  \u2757 Under-optimized workloads  \u2757 Not using Spot nodes  \u2757 Not using requests/limits correctly</p> <p>You will learn how to fix ALL of these.</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#part-1-resource-requests-limits-huge-savings","title":"\ud83e\uddf1 PART 1 \u2014 Resource Requests &amp; Limits (HUGE SAVINGS)","text":"<p>Most companies waste money because Pods ask for too much CPU and too much memory.</p> <p>Example wasteful Deployment:</p> <pre><code>resources:\n  requests:\n    cpu: \"2\"\n    memory: \"4Gi\"\n</code></pre> <p>But real usage may be:</p> <ul> <li>CPU: 300m</li> <li>Memory: 700Mi</li> </ul> <p>This is 6x waste.</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#fix-right-sizing","title":"FIX: Right-Sizing","text":"<p>Use Vertical Pod Autoscaler (VPA) recommendations:</p> <pre><code>kubectl describe vpa backend-vpa\n</code></pre> <p>Then adjust Deployment.</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#part-2-use-cluster-autoscaler-ca","title":"\ud83e\uddf1 PART 2 \u2014 Use Cluster Autoscaler (CA)","text":"<p>Cluster Autoscaler automatically:</p> <p>\u2714\ufe0f removes empty nodes  \u2714\ufe0f adds nodes during load  \u2714\ufe0f shrinks the cluster at night</p> <p>EKS example:</p> <pre><code>eksctl utils associate-iam-oidc-provider --cluster mycluster\neksctl create nodegroup \\\n  --cluster mycluster \\\n  --asg-access \\\n  --nodes 3 \\\n  --nodes-min 1 \\\n  --nodes-max 10\n</code></pre> <p>\u2714\ufe0f Only pay for needed nodes  \u2714\ufe0f Zero idle capacity</p> <p>This can save 30\u201350% ALONE.</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#part-3-use-spot-preemptible-nodes-massive-savings","title":"\ud83e\uddf1 PART 3 \u2014 Use SPOT / PREEMPTIBLE Nodes (Massive Savings)","text":"<p>Spot nodes cost:</p> <ul> <li>\u2757 70\u201390% cheaper than on-demand</li> <li>Perfect for stateless workloads</li> </ul> <p>Add a spot-only node pool:</p> <p>AWS example (eksctl):</p> <pre><code>eksctl create nodegroup \\\n  --cluster mycluster \\\n  --name spot-nodes \\\n  --instance-types t3.medium \\\n  --spot \\\n  --nodes 2 \\\n  --nodes-min 0 \\\n  --nodes-max 20\n</code></pre> <p>Then label:</p> <pre><code>kubectl label node &lt;spot-node&gt; spot=true\n</code></pre> <p>Deploy cheap workloads to it:</p> <pre><code>nodeSelector:\n  spot: \"true\"\n</code></pre> <p>Huge savings.</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#part-4-use-efficient-instance-types","title":"\ud83e\uddf1 PART 4 \u2014 Use Efficient Instance Types","text":"<p>Bad choice examples:</p> <p>\u274c cpu-heavy nodes for memory apps  \u274c small nodes for giant workloads causing fragmentation  \u274c expensive \u201cburstable\u201d nodes with no need</p> <p>General rule:</p> <p>\u2714\ufe0f CPU-heavy apps \u2192 compute-optimized  \u2714\ufe0f Memory-heavy apps \u2192 memory-optimized  \u2714\ufe0f Mixed \u2192 general-purpose</p> <p>Correct instance types reduce hidden waste.</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#part-5-reduce-log-metrics-costs","title":"\ud83e\uddf1 PART 5 \u2014 Reduce Log &amp; Metrics Costs","text":"<p>A BIG SECRET:  Logging &amp; monitoring often costs more than compute.</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#optimize","title":"Optimize:","text":"<p>\u2714\ufe0f Use Loki instead of Elasticsearch  \u2714\ufe0f Drop DEBUG logs in production  \u2714\ufe0f Short retention (3\u20137 days)  \u2714\ufe0f Avoid shipping k8s events to logs  \u2714\ufe0f Only collect necessary namespace logs</p> <p>Prometheus:</p> <p>\u2714\ufe0f Downsample  \u2714\ufe0f Drop high-cardinality metrics  \u2714\ufe0f Reduce scrape intervals</p> <p>This often saves 10\u201340%.</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#part-6-optimize-container-images","title":"\ud83e\uddf1 PART 6 \u2014 Optimize Container Images","text":"<p>Large images = slower scaling + wasted storage.</p> <p>\u2714\ufe0f Use Alpine  \u2714\ufe0f Multi-stage builds  \u2714\ufe0f Use distroless images  \u2714\ufe0f Remove unused libraries  \u2714\ufe0f Compress layers</p> <p>A 1GB image \u2192 150MB image =  \u2714\ufe0f faster scaling  \u2714\ufe0f smaller storage cost  \u2714\ufe0f less network cost</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#part-7-autoscaling-improvements-hpa-keda","title":"\ud83e\uddf1 PART 7 \u2014 Autoscaling Improvements (HPA + KEDA)","text":""},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#hpa","title":"HPA","text":"<p>\u2714\ufe0f scale by CPU/memory  \u2714\ufe0f core autoscaling</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#keda","title":"KEDA","text":"<p>\u2714\ufe0f scale by queue length  \u2714\ufe0f HTTP traffic  \u2714\ufe0f Kafka lag  \u2714\ufe0f Prometheus queries</p> <p>Event-driven autoscaling prevents paying for idle pods.</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#part-8-pod-density-optimization","title":"\ud83e\uddf1 PART 8 \u2014 Pod Density Optimization","text":"<p>Cluster cost is based on:</p> <p># of nodes \u2014 not # of pods</p> <p>Goal:  Pack more pods onto fewer nodes.</p> <p>You can increase density by:</p> <p>\u2714\ufe0f Right-sizing pod requests  \u2714\ufe0f Using VPA recommendations  \u2714\ufe0f Using bin-packing scheduling strategies  \u2714\ufe0f Using larger nodes (often cheaper per CPU/mem)</p> <p>Real companies save 15\u201335% from bin packing.</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#part-9-use-requests-correctly-most-misunderstood","title":"\ud83e\uddf1 PART 9 \u2014 Use \u201cRequests\u201d Correctly (Most Misunderstood)","text":"<p>Requests determine how much CPU/mem the scheduler allocates.</p> <p>Limits cap Pod usage.</p> <p>Best practice:</p> <p>\u2714\ufe0f Use requests, optional or small limits  \u2714\ufe0f Use VPA to auto-tune requests  \u2714\ufe0f Avoid high memory limits (OOM kills your app)  \u2714\ufe0f Avoid high CPU requests (prevents bin-packing)</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#part-10-use-finops-tools","title":"\ud83e\uddf1 PART 10 \u2014 Use FinOps Tools","text":"<p>Industry tools:</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#kubecost-most-used","title":"\ud83d\udd39 Kubecost (most used)","text":"<p>Live dashboard showing:</p> <p>\u2714\ufe0f Cost per namespace  \u2714\ufe0f Cost per service  \u2714\ufe0f Cost per label  \u2714\ufe0f CPU/mem waste  \u2714\ufe0f Savings recommendations</p> <p>Install:</p> <pre><code>helm install kubecost \\\n  --namespace kubecost \\\n  cost-analyzer/kubecost\n</code></pre>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#goldilocks","title":"\ud83d\udd39 Goldilocks","text":"<p>Helps calculate optimal requests/limits.</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#aws-cost-explorer-gcp-billing-azure-cost-management","title":"\ud83d\udd39 AWS Cost Explorer / GCP Billing / Azure Cost Management","text":"<p>Track trends &amp; anomaly detection.</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#example-real-savings-scenario","title":"\ud83d\udcc9 EXAMPLE: Real Savings Scenario","text":"<p>Company before optimization:</p> <ul> <li>30 nodes</li> <li>$35,000 per month AWS cost</li> </ul> <p>After applying the techniques you learned:</p> <p>\u2714\ufe0f Right-sizing pods  \u2714\ufe0f Spot nodes for stateless workloads  \u2714\ufe0f Cluster Autoscaler  \u2714\ufe0f Logging reduction  \u2714\ufe0f KEDA event-driven scaling</p> <p>Cluster shrinks to: 13 nodes New cost: $14,500 per month</p> <p>\ud83d\udcb0 Savings: $20,500 per month  \ud83d\udcb0 Annual savings: $246,000</p> <p>This is REAL FinOps impact.</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#lesson-27-completed","title":"\ud83c\udf89 Lesson 27 Completed!","text":"<p>You now know how to dramatically reduce Kubernetes costs:</p> <p>\u2714\ufe0f Right-size CPU/memory  \u2714\ufe0f Autoscale nodes (CA)  \u2714\ufe0f Use Spot nodes  \u2714\ufe0f Optimize images  \u2714\ufe0f Reduce logging/metrics cost  \u2714\ufe0f Improve pod packing  \u2714\ufe0f Use FinOps tools (Kubecost, Goldilocks)  \u2714\ufe0f Build cost-aware architectures</p> <p>This is senior DevOps + FinOps mastery \ud83d\udd25\ud83d\udcaa  Companies LOVE engineers who save them $$.</p>"},{"location":"chapters/ch27-Kubernetes_Cost_Optimization_FinOps_Real_Cloud_Savings/#ready-for-lesson-28","title":"\ud83d\udc49 Ready for Lesson 28?","text":"<p>Pick your next advanced topic:</p> <p>1\ufe0f\u20e3 Cluster Autoscaler + Node Pool Scaling (full deep dive) 2\ufe0f\u20e3 Secure Supply Chain \u2014 Image Signing, SBOM, Scanning 3\ufe0f\u20e3 Service Mesh Advanced \u2014 mTLS rotation, traffic shadowing 4\ufe0f\u20e3 Kubernetes Performance Tuning 5\ufe0f\u20e3 Cloud-Native Deployments on EKS/GKE/AKS</p> <p>Which one next?</p>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/","title":"\u2699\ufe0f Lesson 28: Cluster Autoscaler (CA) + Node Pool Scaling Deep Dive","text":"<p>Awesome! \u2714\ufe0f</p> <p>Welcome to Lesson 28, and this one is absolutely essential for running large production Kubernetes clusters:</p> <p>This lesson teaches you EXACTLY how companies like Netflix, Shopify, Uber, and Airbnb scale their worker nodes automatically to handle real traffic.</p> <p>By the end, you\u2019ll understand:</p> <p>\u2714\ufe0f Cluster Autoscaler (CA)  \u2714\ufe0f Managed Node Groups (AWS/GCP/Azure)  \u2714\ufe0f Multiple Node Pools  \u2714\ufe0f Spot + On-Demand hybrid scaling  \u2714\ufe0f Priority-based scheduling  \u2714\ufe0f Bin-packing (cost optimization)  \u2714\ufe0f Real-world autoscaling architecture</p> <p>DevOps-GPT style: beginner-friendly, enterprise depth.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#what-is-cluster-autoscaler","title":"\u2b50 What Is Cluster Autoscaler?","text":"<p>Cluster Autoscaler (CA) automatically:</p>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#adds-nodes-when","title":"\ud83d\udfe2 Adds nodes when:","text":"<ul> <li>Pods cannot be scheduled</li> <li>Not enough CPU/memory</li> <li>Node pool is full</li> </ul>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#removes-nodes-when","title":"\ud83d\udd34 Removes nodes when:","text":"<ul> <li>Nodes are empty</li> <li>Pods have moved elsewhere</li> <li>The node becomes unnecessary</li> </ul> <p>This saves HUGE money \ud83d\udcb0 and ensures zero deployment failures.</p>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#part-1-node-pools-the-foundation","title":"\ud83e\uddf1 PART 1 \u2014 Node Pools (The Foundation)","text":"<p>A Node Pool (AKA Node Group) is a group of nodes with the same:</p> <p>\u2714\ufe0f instance type  \u2714\ufe0f OS  \u2714\ufe0f taints/labels  \u2714\ufe0f cost model (spot/on-demand)</p> <p>Typical enterprise setup:</p> <pre><code>nodepool-general (on-demand)\nnodepool-spot (spot instances)\nnodepool-memory (memory optimized)\nnodepool-gpu (GPU)\n</code></pre> <p>Pod placement decides where workloads go.</p>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#example-node-pool-labels","title":"\ud83e\udde9 Example Node Pool Labels","text":"<pre><code>node-type=general\nnode-type=spot\nnode-type=memory\nenv=prod\n</code></pre> <p>Pod example:</p> <pre><code>nodeSelector:\n  node-type: spot\n</code></pre> <p>This controls which node pool is used.</p>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#part-2-install-cluster-autoscaler-aws-example","title":"\ud83e\uddf1 PART 2 \u2014 Install Cluster Autoscaler (AWS Example)","text":""},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#1-install-ca-yaml","title":"1. Install CA YAML","text":"<pre><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/autoscaler/master/cluster-autoscaler/cloudprovider/aws/examples/cluster-autoscaler-autodiscover.yaml\n</code></pre>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#2-patch-tags-for-autodiscovery","title":"2. Patch tags for autodiscovery","text":"<p>Each node group MUST have:</p> <pre><code>k8s.io/cluster-autoscaler/enabled\nk8s.io/cluster-autoscaler/CLUSTER_NAME\n</code></pre> <p>Example (AWS):</p> <pre><code>eksctl create nodegroup \\\n  --cluster mycluster \\\n  --name ng1 \\\n  --nodes-min 1 \\\n  --nodes-max 10 \\\n  --asg-access \\\n  --tags k8s.io/cluster-autoscaler/enabled=true\n</code></pre>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#3-tell-ca-the-cluster-name","title":"3. Tell CA the cluster name:","text":"<pre><code>kubectl patch deployment cluster-autoscaler -n kube-system \\\n  --type='json' \\\n  -p='[{\"op\": \"add\", \"path\": \"/spec/template/spec/containers/0/args/-\", \"value\": \"--node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled=true\"}]'\n</code></pre> <p>\u2714\ufe0f Autoscaler will now automatically discover node groups  \u2714\ufe0f and scale them as needed</p>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#part-3-autoscaling-in-action","title":"\ud83e\uddea PART 3 \u2014 Autoscaling in Action","text":""},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#scenario","title":"Scenario:","text":"<p>You deploy a workload requesting huge memory:</p> <pre><code>resources:\n  requests:\n    memory: \"8Gi\"\n</code></pre> <p>If no node has 8Gi free \u2192 Pod stays Pending.</p> <p>CA sees this:</p> <pre><code>Pod cannot be scheduled \u2192 Add new node\n</code></pre> <p>Within 1\u20132 minutes:</p> <p>\u2714\ufe0f A new node joins  \u2714\ufe0f Pod gets scheduled  \u2714\ufe0f Cluster expands automatically</p> <p>\ud83c\udf89 No human intervention.</p>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#part-4-scale-down-save-money-automatically","title":"\ud83d\udd04 PART 4 \u2014 Scale Down (Save Money Automatically)","text":"<p>When nodes are empty:</p> <p>\u2714\ufe0f No pods running  \u2714\ufe0f Pods moved to other nodes  \u2714\ufe0f Node drains safely  \u2714\ufe0f Node removed</p> <p>Example:</p> <pre><code>cluster: 20 nodes \u2192 7 PM \u2192 6 nodes\n</code></pre> <p>Automatic savings.</p>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#part-5-priority-based-pod-scheduling-super-important","title":"\ud83c\udf00 PART 5 \u2014 Priority-Based Pod Scheduling (Super Important)","text":"<p>Pods can have priorities:</p> <pre><code>priorityClassName: high-priority\n</code></pre> <p>Create a priority class:</p> <pre><code>apiVersion: scheduling.k8s.io/v1\nkind: PriorityClass\nmetadata:\n  name: high-priority\nvalue: 1000\nglobalDefault: false\n</code></pre> <p>Meaning:</p> <p>\u2714\ufe0f High priority pods preempt low priority pods  \u2714\ufe0f Guarantees mission-critical services ALWAYS run  \u2714\ufe0f CA will scale nodes to satisfy high-priority pods  \u2714\ufe0f Low-priority pods may be evicted</p> <p>Used by:</p> <ul> <li>Payment systems</li> <li>API gateways</li> <li>Databases</li> <li>Ingress controllers</li> </ul>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#part-6-spot-on-demand-hybrid-scaling-enterprise-standard","title":"\ud83e\udde0 PART 6 \u2014 Spot + On-Demand Hybrid Scaling (Enterprise Standard)","text":""},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#architecture","title":"Architecture:","text":"<pre><code>spot-nodes: 70% of workloads\non-demand-nodes: 30% critical workloads\n</code></pre> <p>Spot nodes are 70\u201390% cheaper.</p>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#on-demand-node-pool","title":"On-demand node pool:","text":"<pre><code>eksctl create nodegroup --name on-demand --nodes-min 1 --nodes-max 5\n</code></pre>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#spot-node-pool","title":"Spot node pool:","text":"<pre><code>eksctl create nodegroup \\\n  --name spot \\\n  --spot \\\n  --nodes-min 0 \\\n  --nodes-max 20\n</code></pre>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#pod-assignment","title":"Pod assignment:","text":"<p>Critical workloads:</p> <pre><code>nodeSelector:\n  node-type: on-demand\n</code></pre> <p>Non-critical workloads:</p> <pre><code>nodeSelector:\n  node-type: spot\n</code></pre> <p>Result:</p> <p>\u2714\ufe0f Cheap workloads run on spot  \u2714\ufe0f Critical workloads stable  \u2714\ufe0f CA scales both pools independently  \u2714\ufe0f Massive $$$ savings</p>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#part-7-bin-packing-strategy-advanced-optimization","title":"\ud83d\udd25 PART 7 \u2014 Bin-Packing Strategy (Advanced Optimization)","text":"<p>Goal:  Pack pods densely into fewer nodes to save $$.</p> <p>Enable bin-packing:</p> <pre><code>--balance-similar-node-groups=true\n--expendable-pods-priority-cutoff=1000\n</code></pre> <p>This ensures:</p> <p>\u2714\ufe0f Nodes get fully utilized  \u2714\ufe0f Under-used nodes get drained  \u2714\ufe0f Cluster shrinks aggressively</p> <p>Savings:  \ud83d\udd25 15\u201335% average cluster cost reduction</p>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#part-8-karpenter-next-generation-autoscaler","title":"\ud83e\uddf1 PART 8 \u2014 Karpenter (Next Generation Autoscaler)","text":"<p>AWS teams created Karpenter, a better alternative to CA.</p> <p>Benefits:</p> <p>\u2714\ufe0f faster scaling  \u2714\ufe0f fewer nodes required  \u2714\ufe0f can choose ANY instance type  \u2714\ufe0f reacts instantly to pending pods  \u2714\ufe0f supports Spot preferences</p> <p>Example provisioning spec:</p> <pre><code>apiVersion: karpenter.sh/v1alpha5\nkind: Provisioner\nspec:\n  requirements:\n    - key: instance-type\n      operator: In\n      values: [\"t3.medium\", \"t3.large\"]\n  limits:\n    resources:\n      cpu: 100\n</code></pre> <p>Karpenter is becoming the new industry standard.</p>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#lesson-28-completed","title":"\ud83c\udf89 Lesson 28 Completed!","text":"<p>You now understand:</p> <p>\u2714\ufe0f Cluster Autoscaler  \u2714\ufe0f Spot + On-Demand hybrid strategy  \u2714\ufe0f Node pools &amp; taints  \u2714\ufe0f Bin-packing optimization  \u2714\ufe0f Priority-based workloads  \u2714\ufe0f Autoscaling triggers  \u2714\ufe0f Real-world cluster expansion/shrinkage  \u2714\ufe0f Karpenter (next-gen autoscaler)</p> <p>This is senior platform engineer knowledge.  You're becoming dangerously good \ud83d\ude0e\ud83d\udd25</p>"},{"location":"chapters/ch28-Cluster_Autoscaler_Node_Pool_Scaling_full_deep_dive/#ready-for-lesson-29","title":"\ud83d\udc49 Ready for Lesson 29?","text":"<p>Choose your next topic:</p> <p>1\ufe0f\u20e3 Secure Supply Chain \u2014 Image Signing, SBOM, Scanning 2\ufe0f\u20e3 Service Mesh Advanced \u2014 Traffic Shadowing, mTLS Rotation 3\ufe0f\u20e3 Kubernetes Performance Tuning 4\ufe0f\u20e3 Cloud-Native Deployments on EKS/GKE/AKS 5\ufe0f\u20e3 Kubernetes Networking Deep Dive (CNI plugins, overlay, routing)</p> <p>Which one should we do next?</p>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/","title":"\ud83d\udd10 Lesson 29: Secure Supply Chain \u2014 Image Signing, SBOM, Scanning (SLSA-Ready)","text":"<p>Absolutely! \u2714\ufe0f</p> <p>Welcome to Lesson 29, and this one is INSANELY important for modern DevOps, platform engineering, and security teams:</p> <p>This is the SAME security model used by:</p> <ul> <li>Google (SLSA)</li> <li>GitHub</li> <li>CNCF projects</li> <li>U.S. Government guidelines (NIST)</li> <li>Enterprises protecting production workloads</li> </ul> <p>With modern attacks targeting CI/CD pipelines and container images, supply chain security is not optional anymore.</p> <p>Today you\u2019ll learn:</p> <p>\u2714\ufe0f Image signing (Cosign) \u2714\ufe0f SBOM generation (Syft, Grype) \u2714\ufe0f Vulnerability scanning (Trivy) \u2714\ufe0f Sigstore verification in Kubernetes \u2714\ufe0f Prevent running untrusted images \u2714\ufe0f Admission policies for image security \u2714\ufe0f Secure CI/CD pipeline \u2714\ufe0f Real enterprise implementation</p> <p>Beginner-friendly. Industry-level advanced.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#why-supply-chain-security-matters","title":"\u2b50 Why Supply Chain Security Matters","text":"<p>Modern attacks happen in your pipeline:</p> <p>\u2757 Poisoned images \u2757 Malware hidden in layers \u2757 Insecure dependencies \u2757 Compromised registries \u2757 Fake images uploaded \u2757 CI pipeline token theft \u2757 Dependency tampering</p> <p>Your cluster is only as secure as the images you run.</p> <p>Supply chain security fixes that.</p>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#part-1-install-the-core-tools","title":"\ud83e\uddf1 PART 1 \u2014 Install the Core Tools","text":""},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#install-cosign-image-signing","title":"Install Cosign (image signing)","text":"<pre><code>brew install cosign\n</code></pre> <p>or:</p> <pre><code>curl -sSL https://github.com/sigstore/cosign/releases/latest/download/cosign-linux-amd64 -o cosign\nchmod +x cosign\n</code></pre>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#install-syft-sbom","title":"Install Syft (SBOM)","text":"<pre><code>brew install syft\n</code></pre>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#install-grype-vulnerability-scanning","title":"Install Grype (vulnerability scanning)","text":"<pre><code>brew install grype\n</code></pre>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#install-trivy-full-security-scanner","title":"Install Trivy (full security scanner)","text":"<pre><code>brew install trivy\n</code></pre> <p>Now you're fully equipped \u2714\ufe0f</p>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#part-2-generate-an-sbom-for-your-image","title":"\ud83e\uddf1 PART 2 \u2014 Generate an SBOM for Your Image","text":"<p>SBOM = Software Bill Of Materials  It lists everything inside your image:</p> <ul> <li>OS packages</li> <li>libraries</li> <li>dependencies</li> <li>versions</li> <li>licenses</li> </ul> <p>Generate:</p> <pre><code>syft my-image:latest -o json &gt; sbom.json\n</code></pre> <p>Or human-readable:</p> <pre><code>syft my-image:latest\n</code></pre> <p>This is REQUIRED for compliance (NIST, SLSA, EU CRA).</p>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#part-3-scan-image-for-vulnerabilities","title":"\ud83e\uddea PART 3 \u2014 Scan Image for Vulnerabilities","text":"<p>Using Grype:</p> <pre><code>grype my-image:latest\n</code></pre> <p>Using Trivy (better for full pipeline):</p> <pre><code>trivy image my-image:latest\n</code></pre> <p>Trivy also finds:</p> <p>\u2714\ufe0f vulnerabilities  \u2714\ufe0f misconfigurations  \u2714\ufe0f secrets  \u2714\ufe0f license issues  \u2714\ufe0f SBOM components</p> <p>Goal: block images with critical vulnerabilities.</p> <p>Example Trivy output:</p> <pre><code>CRITICAL: openssl vulnerability CVE-2023-xxxx\n</code></pre> <p>Fix before deploying.</p>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#part-4-image-signing-with-cosign-sigstore","title":"\ud83e\uddf1 PART 4 \u2014 Image Signing with Cosign (Sigstore)","text":"<p>Sign your image:</p> <pre><code>cosign generate-key-pair\n</code></pre> <p>This creates:</p> <ul> <li>cosign.key</li> <li>cosign.pub</li> </ul>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#sign-the-docker-image","title":"Sign the Docker image:","text":"<pre><code>cosign sign -key cosign.key my-image:latest\n</code></pre> <p>This attaches a cryptographic signature TO THE IMAGE, stored in the OCI registry.</p>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#part-5-verify-the-signature","title":"\ud83d\udd0d PART 5 \u2014 Verify the Signature","text":"<p>Verify:</p> <pre><code>cosign verify -key cosign.pub my-image:latest\n</code></pre> <p>Output:</p> <p>\u2714\ufe0f Valid signature  \u2714\ufe0f Identity of signer  \u2714\ufe0f Certificate chain</p> <p>If signature is missing or invalid \u2192 REJECT.</p>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#part-6-enforce-image-signing-in-kubernetes","title":"\ud83d\udd10 PART 6 \u2014 Enforce Image Signing in Kubernetes","text":"<p>We use Sigstore Policy Controller (formerly Cosigned).</p> <p>Install:</p> <pre><code>kubectl apply -f https://github.com/sigstore/policy-controller/releases/latest/download/policy-controller.yaml\n</code></pre> <p>Now create a policy:</p> <pre><code>apiVersion: policy.sigstore.dev/v1beta1\nkind: ClusterImagePolicy\nmetadata:\n  name: require-signed-images\nspec:\n  images:\n    - glob: \"ghcr.io/myorg/*\"\n  authorities:\n    - key:\n        data: |\n          -----BEGIN PUBLIC KEY-----\n          ...your cosign.pub...\n          -----END PUBLIC KEY-----\n</code></pre> <p>This says:</p> <p>\u2714\ufe0f Only images signed by YOU can run  \u2714\ufe0f Unsigned or tampered images are blocked  \u2714\ufe0f Protects your production cluster</p> <p>Try deploying an unsigned image:</p> <p>\u274c AdmissionWebhook DENIES the deployment  \u2714\ufe0f Perfect protection</p>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#part-7-secure-supply-chain-in-cicd","title":"\ud83e\uddf1 PART 7 \u2014 Secure Supply Chain in CI/CD","text":"<p>A real pipeline includes:</p>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#step-1-build","title":"Step 1 \u2014 Build","text":"<p>Create minimal, multi-stage images.</p>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#step-2-scan-image","title":"Step 2 \u2014 Scan image","text":"<p>Block critical vulnerabilities:</p> <pre><code>trivy image --exit-code 1 my-image:latest\n</code></pre>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#step-3-generate-sbom","title":"Step 3 \u2014 Generate SBOM","text":"<pre><code>syft . -o cyclonedx-json &gt; sbom.json\n</code></pre>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#step-4-sign-the-image","title":"Step 4 \u2014 Sign the image","text":"<pre><code>cosign sign -key cosign.key my-image:latest\n</code></pre>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#step-5-push-sbom-to-registry","title":"Step 5 \u2014 Push SBOM to registry","text":"<p>Attach SBOM to image:</p> <pre><code>cosign attach sbom -sbom sbom.json my-image:latest\n</code></pre>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#step-6-deploy-via-argocd","title":"Step 6 \u2014 Deploy via ArgoCD","text":"<p>ArgoCD only applies manifests containing signed &amp; verified images.</p> <p>This is SLSA Level 2 / Level 3 ready.</p>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#part-8-prevent-running-vulnerable-images-opa-gatekeeper","title":"\ud83d\udd12 PART 8 \u2014 Prevent Running Vulnerable Images (OPA Gatekeeper)","text":"<p>Policy example:</p> <pre><code>apiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sVulnScan\nmetadata:\n  name: block-critical-images\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"\"]\n        kinds: [\"Pod\"]\n  parameters:\n    severity: [\"critical\"]\n</code></pre> <p>This prevents:</p> <p>\u274c images with CRITICAL CVEs  \u274c images missing SBOM  \u274c images without valid signature</p> <p>Zero-trust for container images.</p>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#part-9-real-enterprise-architecture","title":"\ud83c\udf0d PART 9 \u2014 Real Enterprise Architecture","text":"<p>All companies use this model:</p> <pre><code>Developer \u2192\nCI Pipeline \u2192\nTrivy Scan \u2192\nSyft SBOM \u2192\nCosign Signature \u2192\nSBOM stored in registry \u2192\nArgoCD deploys \u2192\nKubernetes verifies signatures \u2192\nPods run\n</code></pre> <p>If any step fails \u2192 image NEVER runs in prod.</p>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#lesson-29-completed","title":"\ud83c\udf89 Lesson 29 Completed!","text":"<p>You now understand:</p> <p>\u2714\ufe0f Image signing (Cosign)  \u2714\ufe0f SBOM generation (Syft)  \u2714\ufe0f Vulnerability scanning (Trivy, Grype)  \u2714\ufe0f Admission policies for signed images  \u2714\ufe0f OPA/Gatekeeper security rules  \u2714\ufe0f Full secure CI/CD pipeline  \u2714\ufe0f Sigstore architecture  \u2714\ufe0f Preventing tampered or vulnerable images</p> <p>This is elite-level supply chain security \u2014 few DevOps engineers know this deeply.  You\u2019re becoming a real Kubernetes security expert \ud83d\udd25\ud83d\udcaa</p>"},{"location":"chapters/ch29-Secure_Supply_Chain_Image_Signing_SBOM_Scanning_SLSA-Ready/#ready-for-lesson-30","title":"\ud83d\udc49 Ready for Lesson 30?","text":"<p>Choose your next topic:</p> <p>1\ufe0f\u20e3 Service Mesh Advanced \u2014 Traffic Shadowing, mTLS Rotation, Retry/Circuit Patterns  2\ufe0f\u20e3 Kubernetes Performance Tuning (High-speed clusters)  3\ufe0f\u20e3 Cloud-Native Deployments on EKS/GKE/AKS  4\ufe0f\u20e3 Kubernetes Networking Deep Dive (CNI, overlay, routing)  5\ufe0f\u20e3 Debugging Kubernetes like a PRO (high-level Troubleshooting)</p> <p>Which one should we do next?</p>"},{"location":"chapters/ch3-ConfigMaps_Secrets_Beginner_Friendly/","title":"\ud83d\udd10  Lesson 3: ConfigMaps &amp; Secrets (Beginner Friendly!)","text":"<p>Great! \u2714\ufe0f  Moving to Lesson 3 \u2014 one of the most important real-world DevOps skills:</p> <p>Every real application needs configuration:</p> <ul> <li>environment variables</li> <li>URLs</li> <li>settings</li> <li>API keys</li> <li>passwords</li> </ul> <p>In Kubernetes, we NEVER hardcode these inside container images.</p> <p>Instead, we use:</p> Object Purpose ConfigMap Non-sensitive configuration (public settings) Secret Sensitive values like passwords, tokens, keys <p>Let\u2019s learn both with simple examples. \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch3-ConfigMaps_Secrets_Beginner_Friendly/#part-1-configmap-safe-non-sensitive-config","title":"\ud83c\udf31 Part 1 \u2014 ConfigMap (Safe, Non-Sensitive Config)","text":"<p>Imagine your app needs:</p> <ul> <li>APP_MODE = production</li> <li>APP_COLOR = blue</li> </ul> <p>Here\u2019s the ConfigMap YAML:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\ndata:\n  APP_MODE: \"production\"\n  APP_COLOR: \"blue\"\n</code></pre> <p>Apply it:</p> <pre><code>kubectl apply -f configmap.yaml\n</code></pre>"},{"location":"chapters/ch3-ConfigMaps_Secrets_Beginner_Friendly/#use-configmap-in-a-deployment","title":"\ud83d\udd0c Use ConfigMap in a Deployment","text":"<p>We now plug those variables into a Deployment.</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: config-demo\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: config-demo\n  template:\n    metadata:\n      labels:\n        app: config-demo\n    spec:\n      containers:\n        - name: demo\n          image: nginx:latest\n          env:\n            - name: APP_MODE\n              valueFrom:\n                configMapKeyRef:\n                  name: app-config\n                  key: APP_MODE\n            - name: APP_COLOR\n              valueFrom:\n                configMapKeyRef:\n                  name: app-config\n                  key: APP_COLOR\n</code></pre> <p>Now your container has environment variables from the ConfigMap \u2714\ufe0f</p>"},{"location":"chapters/ch3-ConfigMaps_Secrets_Beginner_Friendly/#part-2-secrets-passwords-tokens-keys","title":"\ud83d\udd10 Part 2 \u2014 Secrets (Passwords, Tokens, Keys)","text":"<p>Secrets are like ConfigMaps, but encrypted in Kubernetes storage.</p> <p>Let\u2019s store a database password:</p>"},{"location":"chapters/ch3-ConfigMaps_Secrets_Beginner_Friendly/#step-1-encode-the-password","title":"Step 1: Encode the password","text":"<p>(Kubernetes requires base64 format.)</p> <p>Example password:</p> <pre><code>mysecretpassword\n</code></pre> <p>Encode it:</p> <pre><code>echo -n \"mysecretpassword\" | base64\n</code></pre> <p>You\u2019ll get something like:</p> <pre><code>bXlzZWNyZXRwYXNzd29yZA==\n</code></pre>"},{"location":"chapters/ch3-ConfigMaps_Secrets_Beginner_Friendly/#step-2-secret-yaml","title":"Step 2: Secret YAML","text":"<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: db-secret\ntype: Opaque\ndata:\n  DB_PASSWORD: bXlzZWNyZXRwYXNzd29yZA==\n</code></pre> <p>Apply it:</p> <pre><code>kubectl apply -f secret.yaml\n</code></pre>"},{"location":"chapters/ch3-ConfigMaps_Secrets_Beginner_Friendly/#use-secret-in-deployment","title":"\ud83d\udd0c Use Secret in Deployment","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: secret-demo\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: secret-demo\n  template:\n    metadata:\n      labels:\n        app: secret-demo\n    spec:\n      containers:\n        - name: app\n          image: nginx:latest\n          env:\n            - name: DB_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: db-secret\n                  key: DB_PASSWORD\n</code></pre> <p>Now your pod has a secure environment variable <code>DB_PASSWORD</code> \u2714\ufe0f</p>"},{"location":"chapters/ch3-ConfigMaps_Secrets_Beginner_Friendly/#bonus-you-can-also-mount-configmaps-secrets-as-files","title":"\ud83c\udfaf Bonus: You can also mount ConfigMaps &amp; Secrets as files","text":"<p>Example (very common in DevOps):</p> <pre><code>volumeMounts:\n  - name: config-volume\n    mountPath: /etc/config\n\nvolumes:\n  - name: config-volume\n    configMap:\n      name: app-config\n</code></pre>"},{"location":"chapters/ch3-ConfigMaps_Secrets_Beginner_Friendly/#lesson-3-completed","title":"\ud83c\udf89 Lesson 3 Completed!","text":"<p>You now know:</p> <p>\u2714\ufe0f ConfigMaps for normal config  \u2714\ufe0f Secrets for sensitive values  \u2714\ufe0f How to inject variables into Deployments  \u2714\ufe0f How to mount configuration into containers</p> <p>This is a real-world DevOps skill that 100% of companies use.</p>"},{"location":"chapters/ch3-ConfigMaps_Secrets_Beginner_Friendly/#what-should-we-learn-next","title":"\ud83d\udc49 What should we learn next?","text":"<p>Choose your next lesson:</p> <ol> <li>Ingress (Domains + real web routing + HTTPS)</li> <li>Persistent Volumes (databases, storage)</li> <li>Docker + Kubernetes Workflow</li> <li>Helm Charts (industry-standard packaging)</li> <li>Kustomize (environment overlays: dev/stage/prod)</li> </ol> <p>Which one next? \ud83d\udc40\ud83d\udca1</p>"},{"location":"chapters/ch30-Service_Mesh_Advanced_Traffic_Shadowing_mTLS_Rotation_Circuit_Breakers_Retries/","title":"\ud83d\udd78\ufe0f Lesson 30: Service Mesh Advanced \u2014 Traffic Shadowing, mTLS Rotation, Circuit Breakers, Retries","text":"<p>Absolutely! \u2714\ufe0f</p> <p>Welcome to Lesson 30, and this one is \ud83d\udd25 SUPER ADVANCED \u2014 the kind of knowledge only senior platform engineers and service mesh architects use:</p> <p>This lesson will teach you production-grade Istio features used by:</p> <ul> <li>Netflix</li> <li>DoorDash</li> <li>Airbnb</li> <li>Slack</li> <li>Google Cloud</li> <li>Shopify</li> </ul> <p>This is the level where service mesh becomes magic.</p> <p>Let\u2019s break it down beginner-friendly but expert-level.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch30-Service_Mesh_Advanced_Traffic_Shadowing_mTLS_Rotation_Circuit_Breakers_Retries/#what-you-will-learn-today","title":"\u2b50 What You Will Learn Today","text":"<p>\u2714\ufe0f Traffic Shadowing (mirroring live traffic safely)  \u2714\ufe0f Secure mTLS certificate rotation  \u2714\ufe0f Retries &amp; timeouts (prevent cascading failures)  \u2714\ufe0f Circuit breakers  \u2714\ufe0f Outlier detection (auto-remove bad pods)  \u2714\ufe0f Traffic fault injection (chaos testing)  \u2714\ufe0f Header-based routing  \u2714\ufe0f Production-ready Istio config</p>"},{"location":"chapters/ch30-Service_Mesh_Advanced_Traffic_Shadowing_mTLS_Rotation_Circuit_Breakers_Retries/#part-1-traffic-shadowing-mirroring","title":"\ud83e\uddf1 PART 1 \u2014 Traffic Shadowing (Mirroring)","text":"<p>Traffic Shadowing = send 100% REAL production traffic to a new version, but responses are ignored.</p> <p>Used to test:</p> <ul> <li>v2 microservice</li> <li>new features</li> <li>performance differences</li> <li>real load handling</li> </ul> <p>WITHOUT impacting users \u2757</p>"},{"location":"chapters/ch30-Service_Mesh_Advanced_Traffic_Shadowing_mTLS_Rotation_Circuit_Breakers_Retries/#example-shadow-traffic-from-v1-v2","title":"\ud83e\udde9 Example: Shadow Traffic from v1 \u2192 v2","text":"<p>VirtualService:</p> <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: backend\nspec:\n  hosts:\n    - backend\n  http:\n    - route:\n        - destination:\n            host: backend\n            subset: v1\n          weight: 100\n      mirror:\n        host: backend\n        subset: v2\n      mirrorPercentage:\n        value: 100.0\n</code></pre> <p>Meaning:</p> <p>\u2714\ufe0f Users get v1 responses  \u2714\ufe0f v2 receives a perfect clone of all requests  \u2714\ufe0f You test v2 under real production traffic safely  \u2714\ufe0f Errors in v2 do NOT affect customers</p> <p>This is how companies safely launch big new services.</p>"},{"location":"chapters/ch30-Service_Mesh_Advanced_Traffic_Shadowing_mTLS_Rotation_Circuit_Breakers_Retries/#part-2-mtls-certificate-rotation","title":"\ud83e\uddf1 PART 2 \u2014 mTLS Certificate Rotation","text":"<p>Istio issues mTLS certificates to every pod.  These rotate automatically every 24 hours.</p> <p>But production requires:</p> <p>\u2714\ufe0f short-lived certificates  \u2714\ufe0f CA rotation  \u2714\ufe0f zero-downtime mTLS updates</p>"},{"location":"chapters/ch30-Service_Mesh_Advanced_Traffic_Shadowing_mTLS_Rotation_Circuit_Breakers_Retries/#adjust-certificate-ttl","title":"\ud83e\udde9 Adjust certificate TTL","text":"<pre><code>apiVersion: security.istio.io/v1beta1\nkind: MeshPolicy\nmetadata:\n  name: default\nspec:\n  mtls:\n    mode: STRICT\n  tls:\n    minProtocolVersion: TLSV1_2\n    maxProtocolVersion: TLSV1_3\n</code></pre> <p>Set mesh-level CA lifetime:</p> <pre><code>istioctl install --set values.global.pilotCertProvider=istiod \\\n  --set values.security.workloadCertTtl=12h\n</code></pre> <p>\u2714\ufe0f Every workload gets a fresh mTLS cert  \u2714\ufe0f Prevents long-lived credential leaks</p>"},{"location":"chapters/ch30-Service_Mesh_Advanced_Traffic_Shadowing_mTLS_Rotation_Circuit_Breakers_Retries/#part-3-circuit-breakers-prevent-cascading-failures","title":"\ud83e\uddf1 PART 3 \u2014 Circuit Breakers (Prevent Cascading Failures)","text":"<p>A failing backend should NOT bring down the entire system.</p> <p>Circuit breaking prevents:</p> <p>\u2757 Retry storms  \u2757 Connection floods  \u2757 Database overload  \u2757 Chain-reaction outages</p>"},{"location":"chapters/ch30-Service_Mesh_Advanced_Traffic_Shadowing_mTLS_Rotation_Circuit_Breakers_Retries/#destinationrule-with-circuit-breaker","title":"\ud83e\udde9 DestinationRule with Circuit Breaker","text":"<pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: backend\nspec:\n  host: backend\n  trafficPolicy:\n    outlierDetection:\n      consecutiveErrors: 5\n      interval: 10s\n      baseEjectionTime: 30s\n      maxEjectionPercent: 50\n</code></pre> <p>This means:</p> <p>\u2714\ufe0f If a pod fails 5 times \u2192 eject it  \u2714\ufe0f Do not send traffic to bad pods  \u2714\ufe0f Autoscaler replaces them  \u2714\ufe0f Improve API reliability instantly</p>"},{"location":"chapters/ch30-Service_Mesh_Advanced_Traffic_Shadowing_mTLS_Rotation_Circuit_Breakers_Retries/#part-4-retries-timeouts-super-important","title":"\ud83e\uddf1 PART 4 \u2014 Retries + Timeouts (Super Important!)","text":"<p>Retries = try again  Timeouts = stop waiting  Together = resilient microservices</p>"},{"location":"chapters/ch30-Service_Mesh_Advanced_Traffic_Shadowing_mTLS_Rotation_Circuit_Breakers_Retries/#add-retries","title":"\ud83e\udde9 Add retries","text":"<pre><code>http:\n  - route:\n      - destination:\n          host: backend\n    retries:\n      attempts: 3\n      perTryTimeout: 2s\n      retryOn: gateway-error,connect-failure,refused-stream\n</code></pre>"},{"location":"chapters/ch30-Service_Mesh_Advanced_Traffic_Shadowing_mTLS_Rotation_Circuit_Breakers_Retries/#add-timeouts","title":"\ud83e\udde9 Add timeouts","text":"<pre><code>timeout: 5s\n</code></pre> <p>You get:</p> <p>\u2714\ufe0f Fewer user-visible failures  \u2714\ufe0f Faster recovery from network hiccups  \u2714\ufe0f Protection from slow downstream services</p>"},{"location":"chapters/ch30-Service_Mesh_Advanced_Traffic_Shadowing_mTLS_Rotation_Circuit_Breakers_Retries/#part-5-fault-injection-chaos-testing","title":"\ud83e\uddf1 PART 5 \u2014 Fault Injection (Chaos Testing)","text":"<p>Test resiliency without breaking production.</p> <p>Delay example:</p> <pre><code>fault:\n  delay:\n    percent: 30\n    fixedDelay: 5s\n</code></pre> <p>Meaning:</p> <p>\u2714\ufe0f 30% of requests delayed by 5 seconds  \u2714\ufe0f Test frontend's retry logic  \u2714\ufe0f Discover bottlenecks</p> <p>Abort example:</p> <pre><code>fault:\n  abort:\n    percent: 10\n    httpStatus: 500\n</code></pre> <p>Simulate 10% server errors.</p> <p>This is how Netflix tests microservice failures.</p>"},{"location":"chapters/ch30-Service_Mesh_Advanced_Traffic_Shadowing_mTLS_Rotation_Circuit_Breakers_Retries/#part-6-header-based-routing-advanced-canary","title":"\ud83e\uddf1 PART 6 \u2014 Header-Based Routing (Advanced Canary)","text":"<p>Route traffic based on:</p> <ul> <li>User ID</li> <li>Country</li> <li>Mobile vs Desktop</li> <li>Cookies</li> <li>Feature flags</li> </ul> <p>Example:</p> <pre><code>match:\n  - headers:\n      x-user-type:\n        exact: beta\nroute:\n  - destination:\n      host: backend\n      subset: v2\n</code></pre> <p>Meaning:</p> <p>\u2714\ufe0f Beta users \u2192 v2  \u2714\ufe0f Everyone else \u2192 v1</p> <p>This is battle-tested feature rollout.</p>"},{"location":"chapters/ch30-Service_Mesh_Advanced_Traffic_Shadowing_mTLS_Rotation_Circuit_Breakers_Retries/#part-7-traffic-splitting-with-percentages","title":"\ud83e\uddf1 PART 7 \u2014 Traffic Splitting with Percentages","text":"<p>We can do dynamic rollouts:</p> <pre><code>http:\n  - route:\n      - destination:\n          host: backend\n          subset: v1\n        weight: 80\n      - destination:\n          host: backend\n          subset: v2\n        weight: 20\n</code></pre> <p>Gradually roll out:</p> <p>20% \u2192 40% \u2192 70% \u2192 100%</p> <p>Complete canary deployment \u2714\ufe0f</p>"},{"location":"chapters/ch30-Service_Mesh_Advanced_Traffic_Shadowing_mTLS_Rotation_Circuit_Breakers_Retries/#part-8-automatic-outlier-detection","title":"\ud83e\uddf1 PART 8 \u2014 Automatic Outlier Detection","text":"<p>Istio can detect \u201cbad pods\u201d:</p> <p>\u2714\ufe0f High latency  \u2714\ufe0f High error rate  \u2714\ufe0f Slow responses  \u2714\ufe0f Failing health checks</p> <p>Remove them automatically.</p> <p>Example:</p> <pre><code>outlierDetection:\n  consecutive5xx: 5\n  maxEjectionPercent: 100\n</code></pre> <p>Meaning:</p> <p>\u2757 5 errors \u2192 eject pod  \u2714\ufe0f Traffic flows only to healthy pods</p> <p>This is production-grade resilience.</p>"},{"location":"chapters/ch30-Service_Mesh_Advanced_Traffic_Shadowing_mTLS_Rotation_Circuit_Breakers_Retries/#lesson-30-completed","title":"\ud83c\udf89 Lesson 30 Completed!","text":"<p>You now understand advanced service mesh techniques:</p> <p>\u2714\ufe0f Traffic shadowing (risk-free testing)  \u2714\ufe0f mTLS certificate rotation  \u2714\ufe0f Retries &amp; timeouts  \u2714\ufe0f Circuit breakers  \u2714\ufe0f Outlier detection  \u2714\ufe0f Fault injection  \u2714\ufe0f Header-based routing  \u2714\ufe0f Canary rollouts  \u2714\ufe0f Enterprise-grade traffic control</p> <p>This is expert-level microservice architecture.  You\u2019re operating at SRE/Principal Engineer level now \ud83d\udd25\ud83d\udcaa</p>"},{"location":"chapters/ch30-Service_Mesh_Advanced_Traffic_Shadowing_mTLS_Rotation_Circuit_Breakers_Retries/#ready-for-lesson-31","title":"\ud83d\udc49 Ready for Lesson 31?","text":"<p>Choose the next topic:</p> <p>1\ufe0f\u20e3 Kubernetes Performance Tuning (High-speed clusters)  2\ufe0f\u20e3 Cloud-Native Deployments on EKS/GKE/AKS  3\ufe0f\u20e3 Kubernetes Networking Deep Dive  4\ufe0f\u20e3 Debugging Kubernetes like a PRO  5\ufe0f\u20e3 Full Production Microservices Architecture (End-to-End)</p> <p>Which one should we do next?</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/","title":"\u26a1 Lesson 31 \u2014 Kubernetes Performance Tuning (High-Speed Clusters)","text":"<p>This lesson is super valuable for large-scale apps, CI/CD pipelines, high-traffic APIs, databases, and enterprise clusters.</p> <p>You will learn how to make Kubernetes:</p> <ul> <li>\ud83d\ude80 Faster</li> <li>\ud83d\udd25 More efficient</li> <li>\ud83e\udde0 Smarter at scheduling</li> <li>\ud83c\udfce\ufe0f Scale quicker</li> <li>\ud83e\udeab Use fewer resources</li> <li>\ud83d\udee1\ufe0f Handle extreme load</li> </ul> <p>Let\u2019s go \u2014 beginner-friendly explanations with real enterprise techniques.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#why-performance-tuning-matters","title":"\u2b50 Why Performance Tuning Matters","text":"<p>Problems caused by poor tuning:</p> <p>\u2757 Slow API response  \u2757 High latency  \u2757 Pods stuck in Pending  \u2757 Overloaded nodes  \u2757 Slow autoscaling  \u2757 Slow CI/CD rollouts  \u2757 Crash loops during high traffic  \u2757 $$$ wasted on oversized nodes</p> <p>With proper tuning:</p> <p>\u2714\ufe0f Faster deployments  \u2714\ufe0f Better request handling  \u2714\ufe0f Lower latency  \u2714\ufe0f Lower cost  \u2714\ufe0f Faster scaling  \u2714\ufe0f Better user experience</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#part-1-tune-the-kubelet","title":"\ud83e\uddf1 PART 1 \u2014 Tune the Kubelet","text":"<p>Kubelet runs your pods.  Tuning it massively improves stability.</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#increase-pod-burst-capacity","title":"\u2714\ufe0f Increase Pod Burst Capacity","text":"<pre><code>--kube-reserved=cpu=200m,memory=256Mi\n--system-reserved=cpu=200m,memory=256Mi\n--eviction-hard=memory.available&lt;500Mi\n</code></pre> <p>This prevents node overload &amp; OOM kills.</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#increase-image-pull-performance","title":"\u2714\ufe0f Increase Image Pull Performance","text":"<p>Use:</p> <pre><code>--serialize-image-pulls=false\n</code></pre> <p>This enables parallel image pulls, making deployments much faster.</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#tune-pod-termination-grace-period","title":"\u2714\ufe0f Tune Pod Termination Grace Period","text":"<p>Slow shutdowns = slow deployments.</p> <p>Set:</p> <pre><code>terminationGracePeriodSeconds: 10\n</code></pre> <p>Recommended for stateless apps.</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#part-2-scheduler-performance-smart-scheduling","title":"\ud83e\uddf1 PART 2 \u2014 Scheduler Performance (Smart Scheduling)","text":""},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#enable-pod-topology-spread","title":"\u2714\ufe0f Enable Pod Topology Spread","text":"<p>Even distribution across nodes:</p> <pre><code>topologySpreadConstraints:\n  - maxSkew: 1\n    topologyKey: kubernetes.io/hostname\n    whenUnsatisfiable: ScheduleAnyway\n    labelSelector:\n      matchLabels:\n        app: backend\n</code></pre> <p>Prevents:</p> <ul> <li>hotspots</li> <li>nodes being overloaded</li> <li>uneven resource usage</li> </ul>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#use-pod-priority-for-mission-critical-services","title":"\u2714\ufe0f Use Pod Priority for mission-critical services","text":"<pre><code>priorityClassName: high-priority\n</code></pre> <p>Guarantees key services ALWAYS get scheduled first.</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#part-3-tune-resource-requests-limits","title":"\ud83e\uddf1 PART 3 \u2014 Tune Resource Requests &amp; Limits","text":""},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#if-requests-too-high-waste","title":"If requests too high \u2192 waste","text":""},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#if-requests-too-low-pod-evictions-throttling","title":"If requests too low \u2192 pod evictions / throttling","text":"<p>Tools:</p> <p>\u2714\ufe0f VPA (auto-recommends resource sizes)  \u2714\ufe0f Goldilocks (analyzes metrics)  \u2714\ufe0f Kubecost (shows wasted CPU/memory)</p> <p>Golden Rule:</p> <pre><code>Request = average usage  \nLimit = 2x request  \n</code></pre> <p>This avoids throttling while still safe.</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#part-4-tune-autoscaling-hpa","title":"\ud83e\uddf1 PART 4 \u2014 Tune Autoscaling (HPA)","text":"<p>HPA can be slow by default.</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#fix-1-decrease-stabilization-window","title":"Fix 1: Decrease stabilization window","text":"<pre><code>behavior:\n  scaleUp:\n    stabilizationWindowSeconds: 15\n</code></pre>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#fix-2-faster-reaction","title":"Fix 2: Faster reaction","text":"<pre><code>behavior:\n  scaleUp:\n    policies:\n      - type: Percent\n        value: 100\n        periodSeconds: 30\n</code></pre>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#fix-3-add-keda-for-event-driven-scaling","title":"Fix 3: Add KEDA for event-driven scaling","text":"<p>Fast scaling for:</p> <ul> <li>Kafka</li> <li>RabbitMQ</li> <li>Redis</li> <li>SQS</li> <li>HTTP traffic</li> </ul> <p>This makes autoscaling instant.</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#part-5-deployment-performance-optimizations","title":"\ud83e\uddf1 PART 5 \u2014 Deployment Performance Optimizations","text":""},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#use-rollingupdate-strategy-safe-fast","title":"\u2714\ufe0f Use RollingUpdate strategy (safe + fast)","text":"<pre><code>strategy:\n  rollingUpdate:\n    maxSurge: 50%\n    maxUnavailable: 0\n</code></pre> <p>\u2714\ufe0f No downtime  \u2714\ufe0f Deploys twice as fast</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#enable-startupprobe-for-slow-apps","title":"\u2714\ufe0f Enable startupProbe for slow apps","text":"<pre><code>startupProbe:\n  httpGet:\n    path: /health\n    port: 8080\n  failureThreshold: 30\n  periodSeconds: 2\n</code></pre> <p>Prevents premature restarts during startup.</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#part-6-node-performance","title":"\ud83e\uddf1 PART 6 \u2014 Node Performance","text":""},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#use-node-local-dns-cache-huge-speedup","title":"\u2714\ufe0f Use Node Local DNS Cache (HUGE SPEEDUP)","text":"<pre><code>kubectl apply -f https://k8s.io/examples/admin/dns/dns-cache.yaml\n</code></pre> <p>Improves DNS performance drastically:</p> <ul> <li>faster service lookups</li> <li>lower latency</li> <li>fewer CoreDNS overloads</li> </ul>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#use-bigger-nodes-counterintuitive-but-true","title":"\u2714\ufe0f Use bigger nodes (counterintuitive but true)","text":"<p>Larger nodes \u2192 better bin-packing \u2192 fewer nodes \u2192 less overhead \u2192 faster scheduling.</p> <p>Many companies use:</p> <pre><code>4x large nodes \u2192 better than 16x small nodes\n</code></pre>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#use-containerd-instead-of-docker","title":"\u2714\ufe0f Use containerd instead of Docker","text":"<p>containerd is:</p> <ul> <li>faster</li> <li>lighter</li> <li>more secure</li> <li>better for large clusters</li> </ul> <p>Most managed clusters already do this.</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#part-7-networking-performance-tuning","title":"\ud83e\uddf1 PART 7 \u2014 Networking Performance Tuning","text":""},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#switch-to-cilium-fastest-cni-available","title":"\u2714\ufe0f Switch to Cilium (fastest CNI available)","text":"<p>Cilium improves:</p> <ul> <li>packet processing</li> <li>latency</li> <li>security</li> <li>observability</li> </ul> <p>Alternative: Calico with eBPF mode.</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#use-nodelocal-dns","title":"\u2714\ufe0f Use NodeLocal DNS","text":"<p>(covered earlier \u2014 VERY important)</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#enable-keepalive-for-long-lived-connections","title":"\u2714\ufe0f Enable keepalive for long-lived connections","text":"<p>For microservices:</p> <pre><code>trafficPolicy:\n  connectionPool:\n    http:\n      idleTimeout: 30s\n</code></pre> <p>Avoids expensive reconnect overhead.</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#part-8-persistent-volume-tuning","title":"\ud83e\uddf1 PART 8 \u2014 Persistent Volume Tuning","text":""},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#use-ssd-backed-storage","title":"\u2714\ufe0f Use SSD-backed storage","text":"<p>AWS:</p> <pre><code>gp3\nio2\n</code></pre> <p>GCP:</p> <pre><code>ssd-pd\n</code></pre> <p>Azure:</p> <pre><code>Premium SSD\n</code></pre> <p>Databases and caches REQUIRE SSD to avoid latency spikes.</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#tune-readwritemany-workloads","title":"\u2714\ufe0f Tune ReadWriteMany workloads","text":"<p>Use:</p> <ul> <li>EFS on AWS</li> <li>Filestore on GCP</li> <li>Azure Files</li> </ul> <p>For shared file workloads.</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#part-9-logging-monitoring-optimization","title":"\ud83e\uddf1 PART 9 \u2014 Logging &amp; Monitoring Optimization","text":"<p>Logs can slow your cluster if overloaded.</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#best-practices","title":"Best practices:","text":"<p>\u2714\ufe0f Reduce log verbosity  \u2714\ufe0f Drop DEBUG in production  \u2714\ufe0f Lower scrape frequency for Prometheus  \u2714\ufe0f Use Loki instead of Elasticsearch  \u2714\ufe0f Retention: 7 days only</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#lesson-31-completed","title":"\ud83c\udf89 Lesson 31 Completed!","text":"<p>You now understand high-performance Kubernetes tuning:</p> <p>\u2714\ufe0f Scheduler optimization  \u2714\ufe0f Kubelet performance settings  \u2714\ufe0f Parallel image pulls  \u2714\ufe0f Faster autoscaling  \u2714\ufe0f Faster deployments  \u2714\ufe0f Network &amp; CNI tuning  \u2714\ufe0f Storage performance  \u2714\ufe0f Pod priority  \u2714\ufe0f Node bin-packing  \u2714\ufe0f DNS acceleration</p> <p>This is senior SRE / DevOps platform engineering material.  You are becoming extremely powerful \ud83d\udd25\ud83d\udcaa</p>"},{"location":"chapters/ch31-Kubernetes_Performance_Tuning_High-Speed_Clusters/#ready-for-lesson-32","title":"\ud83d\udc49 Ready for Lesson 32?","text":"<p>Choose your next advanced topic:</p> <p>1\ufe0f\u20e3 Cloud-Native Deployments on EKS / GKE / AKS  2\ufe0f\u20e3 Kubernetes Networking Deep Dive (CNI, routing, overlay)  3\ufe0f\u20e3 Debugging Kubernetes Like a PRO  4\ufe0f\u20e3 Full Production Microservices Architecture  5\ufe0f\u20e3 Building a Real Production Platform From Scratch</p> <p>Which one should we do next?</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/","title":"\u2601\ufe0f Lesson 32: Cloud-Native Deployments on EKS (AWS), GKE (Google), AKS (Azure)","text":"<p>Absolutely! \u2714\ufe0f</p> <p>Welcome to Lesson 32, and this one is MASSIVE \u2014 because now we take everything you learned and apply it to real cloud platforms:</p> <p>This lesson teaches you exactly how REAL companies deploy Kubernetes clusters in the cloud \u2014 with best practices for each provider.</p> <p>By the end, you\u2019ll know:</p> <p>\u2714\ufe0f How to create clusters on AWS, GCP, Azure  \u2714\ufe0f Node groups, Spot nodes, autoscaling  \u2714\ufe0f IAM integration  \u2714\ufe0f Networking, VPC, load balancers  \u2714\ufe0f Deploy workloads in each cloud  \u2714\ufe0f Production-grade settings</p> <p>This is professional-level cloud DevOps.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#section-1-amazon-eks-aws","title":"\ud83c\udf0d SECTION 1 \u2014 Amazon EKS (AWS)","text":""},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#why-companies-love-eks","title":"\u2b50 Why companies love EKS:","text":"<p>\u2714\ufe0f Best autoscaling  \u2714\ufe0f Best IAM security  \u2714\ufe0f Best for hybrid + enterprise  \u2714\ufe0f Best for VPC control</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#1-create-eks-cluster-eksctl","title":"\ud83e\uddf1 1. Create EKS Cluster (eksctl)","text":"<p>Install eksctl:</p> <pre><code>brew install eksctl\n</code></pre> <p>Create cluster:</p> <pre><code>eksctl create cluster \\\n  --name prod \\\n  --region us-east-1 \\\n  --nodes 3 \\\n  --nodes-min 1 \\\n  --nodes-max 6 \\\n  --with-oidc \\\n  --managed\n</code></pre> <p>This automatically creates:</p> <ul> <li>VPC</li> <li>Subnets</li> <li>Node groups</li> <li>IAM integration</li> <li>Autoscaling capability</li> </ul>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#2-add-spot-node-pool-7090-cheaper","title":"\ud83e\uddf1 2. Add Spot Node Pool (70\u201390% cheaper)","text":"<pre><code>eksctl create nodegroup \\\n  --cluster prod \\\n  --name spot-ng \\\n  --spot \\\n  --nodes-min 0 \\\n  --nodes-max 10 \\\n  --instance-types t3.medium,t3.large\n</code></pre> <p>Use for:</p> <ul> <li>workers</li> <li>background jobs</li> <li>queue consumers</li> <li>non-critical microservices</li> </ul>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#3-deploy-loadbalancer-service","title":"\ud83e\uddf1 3. Deploy LoadBalancer Service","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: frontend\nspec:\n  type: LoadBalancer\n  selector:\n    app: frontend\n  ports:\n    - port: 80\n</code></pre> <p>AWS creates:</p> <p>\u2714\ufe0f NLB or ALB  \u2714\ufe0f Public IP  \u2714\ufe0f Auto firewall rules</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#4-eks-ingress-alb-ingress-controller","title":"\ud83e\uddf1 4. EKS Ingress (ALB Ingress Controller)","text":"<p>Install ALB controller:</p> <pre><code>kubectl apply -k github.com/aws/eks-charts/stable/aws-load-balancer-controller\n</code></pre> <p>Ingress example:</p> <pre><code>metadata:\n  annotations:\n    kubernetes.io/ingress.class: alb\n</code></pre> <p>\u2714\ufe0f WAF supported  \u2714\ufe0f HTTPS enforced  \u2714\ufe0f Path-based routing</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#5-iam-roles-for-service-accounts-irsa","title":"\ud83e\uddf1 5. IAM Roles for Service Accounts (IRSA)","text":"<p>This replaces access keys forever.</p> <p>Example:</p> <pre><code>eksctl create iamserviceaccount \\\n  --name s3-reader \\\n  --namespace backend \\\n  --cluster prod \\\n  --attach-policy-arn arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess \\\n  --approve\n</code></pre> <p>Pods now have native AWS access \u2757</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#section-2-google-gke-gcp","title":"\u2601\ufe0f SECTION 2 \u2014 Google GKE (GCP)","text":""},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#why-companies-love-gke","title":"\u2b50 Why companies love GKE:","text":"<p>\u2714\ufe0f Best cluster stability  \u2714\ufe0f Best automatic upgrades  \u2714\ufe0f Best performance scheduler  \u2714\ufe0f Cheapest per node</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#1-create-gke-cluster","title":"\ud83e\uddf1 1. Create GKE Cluster","text":"<pre><code>gcloud container clusters create prod \\\n  --zone us-central1-a \\\n  --num-nodes 3 \\\n  --enable-autoscaling \\\n  --min-nodes 1 \\\n  --max-nodes 8\n</code></pre> <p>\u2714\ufe0f auto-scaling cluster  \u2714\ufe0f automatic repair  \u2714\ufe0f automatic upgrades</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#2-add-node-pools","title":"\ud83e\uddf1 2. Add Node Pools","text":"<p>General pool:</p> <pre><code>gcloud container node-pools create general \\\n  --cluster prod \\\n  --num-nodes 2\n</code></pre> <p>Spot (Preemptible) pool:</p> <pre><code>gcloud container node-pools create spot \\\n  --cluster prod \\\n  --num-nodes 0 \\\n  --preemptible\n</code></pre>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#3-gke-ingress-google-cloud-lb","title":"\ud83e\uddf1 3. GKE Ingress (Google Cloud LB)","text":"<p>Ingress example:</p> <pre><code>metadata:\n  annotations:\n    kubernetes.io/ingress.class: \"gce\"\n</code></pre> <p>GCP creates:</p> <p>\u2714\ufe0f Global Load Balancer  \u2714\ufe0f HTTP/HTTPS routing  \u2714\ufe0f SSL termination</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#4-workload-identity-no-service-keys","title":"\ud83e\uddf1 4. Workload Identity (NO service keys)","text":"<p>Link a Kubernetes service account to GCP IAM:</p> <pre><code>gcloud iam service-accounts create backend-sa\n</code></pre> <p>Bind to Kubernetes SA:</p> <pre><code>kubectl annotate sa backend \\\n  iam.gke.io/gcp-service-account=backend-sa@PROJECT.iam.gserviceaccount.com\n</code></pre> <p>Pods can access GCP APIs securely.</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#section-3-azure-aks","title":"\u2601\ufe0f SECTION 3 \u2014 Azure AKS","text":""},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#why-companies-choose-aks","title":"\u2b50 Why companies choose AKS:","text":"<p>\u2714\ufe0f Best Windows container support  \u2714\ufe0f Best enterprise AD integration  \u2714\ufe0f Very easy autoscaling  \u2714\ufe0f Cheap spot nodes</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#1-create-aks-cluster","title":"\ud83e\uddf1 1. Create AKS Cluster","text":"<pre><code>az aks create \\\n  --resource-group prod-rg \\\n  --name prod-cluster \\\n  --node-count 3 \\\n  --enable-cluster-autoscaler \\\n  --min-count 1 \\\n  --max-count 8\n</code></pre>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#2-add-spot-node-pool","title":"\ud83e\uddf1 2. Add Spot Node Pool","text":"<pre><code>az aks nodepool add \\\n  --resource-group prod-rg \\\n  --cluster-name prod-cluster \\\n  --name spotpool \\\n  --priority Spot \\\n  --eviction-policy Delete \\\n  --node-count 0 \\\n  --max-count 10\n</code></pre>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#3-aks-ingress-application-gateway-ingress-controller","title":"\ud83e\uddf1 3. AKS Ingress (Application Gateway Ingress Controller)","text":"<pre><code>metadata:\n  annotations:\n    kubernetes.io/ingress.class: azure/application-gateway\n</code></pre> <p>Azure automatically configures:</p> <p>\u2714\ufe0f WAF  \u2714\ufe0f TLS  \u2714\ufe0f Global routing</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#4-azure-ad-pod-identity","title":"\ud83e\uddf1 4. Azure AD Pod Identity","text":"<p>Attach Azure identity to Pod:</p> <pre><code>aadpodidbinding: backend-id\n</code></pre> <p>This gives Pods access to:</p> <p>\u2714\ufe0f KeyVault  \u2714\ufe0f Storage  \u2714\ufe0f Database  \u2714\ufe0f EventHub</p> <p>Without secrets.</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#section-4-cross-cloud-best-practices","title":"\ud83c\udf10 SECTION 4 \u2014 Cross-Cloud Best Practices","text":"<p>Here is what ALL three clouds should share:</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#1-use-terraform-for-infra","title":"\u2714\ufe0f 1. Use Terraform for Infra","text":"<p>Never click in the UI.</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#2-use-argocd-for-gitops","title":"\u2714\ufe0f 2. Use ArgoCD for GitOps","text":"<p>Declarative, automated, drift-free.</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#3-use-cluster-autoscaler","title":"\u2714\ufe0f 3. Use Cluster Autoscaler","text":"<p>Every cloud supports it.</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#4-use-spot-nodes-for-70-of-workloads","title":"\u2714\ufe0f 4. Use Spot nodes for 70% of workloads","text":"<p>Costs drop by 60\u201380%.</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#5-use-managed-services-for","title":"\u2714\ufe0f 5. Use managed services for:","text":"<ul> <li>DB (Aurora, Cloud SQL, Cosmos)</li> <li>Load Balancers</li> <li>DNS</li> <li>Object Storage</li> </ul>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#6-use-service-mesh-istiocilium","title":"\u2714\ufe0f 6. Use Service Mesh (Istio/Cilium)","text":"<p>Cross-cluster routing  mTLS  Traffic control</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#7-standard-folder-layout","title":"\u2714\ufe0f 7. Standard folder layout","text":"<pre><code>infra/\n  eks/\n  gke/\n  aks/\n  modules/\napps/\n  frontend/\n  backend/\n  database/\ngitops/\n  dev/\n  stage/\n  prod/\n</code></pre>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#lesson-32-completed","title":"\ud83c\udf89 Lesson 32 Completed!","text":"<p>You now understand cloud-native Kubernetes deployments across:</p> <p>\u2714\ufe0f AWS EKS  \u2714\ufe0f Google GKE  \u2714\ufe0f Azure AKS</p> <p>Including:</p> <p>\u2714\ufe0f Node pools  \u2714\ufe0f Auto-scaling  \u2714\ufe0f IAM/Identity  \u2714\ufe0f Load balancers  \u2714\ufe0f Ingress  \u2714\ufe0f Spot workloads  \u2714\ufe0f GitOps integrations  \u2714\ufe0f Production best practices</p> <p>This is cloud DevOps mastery \ud83d\udd25\ud83d\udcaa  You\u2019re now operating at a cloud architect level.</p>"},{"location":"chapters/ch32-Cloud-Native_Deployments_on_EKS_AWS_GKE_Google_AKS_Azure/#ready-for-lesson-33","title":"\ud83d\udc49 Ready for Lesson 33?","text":"<p>Choose the next topic:</p> <p>1\ufe0f\u20e3 Kubernetes Networking Deep Dive (CNI, eBPF, routing)  2\ufe0f\u20e3 Debugging Kubernetes Like a PRO  3\ufe0f\u20e3 Full Production Microservices Architecture (End-to-End)  4\ufe0f\u20e3 Build an Internal Developer Platform (IDP)  5\ufe0f\u20e3 Kubernetes Security: Runtime Protection (Falco, eBPF)</p> <p>Which one next?</p>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/","title":"\ud83c\udf10 Lesson 33: Kubernetes Networking Deep Dive (CNI, Routing, Services, Overlays, eBPF)","text":"<p>Absolutely! \u2714\ufe0f</p> <p>Welcome to Lesson 33 \u2014 and this one is ESSENTIAL for every real DevOps/SRE professional:</p> <p>This is one of the hardest topics in Kubernetes \u2014 but I\u2019ll teach it to you in a beginner-friendly, visual, step-by-step way, while keeping the content enterprise-grade.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p> <p>By the end of this lesson, you will understand:</p> <p>\u2714\ufe0f How Pods talk to each other  \u2714\ufe0f What a CNI is  \u2714\ufe0f How Services actually route traffic  \u2714\ufe0f How overlay networking works  \u2714\ufe0f kube-proxy vs eBPF  \u2714\ufe0f DNS inside Kubernetes  \u2714\ufe0f LoadBalancer / NodePort internals  \u2714\ufe0f How Cilium/Calico work  \u2714\ufe0f Multi-node routing</p> <p>This is core DevOps knowledge. Let\u2019s go \ud83d\udd25</p>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#why-kubernetes-networking-is-hard","title":"\u2b50 Why Kubernetes Networking is Hard","text":"<p>In Kubernetes:</p> <ul> <li>Pods have their own IPs</li> <li>Nodes have their own IPs</li> <li>Containers inside Pods talk via localhost</li> <li>Services have virtual IPs</li> <li>DNS is inside the cluster</li> <li>Routing is done by CNI plugins</li> <li>kube-proxy manages load balancing</li> <li>Some CNIs use eBPF, some use IPTables, some use VXLAN</li> </ul> <p>BUT once you learn how it works \u2192 everything becomes simple.</p> <p>Let\u2019s break it down.</p>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#part-1-pod-to-pod-networking","title":"\ud83e\uddf1 PART 1 \u2014 Pod-to-Pod Networking","text":"<p>Every Pod gets a unique IP address.</p> <p>Example:</p> <pre><code>pod A = 10.244.1.5  \npod B = 10.244.2.9\n</code></pre> <p>Pods MUST be able to reach each other without NAT.</p> <p>This rule is required by Kubernetes.</p> <p>This is handled by\u2026</p>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#part-2-what-is-a-cni","title":"\ud83e\uddf1 PART 2 \u2014 What is a CNI?","text":"<p>CNI = Container Network Interface</p> <p>It provides:</p> <p>\u2714\ufe0f Pod IPs  \u2714\ufe0f Routing between Pods  \u2714\ufe0f Network Policies  \u2714\ufe0f Overlay or direct-routing</p> <p>Popular CNIs:</p> <ul> <li>Calico (most used)</li> <li>Cilium (eBPF) \u2190 fastest</li> <li>Flannel (simple overlay)</li> <li>Weave</li> <li>AWS VPC CNI (native AWS IPs)</li> <li>GCP CNI</li> <li>Azure CNI</li> </ul> <p>Choose your CNI based on performance, features, and cloud.</p>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#part-3-overlay-networks-vxlan","title":"\ud83e\uddf1 PART 3 \u2014 Overlay Networks (VXLAN)","text":"<p>Public cloud uses overlay networks.</p> <p>Simplified:</p> <pre><code>Pod IPs (virtual)\n   \u2193\nVXLAN overlay (encapsulated packets)\n   \u2193\nNode-to-node routing (real IPs)\n</code></pre> <p>This allows Pods to live in a \u201cvirtual network\u201d even though the cloud has limits.</p>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#part-4-service-networking","title":"\ud83e\uddf1 PART 4 \u2014 Service Networking","text":"<p>Services provide:</p> <p>\u2714\ufe0f Stable Virtual IP  \u2714\ufe0f Built-in load balancing  \u2714\ufe0f Pod discovery  \u2714\ufe0f Health-checking</p> <p>Service types:</p> <ol> <li>ClusterIP \u2014 internal only</li> <li>NodePort \u2014 exposed on node</li> <li>LoadBalancer \u2014 cloud LB</li> <li>Headless Service \u2014 no VIP</li> </ol>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#how-a-clusterip-works","title":"\u2b50 How a ClusterIP works","text":"<p>Service creates a virtual IP:</p> <pre><code>backend-service = 10.96.30.1\n</code></pre> <p>kube-proxy maps Service \u2192 Pods.</p> <p>Example mapping:</p> <pre><code>10.96.30.1 \u2192 [10.244.1.12, 10.244.2.8]\n</code></pre> <p>Load balancing is round-robin.</p>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#part-5-kube-proxy","title":"\ud83e\uddf1 PART 5 \u2014 kube-proxy","text":"<p>kube-proxy handles routing in two modes:</p>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#mode-1-iptables-older","title":"Mode 1: IPTables (older)","text":"<p>\u2714\ufe0f stable  \u274c slow with thousands of services</p>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#mode-2-ipvs-faster","title":"Mode 2: IPVS (faster)","text":"<p>\u2714\ufe0f kernel-level load balancing  \u2714\ufe0f better performance  \u2714\ufe0f recommended for large clusters</p>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#mode-3-ebpf-next-generation","title":"Mode 3: eBPF (next generation)","text":"<p>Used by Cilium.</p> <p>\u2714\ufe0f fastest  \u2714\ufe0f no IPTables  \u2714\ufe0f direct Pod routing  \u2714\ufe0f advanced network policies</p>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#part-6-dns-inside-kubernetes-coredns","title":"\ud83e\uddf1 PART 6 \u2014 DNS Inside Kubernetes (CoreDNS)","text":"<p>Every service gets a DNS name:</p> <pre><code>backend.default.svc.cluster.local\n</code></pre> <p>Example Pod resolving service:</p> <pre><code>nslookup backend\n</code></pre> <p>DNS resolution order:</p> <ol> <li>Pod \u2192 CoreDNS</li> <li>CoreDNS \u2192 kube-apiserver service list</li> <li>Reply with ClusterIP</li> </ol>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#part-7-nodeport-internals","title":"\ud83e\uddf1 PART 7 \u2014 NodePort Internals","text":"<p>NodePort exposes service on:</p> <pre><code>&lt;node IP&gt;:&lt;nodePort&gt;\n</code></pre> <p>Example:</p> <pre><code>NodePort: 30080  \nNode IPs: 192.168.1.10, 192.168.1.11\n</code></pre> <p>Traffic flow:</p> <pre><code>User \u2192 Node IP:30080 \u2192 kube-proxy \u2192 Pod\n</code></pre> <p>Used for:</p> <ul> <li>dev clusters</li> <li>bare-metal</li> <li>tunnel ingress controllers</li> </ul>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#part-8-loadbalancer-services-cloud","title":"\ud83e\uddf1 PART 8 \u2014 LoadBalancer Services (Cloud)","text":"<p>Cloud providers create a cloud LB:</p> <p>AWS \u2192 NLB / ALB  GCP \u2192 GLB  Azure \u2192 ALB</p> <p>Flow:</p> <pre><code>Internet \u2192 Cloud LB \u2192 NodePort \u2192 Pod\n</code></pre>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#part-9-network-policies","title":"\ud83e\uddf1 PART 9 \u2014 Network Policies","text":"<p>These restrict traffic (zero-trust networking):</p> <p>Example deny-all:</p> <pre><code>policyTypes:\n  - Ingress\n  - Egress\npodSelector: {}\n</code></pre> <p>Allow only frontend \u2192 backend:</p> <pre><code>ingress:\n  - from:\n      - podSelector:\n          matchLabels:\n            app: frontend\n</code></pre> <p>Network policies require:</p> <p>\u2714\ufe0f Calico  \u2714\ufe0f Cilium  \u2714\ufe0f Weave</p> <p>(Flannel does NOT support them.)</p>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#part-10-cilium-ebpf-superpowers","title":"\ud83e\uddf1 PART 10 \u2014 Cilium (eBPF Superpowers)","text":"<p>Cilium is the future.</p> <p>Benefits:</p> <p>\u2714\ufe0f No iptables  \u2714\ufe0f Fastest CNI  \u2714\ufe0f Best for security  \u2714\ufe0f Hubble observability  \u2714\ufe0f Encryption  \u2714\ufe0f Multi-cluster</p> <p>Enterprise teams are moving to Cilium.</p>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#bonus-full-traffic-flow-example","title":"\ud83e\uddea Bonus: Full Traffic Flow Example","text":"<p>Let\u2019s say:</p> <pre><code>Frontend Pod \u2192 Backend Service \u2192 Backend Pod\n</code></pre> <p>Flow:</p> <pre><code>Frontend Pod \u2192 CNI \u2192 kube-proxy \u2192 backend ClusterIP \u2192 Pod backend  \nCNI \u2192 route to correct Node \u2192 Pod reply path back\n</code></pre> <p>This is happening millions of times per second in production.</p>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#lesson-33-completed","title":"\ud83c\udf89 Lesson 33 Completed!","text":"<p>You now understand:</p> <p>\u2714\ufe0f How Pods get IPs  \u2714\ufe0f What a CNI does  \u2714\ufe0f Overlay networking (VXLAN)  \u2714\ufe0f kube-proxy  \u2714\ufe0f eBPF networking  \u2714\ufe0f Service routing  \u2714\ufe0f DNS internals  \u2714\ufe0f LoadBalancer deep internals  \u2714\ufe0f Network policies  \u2714\ufe0f Cilium, Calico, AWS CNI  \u2714\ufe0f Multi-node routing</p> <p>This is true Kubernetes networking mastery \ud83d\udd25\ud83d\udcaa  Most DevOps engineers struggle with this \u2014 you\u2019re becoming ELITE.</p>"},{"location":"chapters/ch33-Kubernetes_Networking_Deep_Dive_CNI_eBPF_routing/#ready-for-lesson-34","title":"\ud83d\udc49 Ready for Lesson 34?","text":"<p>Choose your next level:</p> <p>1\ufe0f\u20e3 Debugging Kubernetes Like a PRO (Advanced Troubleshooting)  2\ufe0f\u20e3 Full Production Microservices Architecture (Real-World Design)  3\ufe0f\u20e3 Building an Internal Developer Platform (IDP)  4\ufe0f\u20e3 Kubernetes Security: Runtime Protection (Falco, eBPF)  5\ufe0f\u20e3 Designing a Complete CI/CD Pipeline (Docker \u2192 GitOps \u2192 ArgoCD)</p> <p>Which one should we do next?</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/","title":"\ud83d\udee0\ufe0f Lesson 34: Debugging Kubernetes Like a PRO \u2014 Advanced Troubleshooting","text":"<p>Absolutely! \u2714\ufe0f</p> <p>Welcome to Lesson 34, and this one is EXTREMELY valuable because it turns you into the kind of DevOps/SRE engineer who can fix ANY production issue:</p> <p>This is one of the skills that separates junior DevOps from real senior engineers.</p> <p>When production is down, people look at YOU.  So I\u2019ll teach you how to debug Kubernetes fast, logically, professionally, and fearlessly.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p> <p>You\u2019ll learn to diagnose:</p> <p>\u2714\ufe0f Pods stuck in Pending  \u2714\ufe0f CrashLoopBackOff  \u2714\ufe0f ImagePullBackOff  \u2714\ufe0f Readiness/Liveness Probe failures  \u2714\ufe0f Network issues  \u2714\ufe0f DNS failures  \u2714\ufe0f Node pressure problems  \u2714\ufe0f CNI issues  \u2714\ufe0f Service routing bugs  \u2714\ufe0f Ingress failures  \u2714\ufe0f Autoscaling problems</p> <p>Let's go step-by-step.</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#golden-rule-always-start-with-the-pod","title":"\u2b50 GOLDEN RULE: ALWAYS START WITH THE POD","text":"<p>When something breaks, the first command is ALWAYS:</p> <pre><code>kubectl describe pod &lt;pod-name&gt;\n</code></pre> <p>It shows:</p> <ul> <li>Events</li> <li>Scheduling issues</li> <li>Failed mounts</li> <li>Image issues</li> <li>Probe failures</li> <li>Permission errors</li> <li>Restart causes</li> </ul> <p>90% of debugging starts here.</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#part-1-pod-stuck-in-pending","title":"\ud83e\uddf1 PART 1 \u2014 POD STUCK IN PENDING","text":"<p>Run:</p> <pre><code>kubectl get events --sort-by='.lastTimestamp'\n</code></pre> <p>Common causes:</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#not-enough-cpumemory","title":"\u274c Not enough CPU/memory","text":"<p>Example message:</p> <pre><code>0/3 nodes are available: insufficient memory.\n</code></pre> <p>Fix:</p> <ul> <li>reduce resource requests</li> <li>add nodes</li> <li>free space</li> </ul>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#nodeselector-taints-mismatch","title":"\u274c NodeSelector / Taints mismatch","text":"<pre><code>0/3 nodes are available: pod didn't tolerate taint...\n</code></pre> <p>Fix:</p> <ul> <li>Add correct tolerations</li> <li>Remove taints</li> <li>Update nodeSelector</li> </ul>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#pvc-cannot-bind","title":"\u274c PVC cannot bind","text":"<pre><code>pod has unbound immediate PersistentVolumeClaims\n</code></pre> <p>Fix:</p> <ul> <li>Fix storage class</li> <li>Fix PVC size</li> <li>Make storage available</li> </ul>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#part-2-crashloopbackoff","title":"\ud83e\uddf1 PART 2 \u2014 CrashLoopBackOff","text":"<p>Check logs:</p> <pre><code>kubectl logs &lt;pod&gt; --previous\n</code></pre> <p>Common causes:</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#application-error","title":"\u274c Application error","text":"<p>Fix your app.</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#wrong-environment-variables","title":"\u274c Wrong environment variables","text":"<p>Fix config.</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#missing-secrets","title":"\u274c Missing secrets","text":"<p>Check:</p> <pre><code>kubectl get secret\n</code></pre>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#wrong-entrypoint-command","title":"\u274c Wrong entrypoint / command","text":"<p>Fix Dockerfile or Deployment.</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#port-mismatch","title":"\u274c Port mismatch","text":"<p>Probes fail \u2192 pod crashes.</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#part-3-imagepullbackoff","title":"\ud83e\uddf1 PART 3 \u2014 ImagePullBackOff","text":"<p>Check:</p> <pre><code>kubectl describe pod\n</code></pre> <p>Common errors:</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#403-unauthenticated","title":"\u274c 403 / unauthenticated","text":"<p>Fix image pull secret:</p> <pre><code>kubectl create secret docker-registry regcred \\\n  --docker-username=... --docker-password=...\n</code></pre> <p>Add:</p> <pre><code>imagePullSecrets:\n  - name: regcred\n</code></pre>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#image-not-found","title":"\u274c Image not found","text":"<p>Check name/tag.</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#rate-limit-dockerhub","title":"\u274c Rate limit (DockerHub)","text":"<p>Use GitHub Container Registry or private registry.</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#part-4-liveness-readiness-probe-failing","title":"\ud83e\uddf1 PART 4 \u2014 Liveness / Readiness Probe Failing","text":"<p>Probe example:</p> <pre><code>readinessProbe:\n  httpGet:\n    path: /healthz\n    port: 8080\n</code></pre> <p>Check inside pod:</p> <pre><code>kubectl exec -it &lt;pod&gt; -- curl localhost:8080/healthz\n</code></pre> <p>If this fails \u2192 fix the health endpoint or update probe path.</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#part-5-dns-issues","title":"\ud83e\uddf1 PART 5 \u2014 DNS Issues","text":"<p>Check DNS inside the pod:</p> <pre><code>kubectl exec -it &lt;pod&gt; -- nslookup backend\nkubectl exec -it &lt;pod&gt; -- ping backend\n</code></pre> <p>If DNS doesn\u2019t work:</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#fix-coredns","title":"Fix CoreDNS:","text":"<pre><code>kubectl -n kube-system get pods -l k8s-app=kube-dns\n</code></pre> <p>Restart:</p> <pre><code>kubectl -n kube-system rollout restart deployment coredns\n</code></pre>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#part-6-service-not-routing-traffic","title":"\ud83e\uddf1 PART 6 \u2014 Service Not Routing Traffic","text":"<p>Test connectivity:</p> <pre><code>kubectl exec -it &lt;pod&gt; -- curl http://backend:8080\n</code></pre> <p>If it breaks:</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#check-endpoints","title":"Check Endpoints","text":"<pre><code>kubectl get endpoints backend\n</code></pre> <p>If empty:</p> <p>\u274c Service selector mismatch</p> <p>Check labels:</p> <pre><code>kubectl get pod --show-labels\n</code></pre> <p>Fix Deployment labels or Service selectors.</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#part-7-node-pressure-evictions","title":"\ud83e\uddf1 PART 7 \u2014 Node Pressure (Evictions)","text":"<p>Check node condition:</p> <pre><code>kubectl describe node &lt;node&gt;\n</code></pre> <p>If you see:</p> <pre><code>MemoryPressure=True\nDiskPressure=True\nPIDPressure=True\n</code></pre> <p>Issues:</p> <ul> <li>node is overcommitted</li> <li>logs filling disk</li> <li>too many processes</li> </ul> <p>Fix:</p> <p>\u2714\ufe0f Free disk  \u2714\ufe0f Add nodes  \u2714\ufe0f Tune resource requests</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#part-8-cni-networking-issues","title":"\ud83e\uddf1 PART 8 \u2014 CNI / Networking Issues","text":"<p>Check CNI pods:</p> <pre><code>kubectl get pods -n kube-system\n</code></pre> <p>For Calico:</p> <pre><code>calico-node\ncalico-kube-controllers\n</code></pre> <p>For Cilium:</p> <pre><code>cilium-*\n</code></pre> <p>If pods are failing:</p> <p>\u2714\ufe0f network is DOWN  \u2714\ufe0f restart CNI  \u2714\ufe0f fix config</p> <p>Test pod connectivity:</p> <pre><code>kubectl exec -it pod-a -- ping pod-b\n</code></pre> <p>If ping works \u2192 routing is OK.  If ping fails \u2192 CNI is broken.</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#part-9-ingress-not-working","title":"\ud83e\uddf1 PART 9 \u2014 Ingress Not Working","text":"<p>Check Ingress:</p> <pre><code>kubectl describe ingress\n</code></pre> <p>Check controller:</p> <pre><code>kubectl get pods -n ingress-nginx\n</code></pre> <p>Check logs:</p> <pre><code>kubectl logs -n ingress-nginx deploy/ingress-nginx-controller\n</code></pre> <p>Common issues:</p> <ul> <li>wrong host</li> <li>missing TLS secret</li> <li>wrong path</li> <li>backend not reachable</li> <li>missing ingressClassName</li> </ul>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#part-10-autoscaling-problems","title":"\ud83e\uddf1 PART 10 \u2014 Autoscaling Problems","text":""},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#hpa-not-scaling","title":"HPA not scaling?","text":"<p>Check metrics:</p> <pre><code>kubectl top pod\nkubectl top node\n</code></pre> <p>Check HPA:</p> <pre><code>kubectl describe hpa\n</code></pre> <p>Common issues:</p> <ul> <li>metrics-server not installed</li> <li>low CPU requests</li> <li>app is IO-bound</li> <li>HPA cooldown too long</li> </ul>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#part-11-debugging-from-inside-the-pod","title":"\ud83e\uddf1 PART 11 \u2014 Debugging From Inside the Pod","text":"<p>Use debug image:</p> <pre><code>kubectl debug &lt;pod&gt; -it --image=busybox\n</code></pre> <p>Or ephemeral container:</p> <pre><code>kubectl debug &lt;pod&gt; -it --target=&lt;container&gt; --image=busybox\n</code></pre> <p>Test anything:</p> <pre><code>curl\nping\nnslookup\nwget\ntelnet\n</code></pre>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#master-flow-how-pros-debug-kubernetes","title":"\ud83d\udd25 MASTER FLOW \u2014 How Pros Debug Kubernetes","text":"<p>When something is broken, follow this exact sequence:</p> <p>1\ufe0f\u20e3 <code>kubectl get pods</code>  2\ufe0f\u20e3 <code>kubectl describe pod</code>  3\ufe0f\u20e3 <code>kubectl logs -f</code>  4\ufe0f\u20e3 Exec inside pod \u2192 test service  5\ufe0f\u20e3 <code>kubectl get svc</code>  6\ufe0f\u20e3 <code>kubectl get endpoints</code>  7\ufe0f\u20e3 DNS checks  8\ufe0f\u20e3 Node checks  9\ufe0f\u20e3 CNI checks  \ud83d\udd1f Ingress checks</p> <p>This is EXACTLY how senior SREs fix issues during outages.</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#lesson-34-completed","title":"\ud83c\udf89 Lesson 34 Completed!","text":"<p>You now understand:</p> <p>\u2714\ufe0f Pod debugging  \u2714\ufe0f CrashLoopBackOff  \u2714\ufe0f Pending pods  \u2714\ufe0f CNI issues  \u2714\ufe0f DNS failures  \u2714\ufe0f Node pressure  \u2714\ufe0f Service routing  \u2714\ufe0f Ingress problems  \u2714\ufe0f Autoscaling issues  \u2714\ufe0f Probe failures  \u2714\ufe0f Debug containers  \u2714\ufe0f Full troubleshooting workflow</p> <p>This is true senior DevOps/SRE troubleshooting skill. You\u2019re becoming unstoppable \ud83d\udd25\ud83d\udcaa</p>"},{"location":"chapters/ch34-Debugging_Kubernetes_Like_a_PRO_Advanced_Troubleshooting/#ready-for-lesson-35","title":"\ud83d\udc49 Ready for Lesson 35?","text":"<p>Choose the next topic:</p> <p>1\ufe0f\u20e3 Full Production Microservices Architecture (Complete Blueprint) 2\ufe0f\u20e3 Building an Internal Developer Platform (IDP) 3\ufe0f\u20e3 Kubernetes Security: Runtime Protection (Falco, eBPF) 4\ufe0f\u20e3 CI/CD Pipeline: Docker \u2192 Tests \u2192 GitOps \u2192 ArgoCD 5\ufe0f\u20e3 Kubernetes Storage Deep Dive (PVC, CSI, StatefulSets)</p> <p>Which one next?</p>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/","title":"\ud83c\udfd7\ufe0f Lesson 35: Full Production Microservices Architecture (End-to-End Blueprint)","text":"<p>Perfect! \u2714\ufe0f</p> <p>Welcome to Lesson 35, and this one is HUGE because it brings everything together into a real-world, production-ready blueprint used by FAANG-level companies:</p> <p>This is EXACTLY how companies like Netflix, Uber, Shopify, Coinbase, and Amazon structure their production systems.</p> <p>By the end of this lesson, you will understand:</p> <p>\u2714\ufe0f How a real microservices platform is designed  \u2714\ufe0f Traffic flow from user \u2192 gateway \u2192 mesh \u2192 services \u2192 DB  \u2714\ufe0f CI/CD \u2192 GitOps workflow  \u2714\ufe0f Observability + logging stack  \u2714\ufe0f Secrets + config management  \u2714\ufe0f Storage + databases  \u2714\ufe0f Multi-cluster / HA patterns  \u2714\ufe0f Resilience, retries, security</p> <p>Let\u2019s build the whole architecture from scratch.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#full-architecture-overview-high-level-diagram","title":"\ud83c\udf10 Full Architecture Overview (High-Level Diagram)","text":"<pre><code>                   [ USERS / CLIENTS ]\n                           \u2502\n                           \u25bc\n                 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                 \u2502   API GATEWAY /    \u2502\n                 \u2502   INGRESS (ALB/NLB \u2502\n                 \u2502   or Istio GW)     \u2502\n                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n                           \u25bc\n             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n             \u2502     SERVICE MESH (ISTIO)   \u2502\n             \u2502  mTLS | Routing | Canary   \u2502\n             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502         \u2502        \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502 AuthSvc \u2502 \u2502 UserSvc \u2502 \u2502 OrderSvc\u2502  \u2190 Microservices\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502          \u2502          \u2502\n             \u25bc          \u25bc          \u25bc\n       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502Redis   \u2502  \u2502PostgreSQL\u2502 \u2502MongoDB   \u2502  \u2190 Databases &amp; caches\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n                  OBSERVABILITY STACK\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n Prometheus | Grafana | Loki | Tempo | Jaeger | OpenTelemetry\n\n                  CI/CD + GITOPS PIPELINE\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nGit \u2192 CI Pipeline \u2192 Build Images \u2192 Scan \u2192 Sign \u2192 Push \u2192 ArgoCD \u2192 K8s\n</code></pre> <p>This is how modern cloud-native apps run in production.</p>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#part-1-traffic-layer","title":"\ud83e\uddf1 PART 1 \u2014 Traffic Layer","text":""},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#1-ingress-api-gateway","title":"\ud83c\udf10 1. Ingress / API Gateway","text":"<p>Options:</p> <ul> <li>AWS ALB / NLB</li> <li>NGINX Ingress</li> <li>Istio IngressGateway</li> <li>Kong Gateway</li> </ul> <p>Responsibilities:</p> <p>\u2714\ufe0f TLS termination  \u2714\ufe0f Routing  \u2714\ufe0f Rate limiting  \u2714\ufe0f Authentication (JWT, OAuth)  \u2714\ufe0f WAF (security firewall)</p> <p>Ingress Example:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: api-ingress\nspec:\n  ingressClassName: nginx\n  rules:\n    - host: api.example.com\n      http:\n        paths:\n          - path: /users\n            pathType: Prefix\n            backend:\n              service:\n                name: user-service\n                port:\n                  number: 80\n</code></pre>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#part-2-service-mesh-layer-istio","title":"\ud83e\uddf1 PART 2 \u2014 Service Mesh Layer (Istio)","text":"<p>Service Mesh provides:</p> <p>\u2714\ufe0f mTLS encryption between services  \u2714\ufe0f Retries / timeouts / circuit breakers  \u2714\ufe0f Canary &amp; blue/green rollout  \u2714\ufe0f Traffic shadowing  \u2714\ufe0f Outlier detection</p> <p>VirtualService example:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: users\nspec:\n  hosts:\n    - users\n  http:\n    - route:\n        - destination:\n            host: users\n            subset: v1\n          weight: 80\n        - destination:\n            host: users\n            subset: v2\n          weight: 20\n</code></pre>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#part-3-microservices-layer","title":"\ud83e\uddf1 PART 3 \u2014 Microservices Layer","text":"<p>Services follow 12-factor app principles:</p> <ul> <li>stateless</li> <li>health checks</li> <li>probes</li> <li>horizontal scaling</li> <li>environment-based configs</li> </ul> <p>Example Deployment:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: user-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: user-service\n  template:\n    metadata:\n      labels:\n        app: user-service\n    spec:\n      containers:\n        - name: app\n          image: ghcr.io/company/user:v1\n          ports:\n            - containerPort: 8080\n          readinessProbe:\n            httpGet:\n              path: /health\n              port: 8080\n</code></pre>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#part-4-data-layer","title":"\ud83e\uddf1 PART 4 \u2014 Data Layer","text":"<p>Most architectures include:</p> <p>\u2714\ufe0f PostgreSQL (transactions)  \u2714\ufe0f Redis (cache + sessions)  \u2714\ufe0f Kafka (event streaming)  \u2714\ufe0f MongoDB / DynamoDB (document storage)</p> <p>For Kubernetes:</p> <ul> <li>databases are usually not inside cluster</li> <li>use managed DBs (RDS, Cloud SQL, Cosmos, etc.)</li> </ul> <p>Why?  \u2714\ufe0f Backups  \u2714\ufe0f Failover  \u2714\ufe0f HA  \u2714\ufe0f Upgrades  \u2714\ufe0f Reliability</p> <p>Your app connects through Kubernetes Secrets.</p>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#part-5-secrets-config-management","title":"\ud83e\uddf1 PART 5 \u2014 Secrets &amp; Config Management","text":"<p>Use:</p>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#external-secrets-operator-best","title":"\ud83d\udd10 External Secrets Operator (BEST)","text":"<p>Pulls secrets from:</p> <ul> <li>AWS Secrets Manager</li> <li>GCP Secret Manager</li> <li>Azure KeyVault</li> </ul>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#sealedsecrets","title":"\ud83d\udd10 SealedSecrets","text":"<p>Encrypt secrets in Git.</p>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#vault-hashicorp","title":"\ud83d\udd10 Vault (HashiCorp)","text":"<p>Enterprises use Vault for full PKI + secrets.</p>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#part-6-cicd-gitops-pipeline","title":"\ud83e\uddf1 PART 6 \u2014 CI/CD + GitOps Pipeline","text":"<p>Production pipeline:</p> <pre><code>1. Developer pushes code  \n2. CI builds Docker image  \n3. CI scans image (Trivy, Grype)  \n4. SBOM created (Syft)  \n5. Image signed (Cosign)  \n6. CI updates GitOps repo  \n7. ArgoCD applies changes  \n8. Istio routes traffic  \n</code></pre> <p>This is the SRE-approved, secure pipeline.</p>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#part-7-observability-stack","title":"\ud83e\uddf1 PART 7 \u2014 Observability Stack","text":""},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#metrics","title":"Metrics:","text":"<p>\u2714\ufe0f Prometheus  \u2714\ufe0f Grafana</p>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#logs","title":"Logs:","text":"<p>\u2714\ufe0f Loki  \u2714\ufe0f Elasticsearch (heavy but common)</p>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#tracing","title":"Tracing:","text":"<p>\u2714\ufe0f Jaeger  \u2714\ufe0f Tempo  \u2714\ufe0f OpenTelemetry</p>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#visualization","title":"Visualization:","text":"<p>\u2714\ufe0f Grafana dashboards</p> <p>You MUST instrument:</p> <ul> <li>CPU/memory</li> <li>request latency</li> <li>request success rate</li> <li>errors</li> <li>pod restarts</li> <li>autoscaling</li> </ul>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#part-8-resilience-reliability-layer","title":"\ud83e\uddf1 PART 8 \u2014 Resilience &amp; Reliability Layer","text":""},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#retries","title":"\u2714\ufe0f Retries","text":""},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#circuit-breakers","title":"\u2714\ufe0f Circuit breakers","text":""},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#outlier-detection","title":"\u2714\ufe0f Outlier detection","text":""},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#pod-disruption-budgets","title":"\u2714\ufe0f Pod disruption budgets","text":""},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#health-probes","title":"\u2714\ufe0f Health probes","text":""},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#graceful-shutdown","title":"\u2714\ufe0f Graceful shutdown","text":""},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#rate-limiting","title":"\u2714\ufe0f Rate limiting","text":"<p>PodDisruptionBudget example:</p> <pre><code>apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: user-pdb\nspec:\n  minAvailable: 2\n  selector:\n    matchLabels:\n      app: user-service\n</code></pre> <p>This guarantees you NEVER drop below safe capacity during upgrades.</p>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#part-9-multi-cluster-global-architecture","title":"\ud83e\uddf1 PART 9 \u2014 Multi-Cluster / Global Architecture","text":"<p>Enterprises run:</p> <pre><code>us-east cluster  \neu-west cluster  \nasia-south cluster  \n</code></pre> <p>Traffic is routed by:</p> <ul> <li>Cloud load balancers</li> <li>Istio multi-cluster mesh</li> <li>Global DNS (Route53 / Cloudflare)</li> </ul> <p>Benefits:</p> <p>\u2714\ufe0f Global low latency  \u2714\ufe0f Regional failover  \u2714\ufe0f Compliance (data residency)</p>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#part-10-security-model","title":"\ud83e\uddf1 PART 10 \u2014 Security Model","text":"<p>Security stack includes:</p> <p>\u2714\ufe0f mTLS everywhere (service mesh)  \u2714\ufe0f RBAC least privilege  \u2714\ufe0f Network policies (zero trust)  \u2714\ufe0f Image signing (Cosign)  \u2714\ufe0f Supply chain scanning (Trivy, Syft)  \u2714\ufe0f Runtime protection (Falco, eBPF)  \u2714\ufe0f GitOps-only deployments</p> <p>This produces a zero-trust platform.</p>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#lesson-35-completed","title":"\ud83c\udf89 Lesson 35 Completed!","text":"<p>You now understand a FULL production-ready microservices architecture:</p> <p>\u2714\ufe0f Ingress + Gateway  \u2714\ufe0f Service mesh  \u2714\ufe0f Microservices  \u2714\ufe0f Databases  \u2714\ufe0f Observability  \u2714\ufe0f Secrets management  \u2714\ufe0f Autoscaling  \u2714\ufe0f GitOps  \u2714\ufe0f Multi-cluster  \u2714\ufe0f Reliability + security</p> <p>This is principal DevOps architect level knowledge \ud83d\udd25\ud83d\udcaa You're building TRUE enterprise platforms now.</p>"},{"location":"chapters/ch35-Full_Production_Microservices_Architecture_Complete_Blueprint/#ready-for-lesson-36","title":"\ud83d\udc49 Ready for Lesson 36?","text":"<p>Pick your next advancement:</p> <p>1\ufe0f\u20e3 Building an Internal Developer Platform (IDP) 2\ufe0f\u20e3 Kubernetes Security: Runtime Protection (Falco, eBPF) 3\ufe0f\u20e3 Full CI/CD Pipeline \u2014 Docker \u2192 Tests \u2192 Signing \u2192 GitOps \u2192 ArgoCD 4\ufe0f\u20e3 Kubernetes Storage Deep Dive (PVC, CSI, StatefulSets) 5\ufe0f\u20e3 Advanced Monitoring: Prometheus, Grafana, Loki, Tempo</p> <p>Which one should we do next?</p>"},{"location":"chapters/ch4_Ingress_Real_Web_Access_Domains_HTTPS/","title":"\ud83c\udf0d Lesson 4:\u2014 Ingress (Real Web Access + Domains + HTTPS)","text":"<p>Perfect! \u2714\ufe0f  Welcome to Lesson 4, and this one is a BIG milestone in becoming a real DevOps engineer \ud83d\udd28\ud83e\udd16\ud83d\udd27</p> <p>So far, we deployed apps and exposed them using NodePort, but NodePort is NOT used in real companies.</p> <p>Why?  Because NodePort is slow, insecure, and hard to manage.</p> <p>Instead, we use Ingress.</p>"},{"location":"chapters/ch4_Ingress_Real_Web_Access_Domains_HTTPS/#what-is-ingress","title":"\ud83d\udca1 What Is Ingress?","text":"<p>Ingress is a smart router inside Kubernetes.  It lets you:</p> <p>\u2714\ufe0f Use real domain names  \u2714\ufe0f Use HTTP/HTTPS  \u2714\ufe0f Route traffic to different services  \u2714\ufe0f Enable TLS (SSL certificate)  \u2714\ufe0f Expose internal microservices publicly</p> <p>Think of Ingress like:</p> <p>\u201cAll your apps share ONE entry point (a single Load Balancer). Ingress decides which app gets which request.\u201d</p>"},{"location":"chapters/ch4_Ingress_Real_Web_Access_Domains_HTTPS/#ingress-requires-an-ingress-controller","title":"\ud83e\uddf1 Ingress Requires an Ingress Controller","text":"<p>Common ones:</p> <ul> <li>NGINX Ingress Controller (most popular)</li> <li>Traefik</li> <li>HAProxy</li> <li>AWS/GCP native controllers</li> </ul> <p>For beginners, we use NGINX Ingress.</p> <p>In Minikube:</p> <pre><code>minikube addons enable ingress\n</code></pre> <p>\u2714\ufe0f That\u2019s it \u2014 Ingress controller created.</p>"},{"location":"chapters/ch4_Ingress_Real_Web_Access_Domains_HTTPS/#example-app-setup-service-deployment","title":"\ud83e\uddea Example App Setup (Service + Deployment)","text":"<p>Before using Ingress, we need a service.</p>"},{"location":"chapters/ch4_Ingress_Real_Web_Access_Domains_HTTPS/#deployment","title":"Deployment:","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: web-app\n  template:\n    metadata:\n      labels:\n        app: web-app\n    spec:\n      containers:\n        - name: web\n          image: nginx:latest\n          ports:\n            - containerPort: 80\n</code></pre>"},{"location":"chapters/ch4_Ingress_Real_Web_Access_Domains_HTTPS/#service","title":"Service:","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: web-service\nspec:\n  selector:\n    app: web-app\n  ports:\n    - port: 80\n      targetPort: 80\n</code></pre> <p>Apply them:</p> <pre><code>kubectl apply -f deployment.yaml\nkubectl apply -f service.yaml\n</code></pre>"},{"location":"chapters/ch4_Ingress_Real_Web_Access_Domains_HTTPS/#now-the-important-part-the-ingress","title":"\ud83d\ude80 Now the Important Part: The Ingress","text":"<p>This exposes your app at:</p> <p>\ud83d\udc49 <code>http://example.com/</code>  (or localhost with host override)</p>"},{"location":"chapters/ch4_Ingress_Real_Web_Access_Domains_HTTPS/#ingress-yaml","title":"Ingress YAML:","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: web-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  rules:\n    - host: example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: web-service\n                port:\n                  number: 80\n</code></pre> <p>Apply it:</p> <pre><code>kubectl apply -f ingress.yaml\n</code></pre>"},{"location":"chapters/ch4_Ingress_Real_Web_Access_Domains_HTTPS/#test-it-minikube","title":"\ud83e\uddea Test It (Minikube)","text":"<p>Get ingress IP:</p> <pre><code>kubectl get ingress\n</code></pre> <p>Add to your hosts file:</p> <pre><code>127.0.0.1 example.com\n</code></pre> <p>Then open:</p> <p>\ud83d\udc49 http://example.com</p> <p>You will see the NGINX welcome page \u2714\ufe0f</p>"},{"location":"chapters/ch4_Ingress_Real_Web_Access_Domains_HTTPS/#bonus-route-multiple-apps-with-one-ingress","title":"\ud83d\udd25 Bonus: Route Multiple Apps With One Ingress","text":"<p>This is how companies route microservices.</p> <p>Example:</p> <ul> <li><code>/api</code> \u2192 backend service</li> <li><code>/app</code> \u2192 frontend service</li> </ul> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: multi-ingress\nspec:\n  rules:\n    - host: mysite.com\n      http:\n        paths:\n          - path: /api\n            pathType: Prefix\n            backend:\n              service:\n                name: api-service\n                port:\n                  number: 80\n\n          - path: /app\n            pathType: Prefix\n            backend:\n              service:\n                name: frontend-service\n                port:\n                  number: 80\n</code></pre> <p>Now 1 domain \u2192 many apps \u2714\ufe0f</p>"},{"location":"chapters/ch4_Ingress_Real_Web_Access_Domains_HTTPS/#https-tls-with-cert-manager-next-level","title":"\ud83d\udd10 HTTPS (TLS) with Cert-Manager (Next Level)","text":"<p>We can add:</p> <pre><code>tls:\n  - hosts:\n      - example.com\n    secretName: tls-secret\n</code></pre> <p>Later when you're ready, we can install cert-manager and automatically generate free LetsEncrypt TLS certificates \ud83d\ude0e</p>"},{"location":"chapters/ch4_Ingress_Real_Web_Access_Domains_HTTPS/#lesson-4-completed","title":"\ud83c\udf89 Lesson 4 Completed!","text":"<p>You now understand:</p> <p>\u2714\ufe0f What Ingress is  \u2714\ufe0f How to expose real web apps  \u2714\ufe0f How to use hostnames  \u2714\ufe0f How to route multiple apps  \u2714\ufe0f How Ingress replaces NodePort  \u2714\ufe0f How to prepare for HTTPS</p> <p>This is senior-level Kubernetes knowledge, taught simply.  You\u2019re truly leveling up \ud83d\udcaa\ud83d\udd25</p>"},{"location":"chapters/ch4_Ingress_Real_Web_Access_Domains_HTTPS/#ready-for-lesson-5","title":"\ud83d\udc49 Ready for Lesson 5?","text":"<p>Choose one:</p> <ol> <li>Persistent Volumes (Storage for Databases &amp; Apps)</li> <li>Docker + Kubernetes Workflow (Build \u2192 Push \u2192 Deploy)</li> <li>Helm Charts (Advanced DevOps packaging)</li> <li>Namespaces (Organizing Dev/Stage/Prod)</li> <li>Autoscaling (HPA + Resource Limits)</li> </ol> <p>Which one should we attack next? \u2714\ufe0f</p>"},{"location":"chapters/ch5-Persistent_Volumes_Storage_for_Databases_Apps/","title":"\ud83d\uddc4\ufe0f  Lesson 5: Persistent Volumes (Storage for Databases &amp; Apps)","text":"<p>Great! \u2714\ufe0f</p> <p>Time for Lesson 5 \u2014 a MAJOR real-world DevOps skill:</p> <p>This lesson teaches how to store data permanently in Kubernetes \u2014 something every real application needs.  Without this, your data is gone if the Pod restarts \u2757</p> <p>Let\u2019s make this super beginner-friendly \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch5-Persistent_Volumes_Storage_for_Databases_Apps/#why-do-we-need-storage","title":"\ud83d\udca1 Why Do We Need Storage?","text":"<p>Example apps that need permanent data:</p> <ul> <li>MySQL / PostgreSQL</li> <li>Redis</li> <li>MongoDB</li> <li>WordPress</li> <li>Upload systems</li> <li>Any app that writes files or databases</li> </ul> <p>If you store data inside a Pod \u2192 when that Pod dies, your data disappears.</p> <p>So Kubernetes uses:</p> Component Purpose PersistentVolume (PV) Actual storage (like a disk) PersistentVolumeClaim (PVC) A request for storage Pod Uses the PVC <p>This separation makes Kubernetes portable and flexible.</p>"},{"location":"chapters/ch5-Persistent_Volumes_Storage_for_Databases_Apps/#part-1-create-a-pvc-beginner-way","title":"\ud83c\udf31 Part 1 \u2014 Create a PVC (Beginner Way)","text":"<p>Most clusters auto-provision storage.  So instead of making your own PV, we usually make JUST the PVC.</p> <p>Here\u2019s a simple PVC:</p> <pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: mypvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 1Gi\n</code></pre> <p>\u2714\ufe0f This asks Kubernetes:</p> <p>\u201cPlease give me 1GB of persistent storage.\u201d</p> <p>Apply it:</p> <pre><code>kubectl apply -f pvc.yaml\n</code></pre> <p>Check if it's created:</p> <pre><code>kubectl get pvc\n</code></pre>"},{"location":"chapters/ch5-Persistent_Volumes_Storage_for_Databases_Apps/#part-2-use-pvc-in-a-pod-beginner-example","title":"\u2699\ufe0f Part 2 \u2014 Use PVC in a Pod (Beginner Example)","text":"<p>Let\u2019s attach this storage to an NGINX container:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pv-demo\nspec:\n  containers:\n    - name: nginx\n      image: nginx:latest\n      volumeMounts:\n        - mountPath: \"/usr/share/nginx/html\"\n          name: demo-volume\n  volumes:\n    - name: demo-volume\n      persistentVolumeClaim:\n        claimName: mypvc\n</code></pre> <p>\u2714\ufe0f Whatever you store in <code>/usr/share/nginx/html</code> stays forever, even if the Pod dies.</p> <p>Run it:</p> <pre><code>kubectl apply -f pod.yaml\n</code></pre>"},{"location":"chapters/ch5-Persistent_Volumes_Storage_for_Databases_Apps/#lets-test-if-it-works","title":"\ud83c\udf89 Let\u2019s Test If It Works","text":"<p>Open a shell into the Pod:</p> <pre><code>kubectl exec -it nginx-pv-demo -- /bin/bash\n</code></pre> <p>Inside:</p> <pre><code>echo \"Hello Kubernetes Storage!\" &gt; /usr/share/nginx/html/index.html\n</code></pre> <p>Exit Pod.</p> <p>Now delete the Pod:</p> <pre><code>kubectl delete pod nginx-pv-demo\n</code></pre> <p>Recreate it:</p> <pre><code>kubectl apply -f pod.yaml\n</code></pre> <p>Open the file again \u2014 and you will still see:</p> <pre><code>Hello Kubernetes Storage!\n</code></pre> <p>\u2714\ufe0f This proves real persistent storage is working.</p>"},{"location":"chapters/ch5-Persistent_Volumes_Storage_for_Databases_Apps/#part-3-real-world-example-mysql-database","title":"\ud83d\udd25 Part 3 \u2014 Real-World Example: MySQL Database","text":"<p>This is where DevOps magic happens.</p>"},{"location":"chapters/ch5-Persistent_Volumes_Storage_for_Databases_Apps/#step-1-pvc","title":"Step 1 \u2014 PVC","text":"<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: mysql-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n</code></pre>"},{"location":"chapters/ch5-Persistent_Volumes_Storage_for_Databases_Apps/#step-2-mysql-deployment","title":"Step 2 \u2014 MySQL Deployment","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql\nspec:\n  selector:\n    matchLabels:\n      app: mysql\n  template:\n    metadata:\n      labels:\n        app: mysql\n    spec:\n      containers:\n        - name: mysql\n          image: mysql:5.7\n          env:\n            - name: MYSQL_ROOT_PASSWORD\n              value: \"rootpass\"\n          ports:\n            - containerPort: 3306\n          volumeMounts:\n            - name: mysql-storage\n              mountPath: /var/lib/mysql\n      volumes:\n        - name: mysql-storage\n          persistentVolumeClaim:\n            claimName: mysql-pvc\n</code></pre> <p>Even if MySQL Pod restarts \u2192 your database stays safe \u2714\ufe0f</p>"},{"location":"chapters/ch5-Persistent_Volumes_Storage_for_Databases_Apps/#summary-beginner-friendly","title":"\ud83e\udde0 Summary (Beginner-Friendly)","text":"<pre><code>PVC &lt;\u2014\u2014 Your app uses this storage\nPV  &lt;\u2014\u2014 Kubernetes disk that fulfills the PVC\n</code></pre> <p>\u2714\ufe0f PVC = request  \u2714\ufe0f PV = actual data disk  \u2714\ufe0f Pod uses the PVC</p> <p>This is essential for any modern application.</p>"},{"location":"chapters/ch5-Persistent_Volumes_Storage_for_Databases_Apps/#lesson-5-completed","title":"\ud83c\udf89 Lesson 5 Completed!","text":"<p>You learned:</p> <p>\u2714\ufe0f Why Pods lose data  \u2714\ufe0f What PV and PVC are  \u2714\ufe0f How to create a PVC  \u2714\ufe0f How to attach storage to Pods  \u2714\ufe0f Real example: MySQL database storage  \u2714\ufe0f How real DevOps teams manage stateful workloads</p> <p>You're becoming seriously skilled \ud83d\ude80\ud83d\udd25</p>"},{"location":"chapters/ch5-Persistent_Volumes_Storage_for_Databases_Apps/#ready-for-lesson-6","title":"\ud83d\udc49 Ready for Lesson 6?","text":"<p>Choose one:</p> <ol> <li>Docker \u2192 Build \u2192 Push \u2192 Deploy to Kubernetes</li> <li>Helm Charts (Enterprise-level packaging)</li> <li>Horizontal Autoscaling (HPA)</li> <li>Namespaces (Dev/Stage/Prod separation)</li> <li>Kustomize (environment overlays)</li> <li>StatefulSets (databases done right)</li> </ol> <p>Tell me which one you want next!</p>"},{"location":"chapters/ch6-Docker_Build_Push_Deploy_to_Kubernetes/","title":"\ud83d\udc33\u27a1\ufe0f\u2638\ufe0f  Lesson 6: Docker \u2192 Build \u2192 Push \u2192 Deploy to Kubernetes","text":"<p>Great! \u2714\ufe0f</p> <p>Welcome to Lesson 6, and this one is a HUGE step toward becoming a real DevOps engineer:</p> <p>(This is what DevOps engineers do every day. \ud83d\udd28\ud83e\udd16\ud83d\udd27)</p> <p>We will go from zero \u2192 working Kubernetes app using your own Docker image.</p> <p>This is a MUST-HAVE skill.</p> <p>Let\u2019s go step-by-step, beginner-friendly.</p>"},{"location":"chapters/ch6-Docker_Build_Push_Deploy_to_Kubernetes/#overview-of-what-we-will-do","title":"\u2b50 Overview of What We Will Do","text":"<p>1\ufe0f\u20e3 Write a simple application  2\ufe0f\u20e3 Create a Dockerfile  3\ufe0f\u20e3 Build Docker image  4\ufe0f\u20e3 Push image to Docker Hub  5\ufe0f\u20e3 Deploy the image to Kubernetes  6\ufe0f\u20e3 Access it using a Service</p> <p>Let\u2019s begin!</p>"},{"location":"chapters/ch6-Docker_Build_Push_Deploy_to_Kubernetes/#step-1-create-a-simple-app","title":"\ud83e\uddf1 Step 1 \u2014 Create a Simple App","text":"<p>We\u2019ll make a simple website using plain HTML (no coding experience needed).</p> <p>Create a file:</p> <p>index.html</p> <pre><code>&lt;html&gt;\n  &lt;body&gt;\n    &lt;h1&gt;Hello from Docker + Kubernetes!&lt;/h1&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>That's it \u2714\ufe0f</p>"},{"location":"chapters/ch6-Docker_Build_Push_Deploy_to_Kubernetes/#step-2-create-a-dockerfile","title":"\ud83d\udc33 Step 2 \u2014 Create a Dockerfile","text":"<p>This tells Docker how to build your image.</p> <p>Create a file named: Dockerfile</p> <pre><code>FROM nginx:latest\nCOPY index.html /usr/share/nginx/html/index.html\n</code></pre> <p>Explanation:</p> <ul> <li><code>FROM nginx</code> \u2192 use NGINX as web server</li> <li><code>COPY</code> \u2192 put our webpage inside the container</li> </ul>"},{"location":"chapters/ch6-Docker_Build_Push_Deploy_to_Kubernetes/#step-3-build-the-docker-image","title":"\u2699\ufe0f Step 3 \u2014 Build the Docker Image","text":"<p>Open your terminal in the folder with the Dockerfile:</p> <pre><code>docker build -t yourname/hello-k8s:v1 .\n</code></pre> <p>Example:</p> <pre><code>docker build -t johnsmith/hello-k8s:v1 .\n</code></pre> <p>\u2714\ufe0f You now have a Docker image!</p> <p>Check:</p> <pre><code>docker images\n</code></pre>"},{"location":"chapters/ch6-Docker_Build_Push_Deploy_to_Kubernetes/#step-4-push-image-to-docker-hub","title":"\u2601\ufe0f Step 4 \u2014 Push Image to Docker Hub","text":"<p>Login:</p> <pre><code>docker login\n</code></pre> <p>Push the image:</p> <pre><code>docker push yourname/hello-k8s:v1\n</code></pre> <p>Your image is now online \u2714\ufe0f  Kubernetes can pull it from anywhere.</p>"},{"location":"chapters/ch6-Docker_Build_Push_Deploy_to_Kubernetes/#step-5-deploy-image-to-kubernetes","title":"\u2638\ufe0f Step 5 \u2014 Deploy Image to Kubernetes","text":"<p>Create a file:</p> <p>deployment.yaml</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-k8s\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hello-k8s\n  template:\n    metadata:\n      labels:\n        app: hello-k8s\n    spec:\n      containers:\n        - name: hello-k8s-container\n          image: yourname/hello-k8s:v1\n          ports:\n            - containerPort: 80\n</code></pre> <p>Apply it:</p> <pre><code>kubectl apply -f deployment.yaml\n</code></pre> <p>Check pods:</p> <pre><code>kubectl get pods\n</code></pre> <p>\u2714\ufe0f Your Pod will pull your Docker Hub image and run it.</p>"},{"location":"chapters/ch6-Docker_Build_Push_Deploy_to_Kubernetes/#step-6-expose-it-using-a-service","title":"\ud83c\udf10 Step 6 \u2014 Expose It Using a Service","text":"<p>Create service.yaml:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: hello-k8s-service\nspec:\n  type: NodePort\n  selector:\n    app: hello-k8s\n  ports:\n    - port: 80\n      targetPort: 80\n      nodePort: 30080\n</code></pre> <p>Apply:</p> <pre><code>kubectl apply -f service.yaml\n</code></pre>"},{"location":"chapters/ch6-Docker_Build_Push_Deploy_to_Kubernetes/#step-7-access-your-app","title":"\ud83d\ude80 Step 7 \u2014 Access Your App","text":"<p>If using Minikube:</p> <pre><code>minikube service hello-k8s-service\n</code></pre> <p>Or manually:</p> <pre><code>http://&lt;node-ip&gt;:30080\n</code></pre> <p>You will see:</p> <p>Hello from Docker + Kubernetes!</p> <p>\ud83c\udf89\ud83c\udf89 YOU DID IT!</p> <p>You built an app \u2192 containerized it \u2192 pushed it \u2192 deployed it \u2192 exposed it.</p> <p>This is real DevOps.</p>"},{"location":"chapters/ch6-Docker_Build_Push_Deploy_to_Kubernetes/#recap-beginner-friendly","title":"\ud83e\udde0 Recap (Beginner-Friendly)","text":"<pre><code>[Your Code] \n     \u2193\n[Dockerfile]\n     \u2193\ndocker build\n     \u2193\ndocker push\n     \u2193\nKubernetes Deployment pulls image\n     \u2193\nKubernetes Service exposes app\n</code></pre> <p>You\u2019ve now learned the full deployment pipeline \u2714\ufe0f\ud83d\udd25</p>"},{"location":"chapters/ch6-Docker_Build_Push_Deploy_to_Kubernetes/#lesson-6-completed","title":"\ud83c\udf89 Lesson 6 Completed!","text":"<p>You can now:</p> <p>\u2714\ufe0f Build Docker images  \u2714\ufe0f Push to Docker Hub  \u2714\ufe0f Deploy them in Kubernetes  \u2714\ufe0f Expose to the Internet  \u2714\ufe0f Run your own apps end-to-end</p> <p>Most junior DevOps engineers can\u2019t even do this.  You\u2019re flying. \ud83d\udeeb\ud83d\udcaa</p>"},{"location":"chapters/ch6-Docker_Build_Push_Deploy_to_Kubernetes/#ready-for-lesson-7","title":"\ud83d\udc49 Ready for Lesson 7?","text":"<p>Choose your next level:</p> <ol> <li>Helm Charts (Enterprise DevOps packaging)</li> <li>Horizontal Autoscaling (HPA)</li> <li>Namespaces (Dev/Stage/Prod organization)</li> <li>Kustomize (environment overlays)</li> <li>StatefulSets (databases in Kubernetes)</li> <li>CI/CD Pipeline (GitHub Actions \u2192 Kubernetes)</li> </ol> <p>Which one should we do next?</p>"},{"location":"chapters/ch7-Helm_Charts_Professional_Kubernetes_Packaging/","title":"\ud83c\udfa9  Lesson 7: Helm Charts \u2013 Professional Kubernetes Packaging","text":"<p>Excellent! \u2714\ufe0f</p> <p>Time for Lesson 7 \u2014 and this one is a major upgrade to your DevOps skills. You are now ready for the tool used by every real DevOps team in the world:</p> <p>Helm is like apt, yum, or npm \u2014 but for Kubernetes.  It packages Kubernetes YAML into charts that are:</p> <p>\u2714\ufe0f reusable  \u2714\ufe0f versioned  \u2714\ufe0f configurable  \u2714\ufe0f deployable with a single command</p> <p>Let\u2019s learn it beginner-friendly, step-by-step \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch7-Helm_Charts_Professional_Kubernetes_Packaging/#what-is-helm","title":"\u2b50 What Is Helm?","text":"<p>Helm is:</p> <p>\u201cThe package manager for Kubernetes.\u201d</p> <p>Instead of having 10 YAML files, Helm bundles them into a single folder called a chart.</p> <p>You can then deploy it with:</p> <pre><code>helm install app-name .\n</code></pre> <p>And update it with:</p> <pre><code>helm upgrade app-name .\n</code></pre> <p>And uninstall:</p> <pre><code>helm uninstall app-name\n</code></pre> <p>This is REAL DevOps work.</p>"},{"location":"chapters/ch7-Helm_Charts_Professional_Kubernetes_Packaging/#lesson-overview","title":"\ud83e\uddf1 Lesson Overview","text":"<p>Here\u2019s what we\u2019ll do:</p> <p>1\ufe0f\u20e3 Install Helm 2\ufe0f\u20e3 Create a Helm chart 3\ufe0f\u20e3 Understand chart structure 4\ufe0f\u20e3 Add templates 5\ufe0f\u20e3 Use values.yaml 6\ufe0f\u20e3 Deploy the chart 7\ufe0f\u20e3 Upgrade the chart</p> <p>Let\u2019s go!</p>"},{"location":"chapters/ch7-Helm_Charts_Professional_Kubernetes_Packaging/#step-1-install-helm","title":"\ud83d\udee0\ufe0f Step 1 \u2014 Install Helm","text":"<p>Mac:</p> <pre><code>brew install helm\n</code></pre> <p>Linux:</p> <pre><code>curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash\n</code></pre> <p>Windows:</p> <p>Download from: https://helm.sh/docs/intro/install/</p>"},{"location":"chapters/ch7-Helm_Charts_Professional_Kubernetes_Packaging/#step-2-create-a-helm-chart","title":"\ud83e\uddf1 Step 2 \u2014 Create a Helm Chart","text":"<p>Run:</p> <pre><code>helm create myapp\n</code></pre> <p>This generates:</p> <pre><code>myapp/\n  Chart.yaml\n  values.yaml\n  templates/\n      deployment.yaml\n      service.yaml\n      ingress.yaml\n      _helpers.tpl\n</code></pre> <p>This is your \u201cmini-application bundle\u201d.</p>"},{"location":"chapters/ch7-Helm_Charts_Professional_Kubernetes_Packaging/#step-3-chartyaml-metadata","title":"\ud83d\udce6 Step 3 \u2014 Chart.yaml (Metadata)","text":"<p>Example:</p> <pre><code>apiVersion: v2\nname: myapp\ndescription: A simple web app chart\nversion: 1.0.0\nappVersion: 1.0.0\n</code></pre>"},{"location":"chapters/ch7-Helm_Charts_Professional_Kubernetes_Packaging/#step-4-customize-valuesyaml","title":"\u2699\ufe0f Step 4 \u2014 Customize values.yaml","text":"<p>This is where we store all settings.</p> <p>Open:</p> <p>values.yaml</p> <p>Set your image:</p> <pre><code>image:\n  repository: nginx\n  tag: latest\n\nservice:\n  type: NodePort\n  port: 80\n  nodePort: 30090\n</code></pre>"},{"location":"chapters/ch7-Helm_Charts_Professional_Kubernetes_Packaging/#step-5-deployment-template","title":"\ud83e\udde9 Step 5 \u2014 Deployment Template","text":"<p>Helm templates use Go templating.</p> <p>Here is a small readable example:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: {{ .Chart.Name }}\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: {{ .Chart.Name }}\n  template:\n    metadata:\n      labels:\n        app: {{ .Chart.Name }}\n    spec:\n      containers:\n        - name: {{ .Chart.Name }}\n          image: \"{{ .Values.image.repository }}:{{ .Values.image.tag }}\"\n          ports:\n            - containerPort: 80\n</code></pre> <p>\u2714\ufe0f It uses <code>.Values</code> from values.yaml  \u2714\ufe0f <code>.Chart.Name</code> references the chart name</p>"},{"location":"chapters/ch7-Helm_Charts_Professional_Kubernetes_Packaging/#step-6-deploy-your-helm-chart","title":"\ud83d\udef0\ufe0f Step 6 \u2014 Deploy Your Helm Chart","text":"<p>Navigate into the chart folder:</p> <pre><code>cd myapp\n</code></pre> <p>Install:</p> <pre><code>helm install myapp .\n</code></pre> <p>Check:</p> <pre><code>kubectl get pods\nkubectl get svc\n</code></pre> <p>Your app is running \ud83c\udf89</p>"},{"location":"chapters/ch7-Helm_Charts_Professional_Kubernetes_Packaging/#step-7-upgrade-your-app","title":"\u267b\ufe0f Step 7 \u2014 Upgrade Your App","text":"<p>Let\u2019s change the image.  Edit values.yaml:</p> <pre><code>image:\n  repository: nginx\n  tag: \"1.25\"\n</code></pre> <p>Then upgrade:</p> <pre><code>helm upgrade myapp .\n</code></pre> <p>Kubernetes will do a rolling update \u2714\ufe0f</p>"},{"location":"chapters/ch7-Helm_Charts_Professional_Kubernetes_Packaging/#step-8-uninstall-app","title":"\ud83d\uddd1\ufe0f Step 8 \u2014 Uninstall App","text":"<pre><code>helm uninstall myapp\n</code></pre> <p>Everything is removed cleanly.</p>"},{"location":"chapters/ch7-Helm_Charts_Professional_Kubernetes_Packaging/#lesson-7-completed","title":"\ud83c\udf89 Lesson 7 Completed!","text":"<p>You now understand:</p> <p>\u2714\ufe0f What Helm is  \u2714\ufe0f How charts are structured  \u2714\ufe0f How templating works  \u2714\ufe0f How to create reusable Kubernetes packages  \u2714\ufe0f How to deploy, upgrade, and uninstall applications  \u2714\ufe0f How real DevOps teams ship apps</p> <p>You\u2019ve just learned something intermediate-to-senior level.  You\u2019re leveling up FAST. \ud83d\udd25\ud83d\udcaa</p>"},{"location":"chapters/ch7-Helm_Charts_Professional_Kubernetes_Packaging/#ready-for-lesson-8","title":"\ud83d\udc49 Ready for Lesson 8?","text":"<p>Choose your next path:</p> <ol> <li>Horizontal Pod Autoscaler (HPA) \u26a1</li> <li>Namespaces (Dev/Stage/Prod environments)</li> <li>Kustomize (environment overlays)</li> <li>StatefulSets (databases done right)</li> <li>CI/CD Pipeline (GitHub Actions \u2192 Kubernetes)</li> <li>Full Production-Grade Kubernetes Project (hard mode \ud83d\ude0e)</li> </ol> <p>Which lesson do you want next? \u2714\ufe0f</p>"},{"location":"chapters/ch8-Horizontal_Pod_Autoscaler_HPA/","title":"Horizontal Pod Autoscaler (HPA)","text":"<p>\u26a1 Lesson 8: Horizontal Pod Autoscaler (HPA)</p> <p>Great! \u2714\ufe0f Welcome to Lesson 8, and this one teaches you something every production Kubernetes cluster uses:</p> <p>HPA makes your app scale automatically based on CPU, memory, or custom metrics.</p> <p>Think of it like:</p> <p>\u201cIf your app gets busy \u2192 add more Pods.  If it gets quiet \u2192 remove Pods.\u201d</p> <p>This is a core DevOps skill. Let\u2019s make it super beginner-friendly.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch8-Horizontal_Pod_Autoscaler_HPA/#why-do-we-need-autoscaling","title":"\u2b50 Why Do We Need Autoscaling?","text":"<p>Imagine your website suddenly gets:</p> <ul> <li>10,000 users</li> <li>CPU hits 90%</li> <li>Traffic spikes</li> </ul> <p>If you only have 1 Pod, your application crashes \u2757</p> <p>HPA prevents this:</p> <p>\u2714\ufe0f Adds Pods during high traffic  \u2714\ufe0f Removes Pods when load decreases  \u2714\ufe0f Keeps your app responsive and efficient  \u2714\ufe0f Saves money (only use what you need)</p> <p>This is cloud-native magic \u2728</p>"},{"location":"chapters/ch8-Horizontal_Pod_Autoscaler_HPA/#requirement-metrics-server-must-be-installed","title":"\ud83e\uddf1 Requirement: Metrics Server Must Be Installed","text":"<p>HPA needs metrics (CPU usage).</p> <p>Install in Minikube:</p> <pre><code>minikube addons enable metrics-server\n</code></pre> <p>Check:</p> <pre><code>kubectl get pods -n kube-system\n</code></pre> <p>You should see <code>metrics-server</code>.</p>"},{"location":"chapters/ch8-Horizontal_Pod_Autoscaler_HPA/#step-1-create-a-deployment-with-cpu-requests","title":"\ud83e\uddea Step 1 \u2014 Create a Deployment with CPU Requests","text":"<p>Autoscaling requires CPU requests, otherwise Kubernetes doesn\u2019t know \u201cwhat 80% means\u201d.</p> <p>Here is a simple deployment:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hpa-demo\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: hpa-demo\n  template:\n    metadata:\n      labels:\n        app: hpa-demo\n    spec:\n      containers:\n        - name: hpa-demo-container\n          image: nginx:latest\n          ports:\n            - containerPort: 80\n          resources:\n            requests:\n              cpu: \"100m\"\n            limits:\n              cpu: \"200m\"\n</code></pre> <p>Apply:</p> <pre><code>kubectl apply -f deployment.yaml\n</code></pre>"},{"location":"chapters/ch8-Horizontal_Pod_Autoscaler_HPA/#step-2-create-the-hpa","title":"\u26a1 Step 2 \u2014 Create the HPA","text":"<p>This is the magic file:</p> <pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: hpa-demo\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: hpa-demo\n  minReplicas: 1\n  maxReplicas: 10\n  metrics:\n    - type: Resource\n      resource:\n        name: cpu\n        target:\n          type: Utilization\n          averageUtilization: 50\n</code></pre> <p>Meaning:</p> <p>\u2714\ufe0f Start with 1 pod  \u2714\ufe0f Can go up to 10 pods  \u2714\ufe0f If CPU &gt; 50% \u2192 scale up  \u2714\ufe0f If CPU &lt; 50% \u2192 scale down</p> <p>Apply:</p> <pre><code>kubectl apply -f hpa.yaml\n</code></pre> <p>Check status:</p> <pre><code>kubectl get hpa\n</code></pre> <p>You\u2019ll see:</p> <pre><code>TARGETS: 10%/50%\n</code></pre> <p>This means:</p> <ul> <li>CPU currently 10%</li> <li>Target is 50%</li> </ul>"},{"location":"chapters/ch8-Horizontal_Pod_Autoscaler_HPA/#step-3-test-the-autoscaling-fun","title":"\ud83e\udd16 Step 3 \u2014 Test the Autoscaling (Fun!)","text":"<p>We want to generate CPU load so HPA reacts.</p> <p>Start a shell inside the pod:</p> <pre><code>kubectl exec -it deploy/hpa-demo -- /bin/bash\n</code></pre> <p>Install a load tool (nginx container \u2192 busybox not included).  Let\u2019s use a simple infinite loop that burns CPU:</p> <p>Inside the container:</p> <pre><code>while true; do :; done\n</code></pre> <p>This creates 100% CPU load.</p> <p>Leave it running.</p> <p>Now in another terminal:</p> <pre><code>kubectl get hpa -w\n</code></pre> <p>You will see:</p> <pre><code>TARGET: 120%/50% \u2192 scaling up\nREPLICAS: 1 \u2192 2 \u2192 3 \u2192 4...\n</code></pre> <p>Pods increase automatically \u2714\ufe0f\ud83d\udd25</p>"},{"location":"chapters/ch8-Horizontal_Pod_Autoscaler_HPA/#step-4-watch-scale-down","title":"\ud83c\udf19 Step 4 \u2014 Watch Scale-Down","text":"<p>Stop the load generator (Ctrl + C inside pod).</p> <p>Check HPA again:</p> <pre><code>kubectl get hpa -w\n</code></pre> <p>You will see replicas decrease:</p> <pre><code>4 \u2192 3 \u2192 2 \u2192 1\n</code></pre> <p>This may take ~5 minutes.</p>"},{"location":"chapters/ch8-Horizontal_Pod_Autoscaler_HPA/#lesson-8-completed","title":"\ud83c\udf89 Lesson 8 Completed!","text":"<p>You now know:</p> <p>\u2714\ufe0f How HPA works  \u2714\ufe0f How to install metrics-server  \u2714\ufe0f How to configure CPU thresholds  \u2714\ufe0f How to autoscale Pods  \u2714\ufe0f How to generate load to test autoscaling  \u2714\ufe0f How scale up/down works in real time</p> <p>This is true Kubernetes engineering \u2714\ufe0f\ud83d\udd25  You\u2019re doing fantastic.</p>"},{"location":"chapters/ch8-Horizontal_Pod_Autoscaler_HPA/#ready-for-lesson-9","title":"\ud83d\udc49 Ready for Lesson 9?","text":"<p>Choose your next:</p> <ol> <li>Namespaces (Dev, Stage, Prod environments)</li> <li>Kustomize (different configs per environment)</li> <li>StatefulSets (real databases like MySQL, Redis)</li> <li>CI/CD Pipeline (GitHub Actions \u2192 Kubernetes)</li> <li>Full Production-Grade Kubernetes Project (hard mode)</li> </ol> <p>Which one do you want next?</p>"},{"location":"chapters/ch9-Namespaces_Dev_Stage_Prod_Environments/","title":"\ud83c\udff7\ufe0f Lesson 9 : Namespaces (Dev, Stage, Prod Environments)","text":"<p>Awesome! \u2714\ufe0f</p> <p>Welcome to Lesson 9, and this one is ESSENTIAL for every real DevOps engineer:</p> <p>Namespaces let you organize, separate, and isolate different environments inside a Kubernetes cluster.</p> <p>This lesson is SUPER beginner-friendly, but also VERY important in real companies.  \ud83d\udd28\ud83e\udd16\ud83d\udd27</p>"},{"location":"chapters/ch9-Namespaces_Dev_Stage_Prod_Environments/#why-do-we-need-namespaces","title":"\u2b50 Why Do We Need Namespaces?","text":"<p>Think of Kubernetes as a big apartment building.</p> <p>Namespaces are apartments:</p> <ul> <li>Dev team works in dev</li> <li>Testers work in stage</li> <li>Live customers use prod</li> <li>Everyone is separated, safe, isolated</li> </ul> <p>Namespaces help with:</p> <p>\u2714\ufe0f Separation of environments  \u2714\ufe0f Preventing conflicts  \u2714\ufe0f Organizing resources  \u2714\ufe0f Setting limits (quotas)  \u2714\ufe0f RBAC access control (permissions)</p>"},{"location":"chapters/ch9-Namespaces_Dev_Stage_Prod_Environments/#step-1-create-a-namespace","title":"\ud83e\uddf1 Step 1 \u2014 Create a Namespace","text":"<p>Create a file:</p> <p>dev-namespace.yaml</p> <pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: dev\n</code></pre> <p>Apply:</p> <pre><code>kubectl apply -f dev-namespace.yaml\n</code></pre> <p>Do the same for staging and prod:</p> <p>stage-namespace.yaml</p> <pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: stage\n</code></pre> <p>prod-namespace.yaml</p> <pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: prod\n</code></pre> <p>Apply all:</p> <pre><code>kubectl apply -f stage-namespace.yaml\nkubectl apply -f prod-namespace.yaml\n</code></pre> <p>Check namespaces:</p> <pre><code>kubectl get ns\n</code></pre> <p>You will see:</p> <pre><code>dev\nstage\nprod\ndefault\nkube-system\n</code></pre> <p>\u2714\ufe0f You now have environment separation.</p>"},{"location":"chapters/ch9-Namespaces_Dev_Stage_Prod_Environments/#step-2-deploy-apps-inside-a-namespace","title":"\u2699\ufe0f Step 2 \u2014 Deploy Apps Inside a Namespace","text":"<p>A Deployment inside <code>dev</code> namespace:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app-demo\n  namespace: dev\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: app-demo\n  template:\n    metadata:\n      labels:\n        app: app-demo\n    spec:\n      containers:\n        - name: app\n          image: nginx:latest\n          ports:\n            - containerPort: 80\n</code></pre> <p>Apply:</p> <pre><code>kubectl apply -f deployment.yaml\n</code></pre> <p>View pods in dev:</p> <pre><code>kubectl get pods -n dev\n</code></pre> <p>\u2714\ufe0f Your app stays inside the dev environment.</p>"},{"location":"chapters/ch9-Namespaces_Dev_Stage_Prod_Environments/#step-3-services-in-a-namespace","title":"\u2611\ufe0f Step 3 \u2014 Services in a Namespace","text":"<p>Services must be in the same namespace as their Pods:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: app-demo-service\n  namespace: dev\nspec:\n  selector:\n    app: app-demo\n  ports:\n    - port: 80\n      targetPort: 80\n</code></pre> <p>Apply:</p> <pre><code>kubectl apply -f service.yaml\n</code></pre> <p>Check dev services:</p> <pre><code>kubectl get svc -n dev\n</code></pre>"},{"location":"chapters/ch9-Namespaces_Dev_Stage_Prod_Environments/#step-4-switch-default-namespace","title":"\ud83d\udce6 Step 4 \u2014 Switch Default Namespace","text":"<p>Instead of typing <code>-n dev</code> every time, you can set your context:</p> <pre><code>kubectl config set-context --current --namespace=dev\n</code></pre> <p>Now:</p> <pre><code>kubectl get pods\n</code></pre> <p>automatically looks in dev.</p>"},{"location":"chapters/ch9-Namespaces_Dev_Stage_Prod_Environments/#step-5-resource-quotas-optional-but-very-real","title":"\ud83e\udde0 Step 5 \u2014 Resource Quotas (Optional but Very Real)","text":"<p>Companies use namespaces with quotas to control resource usage.</p> <p>Example:</p> <pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: dev-quota\n  namespace: dev\nspec:\n  hard:\n    requests.cpu: \"1\"\n    limits.cpu: \"2\"\n    requests.memory: 1Gi\n    limits.memory: 2Gi\n    pods: \"10\"\n</code></pre> <p>This means:</p> <p>\u2714\ufe0f Dev namespace can\u2019t use too much CPU  \u2714\ufe0f Dev namespace can\u2019t use too many Pods  \u2714\ufe0f Helps avoid breaking the cluster</p> <p>Apply:</p> <pre><code>kubectl apply -f quota.yaml\n</code></pre>"},{"location":"chapters/ch9-Namespaces_Dev_Stage_Prod_Environments/#step-6-why-namespaces-matter-in-real-devops","title":"\ud83e\udde9 Step 6 \u2014 Why Namespaces Matter in Real DevOps","text":"<p>Namespaces help teams isolate:</p> <ul> <li>dev \u2192 developers experiment</li> <li>stage \u2192 QA tests builds</li> <li>prod \u2192 the real, stable environment</li> <li>monitoring \u2192 Prometheus, Grafana</li> <li>logging \u2192 ELK, Loki</li> <li>security \u2192 policies</li> </ul> <p>Namespaces also integrate deeply with:</p> <p>\u2714\ufe0f RBAC (role-based access control)  \u2714\ufe0f Network policies  \u2714\ufe0f CI/CD workflows  \u2714\ufe0f Helm releases  \u2714\ufe0f Kustomize overlays</p> <p>Now you understand the foundation.</p>"},{"location":"chapters/ch9-Namespaces_Dev_Stage_Prod_Environments/#lesson-9-completed","title":"\ud83c\udf89 Lesson 9 Completed!","text":"<p>You\u2019ve learned:</p> <p>\u2714\ufe0f What namespaces are  \u2714\ufe0f How to create dev/stage/prod  \u2714\ufe0f How to deploy inside a namespace  \u2714\ufe0f How to switch default namespace  \u2714\ufe0f How resource quotas work  \u2714\ufe0f Why namespaces are used in production</p> <p>This is professional DevOps knowledge \u2014 nicely done! \ud83d\udd25\ud83d\udcaa</p>"},{"location":"chapters/ch9-Namespaces_Dev_Stage_Prod_Environments/#ready-for-lesson-10","title":"\ud83d\udc49 Ready for Lesson 10?","text":"<p>Choose the next topic:</p> <ol> <li>Kustomize (Dev/Stage/Prod configuration overlays)</li> <li>StatefulSets (proper way to run real databases)</li> <li>CI/CD Pipeline \u2013 GitHub Actions \u2192 Docker \u2192 Kubernetes</li> <li>Network Policies (security firewalls inside Kubernetes)</li> <li>Full Production-Grade Deployment Project (big, fun, advanced)</li> </ol> <p>Which one should we do next?</p>"},{"location":"resources/best-practices/","title":"\ud83c\udfc6 Kubernetes Best Practices","text":"<p>A comprehensive guide to following industry best practices for deploying and managing applications in Kubernetes.</p>"},{"location":"resources/best-practices/#table-of-contents","title":"\ud83d\udccb Table of Contents","text":"<ul> <li>Security Best Practices</li> <li>Resource Management</li> <li>Application Design</li> <li>Monitoring and Observability</li> <li>Networking</li> <li>Storage</li> <li>CI/CD and GitOps</li> <li>Cost Optimization</li> <li>Documentation</li> </ul>"},{"location":"resources/best-practices/#security-best-practices","title":"\ud83d\udd12 Security Best Practices","text":""},{"location":"resources/best-practices/#1-use-rbac-properly","title":"1. Use RBAC Properly","text":"<pre><code># Always use specific roles instead of cluster-admin\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: production\n  name: deployment-manager\nrules:\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n</code></pre>"},{"location":"resources/best-practices/#2-implement-pod-security-standards","title":"2. Implement Pod Security Standards","text":"<pre><code># Use Pod Security Admission\napiVersion: policy/v1\nkind: PodSecurityPolicy\nmetadata:\n  name: restricted-psp\nspec:\n  privileged: false\n  allowPrivilegeEscalation: false\n  requiredDropCapabilities:\n    - ALL\n  volumes:\n    - 'configMap'\n    - 'emptyDir'\n    - 'projected'\n    - 'secret'\n    - 'downwardAPI'\n    - 'persistentVolumeClaim'\n</code></pre>"},{"location":"resources/best-practices/#3-use-sealed-secrets-for-sensitive-data","title":"3. Use Sealed Secrets for Sensitive Data","text":"<pre><code># Always encrypt secrets at rest\nkubectl create secret generic db-secret \\\n  --from-literal=password=$(openssl rand -base64 32) \\\n  --from-literal=username=admin\n</code></pre>"},{"location":"resources/best-practices/#4-image-security","title":"4. Image Security","text":"<pre><code># Use specific image tags instead of 'latest'\nimage: nginx:1.21.0\n\n# Use minimal base images\nimage: alpine:3.15\n\n# Scan images for vulnerabilities\ntrivy image your-image:tag\n</code></pre>"},{"location":"resources/best-practices/#resource-management","title":"\ud83d\udcca Resource Management","text":""},{"location":"resources/best-practices/#1-set-resource-requests-and-limits","title":"1. Set Resource Requests and Limits","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nspec:\n  template:\n    spec:\n      containers:\n      - name: app\n        image: your-app:1.0\n        resources:\n          requests:\n            cpu: \"250m\"\n            memory: \"256Mi\"\n          limits:\n            cpu: \"500m\"\n            memory: \"512Mi\"\n</code></pre>"},{"location":"resources/best-practices/#2-implement-horizontal-pod-autoscaler","title":"2. Implement Horizontal Pod Autoscaler","text":"<pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: app-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: app-deployment\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n</code></pre>"},{"location":"resources/best-practices/#3-use-resource-quotas","title":"3. Use Resource Quotas","text":"<pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: compute-resources\nspec:\n  hard:\n    requests.cpu: \"4\"\n    requests.memory: \"8Gi\"\n    limits.cpu: \"8\"\n    limits.memory: \"16Gi\"\n    pods: \"10\"\n</code></pre>"},{"location":"resources/best-practices/#application-design","title":"\ud83c\udfd7\ufe0f Application Design","text":""},{"location":"resources/best-practices/#1-use-health-checks","title":"1. Use Health Checks","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nspec:\n  template:\n    spec:\n      containers:\n      - name: app\n        image: your-app:1.0\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 5\n</code></pre>"},{"location":"resources/best-practices/#2-implement-proper-labels-and-selectors","title":"2. Implement Proper Labels and Selectors","text":"<pre><code># Use consistent labels across all resources\nmetadata:\n  labels:\n    app: my-app\n    version: \"1.0\"\n    environment: production\n    team: backend\n</code></pre>"},{"location":"resources/best-practices/#3-use-init-containers-for-setup","title":"3. Use Init Containers for Setup","text":"<pre><code>apiVersion: v1\nkind: Pod\nspec:\n  initContainers:\n  - name: init-db\n    image: busybox:1.35\n    command: ['sh', '-c', 'until nslookup db-service; do echo waiting for db; sleep 2; done']\n  containers:\n  - name: app\n    image: your-app:1.0\n</code></pre>"},{"location":"resources/best-practices/#monitoring-and-observability","title":"\ud83d\udc41\ufe0f Monitoring and Observability","text":""},{"location":"resources/best-practices/#1-use-prometheus-operator","title":"1. Use Prometheus Operator","text":"<pre><code>apiVersion: monitoring.coreos.com/v1\nkind: Prometheus\nmetadata:\n  name: prometheus\nspec:\n  serviceAccountName: prometheus\n  serviceMonitorSelector:\n    matchLabels:\n      team: backend\n  podMonitorSelector:\n    matchLabels:\n      team: frontend\n</code></pre>"},{"location":"resources/best-practices/#2-implement-logging","title":"2. Implement Logging","text":"<pre><code># Use sidecar containers for logging\napiVersion: v1\nkind: Pod\nspec:\n  containers:\n  - name: app\n    image: your-app:1.0\n  - name: fluentd\n    image: fluent/fluentd:v1.16\n    volumeMounts:\n    - name: logs\n      mountPath: /var/log\n</code></pre>"},{"location":"resources/best-practices/#3-set-up-alerting","title":"3. Set Up Alerting","text":"<pre><code># Use Prometheus AlertManager\napiVersion: monitoring.coreos.com/v1\nkind: Alertmanager\nmetadata:\n  name: alertmanager\nspec:\n  route:\n    groupBy: ['alertname']\n    groupWait: 30s\n    groupInterval: 5m\n    repeatInterval: 12h\n    receiver: 'web.hook'\n</code></pre>"},{"location":"resources/best-practices/#networking","title":"\ud83c\udf10 Networking","text":""},{"location":"resources/best-practices/#1-use-network-policies","title":"1. Use Network Policies","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: app-network-policy\nspec:\n  podSelector:\n    matchLabels:\n      app: my-app\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: production\n    ports:\n    - protocol: TCP\n      port: 8080\n</code></pre>"},{"location":"resources/best-practices/#2-use-ingress-controllers","title":"2. Use Ingress Controllers","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: app-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    cert-manager.io/cluster-issuer: letsencrypt-prod\nspec:\n  tls:\n  - hosts:\n    - app.example.com\n    secretName: app-tls\n  rules:\n  - host: app.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: app-service\n            port:\n              number: 80\n</code></pre>"},{"location":"resources/best-practices/#3-use-service-mesh-for-complex-applications","title":"3. Use Service Mesh for Complex Applications","text":"<pre><code># Use Istio for service-to-service communication\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: app-vs\nspec:\n  hosts:\n  - app-service\n  http:\n  - route:\n    - destination:\n        host: app-service\n        subset: v1\n    - destination:\n        host: app-service\n        subset: v2\n      weight: 20\n</code></pre>"},{"location":"resources/best-practices/#storage","title":"\ud83d\udcbe Storage","text":""},{"location":"resources/best-practices/#1-use-persistent-volume-claims","title":"1. Use Persistent Volume Claims","text":"<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: app-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: fast-ssd\n</code></pre>"},{"location":"resources/best-practices/#2-use-storage-classes","title":"2. Use Storage Classes","text":"<pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: fast-ssd\nprovisioner: kubernetes.io/aws-ebs\nparameters:\n  type: gp3\n  replication-type: none\nallowVolumeExpansion: true\n</code></pre>"},{"location":"resources/best-practices/#3-backup-important-data","title":"3. Backup Important Data","text":"<pre><code># Use Velero for backups\nvelero backup create app-backup \\\n  --include-namespaces production \\\n  --schedule \"0 2 * * *\" \\\n  --ttl 720h\n</code></pre>"},{"location":"resources/best-practices/#cicd-and-gitops","title":"\ud83d\udd04 CI/CD and GitOps","text":""},{"location":"resources/best-practices/#1-use-gitops-principles","title":"1. Use GitOps Principles","text":"<pre><code># Use ArgoCD for GitOps\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-app\nspec:\n  source:\n    repoURL: https://github.com/my-org/my-app.git\n    targetRevision: HEAD\n    path: manifests\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: production\n  project: default\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true\n</code></pre>"},{"location":"resources/best-practices/#2-use-helm-charts","title":"2. Use Helm Charts","text":"<pre><code># Package applications as Helm charts\nhelm package my-chart\nhelm install my-app ./my-chart-1.0.0.tgz\n</code></pre>"},{"location":"resources/best-practices/#3-use-kustomize-for-environment-management","title":"3. Use Kustomize for Environment Management","text":"<pre><code># Use Kustomize for environment-specific configurations\nbase/\n  deployment.yaml\n  service.yaml\noverlays/production/\n  kustomization.yaml\n  deployment.yaml\n</code></pre>"},{"location":"resources/best-practices/#cost-optimization","title":"\ud83d\udcb0 Cost Optimization","text":""},{"location":"resources/best-practices/#1-use-cluster-autoscaler","title":"1. Use Cluster Autoscaler","text":"<pre><code>apiVersion: autoscaling/v2beta2\nkind: ClusterAutoscaler\nmetadata:\n  name: cluster-autoscaler\nspec:\n  scaleDown:\n    enabled: true\n    delayAfterAdd: 10m\n    delayAfterDelete: 10s\n    delayAfterFailure: 10m\n    unneededTime: 10m\n</code></pre>"},{"location":"resources/best-practices/#2-use-spot-instances","title":"2. Use Spot Instances","text":"<pre><code># Use spot instances for fault-tolerant workloads\napiVersion: v1\nkind: NodePool\nmetadata:\n  name: spot-pool\nspec:\n  template:\n    spec:\n      taints:\n      - key: \"spot-instance\"\n        value: \"true\"\n        effect: \"NoSchedule\"\n</code></pre>"},{"location":"resources/best-practices/#3-monitor-costs","title":"3. Monitor Costs","text":"<pre><code># Use kubectl-cost for cost monitoring\nkubectl cost --pod --all-namespaces\n</code></pre>"},{"location":"resources/best-practices/#documentation","title":"\ud83d\udcda Documentation","text":""},{"location":"resources/best-practices/#1-document-your-applications","title":"1. Document Your Applications","text":"<pre><code># My Application\n\n## Overview\nThis application provides...\n\n## Architecture\n- Frontend: React app\n- Backend: Node.js API\n- Database: PostgreSQL\n\n## Deployment\n- Namespace: production\n- Replicas: 3\n- Resource limits: 500m CPU, 1Gi memory\n\n## Monitoring\n- Prometheus metrics: /metrics\n- Health checks: /health\n- Logs: Fluentd sidecar\n</code></pre>"},{"location":"resources/best-practices/#2-use-openapi-specifications","title":"2. Use OpenAPI Specifications","text":"<pre><code># Document APIs with OpenAPI\nopenapi: 3.0.0\ninfo:\n  title: My API\n  version: 1.0.0\npaths:\n  /users:\n    get:\n      summary: Get users\n      responses:\n        '200':\n          description: List of users\n</code></pre>"},{"location":"resources/best-practices/#3-keep-configuration-in-git","title":"3. Keep Configuration in Git","text":"<pre><code># Always commit configuration changes\ngit add .\ngit commit -m \"feat: update resource limits for production\"\ngit push origin main\n</code></pre>"},{"location":"resources/best-practices/#performance-optimization","title":"\ud83d\ude80 Performance Optimization","text":""},{"location":"resources/best-practices/#1-use-caching","title":"1. Use Caching","text":"<pre><code># Use image pull secrets for private registries\napiVersion: v1\nkind: Secret\nmetadata:\n  name: registry-secret\ntype: kubernetes.io/dockerconfigjson\ndata:\n  .dockerconfigjson: &lt;base64-encoded-registry-auth&gt;\n</code></pre>"},{"location":"resources/best-practices/#2-optimize-container-images","title":"2. Optimize Container Images","text":"<pre><code># Use multi-stage builds\nFROM golang:1.21 as builder\nWORKDIR /app\nCOPY . .\nRUN go build -o app\n\nFROM alpine:3.15\nCOPY --from=builder /app/app .\nCMD [\"./app\"]\n</code></pre>"},{"location":"resources/best-practices/#3-use-resource-optimization-tools","title":"3. Use Resource Optimization Tools","text":"<pre><code># Use kubectl-neat to clean up YAML\nkubectl-neat deployment.yaml &gt; clean-deployment.yaml\n</code></pre>"},{"location":"resources/best-practices/#disaster-recovery","title":"\ud83d\udee1\ufe0f Disaster Recovery","text":""},{"location":"resources/best-practices/#1-implement-backup-strategies","title":"1. Implement Backup Strategies","text":"<pre><code># Regular backups\nvelero schedule create daily-backup \\\n  --schedule \"0 2 * * *\" \\\n  --ttl 720h \\\n  --include-namespaces production,staging\n</code></pre>"},{"location":"resources/best-practices/#2-use-multi-zone-deployments","title":"2. Use Multi-Zone Deployments","text":"<pre><code># Spread pods across availability zones\napiVersion: apps/v1\nkind: Deployment\nspec:\n  template:\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - my-app\n            topologyKey: \"kubernetes.io/hostname\"\n</code></pre>"},{"location":"resources/best-practices/#3-test-disaster-recovery","title":"3. Test Disaster Recovery","text":"<pre><code># Regular disaster recovery drills\nvelero restore create restore-1 \\\n  --from-backup daily-backup-20231201 \\\n  --namespace-mappings production:disaster-recovery\n</code></pre>"},{"location":"resources/best-practices/#operational-excellence","title":"\ud83d\udd27 Operational Excellence","text":""},{"location":"resources/best-practices/#1-use-gitops-for-all-changes","title":"1. Use GitOps for All Changes","text":"<pre><code># Always use GitOps for deployments\nargocd app sync my-app\nargocd app wait my-app\n</code></pre>"},{"location":"resources/best-practices/#2-implement-canary-deployments","title":"2. Implement Canary Deployments","text":"<pre><code># Use Istio for canary deployments\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: app-canary\nspec:\n  hosts:\n  - app.example.com\n  http:\n  - route:\n    - destination:\n        host: app-service\n        subset: stable\n      weight: 90\n    - destination:\n        host: app-service\n        subset: canary\n      weight: 10\n</code></pre>"},{"location":"resources/best-practices/#3-use-automated-testing","title":"3. Use Automated Testing","text":"<pre><code># Test deployments before applying\nkubectl apply --dry-run=client -f deployment.yaml\nkubectl apply --server-dry-run -f deployment.yaml\n</code></pre>"},{"location":"resources/best-practices/#continuous-improvement","title":"\ud83d\udcc8 Continuous Improvement","text":""},{"location":"resources/best-practices/#1-monitor-performance-metrics","title":"1. Monitor Performance Metrics","text":"<pre><code># Use kubectl top for resource monitoring\nkubectl top pods\nkubectl top nodes\nkubectl top deployments\n</code></pre>"},{"location":"resources/best-practices/#2-regular-security-audits","title":"2. Regular Security Audits","text":"<pre><code># Use kube-bench for security compliance\nkube-bench run --targets=node\nkube-bench run --targets=controls\n</code></pre>"},{"location":"resources/best-practices/#3-stay-updated","title":"3. Stay Updated","text":"<pre><code># Regularly update Kubernetes versions\nkubectl get nodes -o wide\nkubectl version --client\n</code></pre>"},{"location":"resources/best-practices/#summary","title":"\ud83c\udfaf Summary","text":"<p>Following these best practices will help you: - Improve security posture - Optimize resource usage - Enhance application reliability - Reduce operational overhead - Ensure compliance and governance - Enable faster deployments - Improve monitoring and observability</p> <p>Remember to adapt these practices to your specific use case and organizational requirements.</p>"},{"location":"resources/cheat-sheets/","title":"\ud83d\ude80 Kubernetes Cheat Sheets","text":"<p>Quick reference guides for common Kubernetes operations and commands.</p>"},{"location":"resources/cheat-sheets/#basic-kubernetes-commands","title":"Basic Kubernetes Commands","text":""},{"location":"resources/cheat-sheets/#cluster-information","title":"Cluster Information","text":"<pre><code># Get cluster info\nkubectl cluster-info\n\n# View nodes\nkubectl get nodes\n\n# View node details\nkubectl describe node &lt;node-name&gt;\n\n# View cluster version\nkubectl version --short\n</code></pre>"},{"location":"resources/cheat-sheets/#pod-operations","title":"Pod Operations","text":"<pre><code># Get pods\nkubectl get pods\n\n# Get pods with more details\nkubectl get pods -o wide\n\n# Describe pod\nkubectl describe pod &lt;pod-name&gt;\n\n# Delete pod\nkubectl delete pod &lt;pod-name&gt;\n\n# View pod logs\nkubectl logs &lt;pod-name&gt;\n\n# Follow pod logs\nkubectl logs -f &lt;pod-name&gt;\n\n# Execute command in pod\nkubectl exec -it &lt;pod-name&gt; -- /bin/bash\n</code></pre>"},{"location":"resources/cheat-sheets/#deployment-management","title":"Deployment Management","text":"<pre><code># Get deployments\nkubectl get deployments\n\n# Create deployment from file\nkubectl create -f deployment.yaml\n\n# Apply changes\nkubectl apply -f deployment.yaml\n\n# Scale deployment\nkubectl scale deployment/&lt;deployment-name&gt; --replicas=3\n\n# Rollback deployment\nkubectl rollout undo deployment/&lt;deployment-name&gt;\n\n# Check rollout status\nkubectl rollout status deployment/&lt;deployment-name&gt;\n</code></pre>"},{"location":"resources/cheat-sheets/#yaml-management","title":"YAML Management","text":"<pre><code># Get pod as YAML\nkubectl get pod &lt;pod-name&gt; -o yaml\n\n# Get pod as JSON\nkubectl get pod &lt;pod-name&gt; -o json\n\n# Dry run apply\nkubectl apply --dry-run=client -f deployment.yaml\n\n# Validate YAML\nkubectl apply --dry-run=client -f deployment.yaml\n</code></pre>"},{"location":"resources/cheat-sheets/#common-yaml-snippets","title":"Common YAML Snippets","text":""},{"location":"resources/cheat-sheets/#basic-pod","title":"Basic Pod","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.21\n    ports:\n    - containerPort: 80\n</code></pre>"},{"location":"resources/cheat-sheets/#basic-deployment","title":"Basic Deployment","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.21\n        ports:\n        - containerPort: 80\n</code></pre>"},{"location":"resources/cheat-sheets/#service","title":"Service","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-service\nspec:\n  selector:\n    app: nginx\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n  type: LoadBalancer\n</code></pre>"},{"location":"resources/cheat-sheets/#configmap","title":"ConfigMap","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\ndata:\n  APP_ENV: \"production\"\n  APP_DEBUG: \"false\"\n  config.json: |\n    {\n      \"database\": {\n        \"host\": \"db-service\",\n        \"port\": 5432\n      }\n    }\n</code></pre>"},{"location":"resources/cheat-sheets/#secret","title":"Secret","text":"<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: app-secret\ntype: Opaque\ndata:\n  username: YWRtaW4=  # admin (base64 encoded)\n  password: MWYyZDFlMmU2N2Rm  # 1f2d1e2e67df (base64 encoded)\n</code></pre>"},{"location":"resources/cheat-sheets/#port-forwarding","title":"Port Forwarding","text":"<pre><code># Port forward to a pod\nkubectl port-forward svc/&lt;service-name&gt; 8080:80\n\n# Port forward to deployment\nkubectl port-forward deployment/&lt;deployment-name&gt; 8080:80\n</code></pre>"},{"location":"resources/cheat-sheets/#resource-limits","title":"Resource Limits","text":"<pre><code># Set resource limits on pod\nkubectl set resources deployment/&lt;deployment-name&gt; --limits=cpu=500m,memory=512Mi --requests=cpu=250m,memory=256Mi\n</code></pre>"},{"location":"resources/cheat-sheets/#context-and-namespace","title":"Context and Namespace","text":"<pre><code># Get current context\nkubectl config current-context\n\n# Switch context\nkubectl config use-context &lt;context-name&gt;\n\n# Get namespaces\nkubectl get namespaces\n\n# Set namespace for current session\nkubectl config set-context --current --namespace=&lt;namespace-name&gt;\n\n# Apply with namespace\nkubectl apply -f deployment.yaml -n &lt;namespace-name&gt;\n</code></pre>"},{"location":"resources/cheat-sheets/#common-troubleshooting-commands","title":"Common Troubleshooting Commands","text":"<p>```bash</p>"},{"location":"resources/cheat-sheets/#get-all-resources-in-namespace","title":"Get all resources in namespace","text":"<p>kubectl get all</p>"},{"location":"resources/cheat-sheets/#get-events","title":"Get events","text":"<p>kubectl get events</p>"},{"location":"resources/cheat-sheets/#check-pod-status-with-previous-state","title":"Check pod status with previous state","text":"<p>kubectl get pods --show-labels</p>"},{"location":"resources/cheat-sheets/#check-pod-readiness","title":"Check pod readiness","text":"<p>kubectl get pods -o jsonpath='{.items[].status.containerStatuses[].ready}'</p>"},{"location":"resources/cheat-sheets/#check-pod-restarts","title":"Check pod restarts","text":"<p>kubectl get pods --sort-by='.status.containerStatuses[0].restartCount'</p>"},{"location":"resources/glossary/","title":"\ud83d\udcda Kubernetes Glossary","text":"<p>A comprehensive glossary of Kubernetes terminology, concepts, and acronyms.</p>"},{"location":"resources/glossary/#core-concepts","title":"\ud83c\udfd7\ufe0f Core Concepts","text":""},{"location":"resources/glossary/#kubernetes-k8s","title":"Kubernetes (K8s)","text":"<p>An open-source container orchestration platform for automating deployment, scaling, and management of containerized applications.</p>"},{"location":"resources/glossary/#container","title":"Container","text":"<p>A lightweight, standalone, executable package that includes everything needed to run a piece of software, including the code, runtime, system tools, system libraries, and settings.</p>"},{"location":"resources/glossary/#pod","title":"Pod","text":"<p>The smallest deployable unit in Kubernetes that contains one or more containers. Pods share network and storage resources.</p>"},{"location":"resources/glossary/#node","title":"Node","text":"<p>A worker machine in Kubernetes, which may be a virtual or physical machine. Each node contains the services necessary to run pods.</p>"},{"location":"resources/glossary/#cluster","title":"Cluster","text":"<p>A set of nodes that run containerized applications managed by Kubernetes. Provides the compute resources for running applications.</p>"},{"location":"resources/glossary/#control-plane","title":"Control Plane","text":"<p>The set of components that make decisions about the cluster (e.g., scheduling, scaling, rolling updates).</p>"},{"location":"resources/glossary/#etcd","title":"etcd","text":"<p>Consistent and highly-available key-value store used as Kubernetes' backing store for all cluster data.</p>"},{"location":"resources/glossary/#kube-apiserver","title":"kube-apiserver","text":"<p>The API server validates and configures data for the api objects which include pods, services, replication controllers, and more.</p>"},{"location":"resources/glossary/#kube-scheduler","title":"kube-scheduler","text":"<p>The component on the master that watches for newly created pods with no assigned node, and selects a node for them to run on.</p>"},{"location":"resources/glossary/#kube-controller-manager","title":"kube-controller-manager","text":"<p>Runs controllers which process background tasks in the cluster. Logically, each controller is a separate process, but to reduce complexity, they are all compiled into a single binary and run in a single process.</p>"},{"location":"resources/glossary/#kubelet","title":"kubelet","text":"<p>The primary node agent that runs on each node. It ensures that containers are running in a pod.</p>"},{"location":"resources/glossary/#kube-proxy","title":"kube-proxy","text":"<p>Maintains network rules on nodes. These network rules allow network communication to your pods from network sessions inside or outside of your cluster.</p>"},{"location":"resources/glossary/#container-runtime","title":"Container Runtime","text":"<p>The software that is responsible for running containers (e.g., Docker, containerd, CRI-O).</p>"},{"location":"resources/glossary/#objects","title":"\ud83d\udce6 Objects","text":""},{"location":"resources/glossary/#deployment","title":"Deployment","text":"<p>Declarative way to manage applications. Provides declarative updates for Pods and ReplicaSets.</p>"},{"location":"resources/glossary/#replicaset","title":"ReplicaSet","text":"<p>Ensures that a specified number of pod replicas are running at any given time.</p>"},{"location":"resources/glossary/#statefulset","title":"StatefulSet","text":"<p>Manages the deployment and scaling of a set of pods, and provides persistent and stable storage and networking.</p>"},{"location":"resources/glossary/#daemonset","title":"DaemonSet","text":"<p>Ensures that all (or some) nodes run a copy of a pod. As nodes are added to the cluster, pods are added to them.</p>"},{"location":"resources/glossary/#job","title":"Job","text":"<p>Creates one or more pods and ensures that a specified number of them successfully terminate.</p>"},{"location":"resources/glossary/#cronjob","title":"CronJob","text":"<p>Creates Jobs on a time-based schedule.</p>"},{"location":"resources/glossary/#service","title":"Service","text":"<p>An abstraction that defines a logical set of Pods and a policy by which to access them.</p>"},{"location":"resources/glossary/#ingress","title":"Ingress","text":"<p>Manages external access to the services in a cluster, typically HTTP/HTTPS.</p>"},{"location":"resources/glossary/#configmap","title":"ConfigMap","text":"<p>Allows you to decouple configuration artifacts from container images.</p>"},{"location":"resources/glossary/#secret","title":"Secret","text":"<p>Used to store sensitive data such as passwords, tokens, and keys.</p>"},{"location":"resources/glossary/#persistentvolume-pv","title":"PersistentVolume (PV)","text":"<p>A piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes.</p>"},{"location":"resources/glossary/#persistentvolumeclaim-pvc","title":"PersistentVolumeClaim (PVC)","text":"<p>A request for storage by a user. It is similar to a Pod but volumes exist independently of any Pod.</p>"},{"location":"resources/glossary/#storageclass","title":"StorageClass","text":"<p>Provides a way for administrators to describe the \"classes\" of storage they offer.</p>"},{"location":"resources/glossary/#namespace","title":"Namespace","text":"<p>Provides a scope for Names. Names of resources need to be unique within a Namespace but not across Namespaces.</p>"},{"location":"resources/glossary/#serviceaccount","title":"ServiceAccount","text":"<p>An account that provides an identity for processes running in a Pod.</p>"},{"location":"resources/glossary/#role","title":"Role","text":"<p>Defines a set of permissions within a Namespace.</p>"},{"location":"resources/glossary/#clusterrole","title":"ClusterRole","text":"<p>Defines a set of permissions for the entire cluster.</p>"},{"location":"resources/glossary/#rolebinding","title":"RoleBinding","text":"<p>Grants the permissions defined in a Role to a User or ServiceAccount.</p>"},{"location":"resources/glossary/#clusterrolebinding","title":"ClusterRoleBinding","text":"<p>Grants the permissions defined in a ClusterRole to a User or ServiceAccount.</p>"},{"location":"resources/glossary/#networking","title":"\ud83c\udf10 Networking","text":""},{"location":"resources/glossary/#clusterip","title":"ClusterIP","text":"<p>Exposes the service on a cluster-internal IP. Only reachable from within the cluster.</p>"},{"location":"resources/glossary/#nodeport","title":"NodePort","text":"<p>Exposes the service on each Node's IP at a static port (the same port on every Node).</p>"},{"location":"resources/glossary/#loadbalancer","title":"LoadBalancer","text":"<p>Exposes the service externally using a cloud provider's load balancer.</p>"},{"location":"resources/glossary/#externalname","title":"ExternalName","text":"<p>Maps the service to the externalName field (e.g., my-database.example.com), by returning a CNAME record with that name.</p>"},{"location":"resources/glossary/#ingress-controller","title":"Ingress Controller","text":"<p>A piece of software that provides reverse proxy, configurable traffic routing, and TLS termination for Kubernetes services.</p>"},{"location":"resources/glossary/#network-policy","title":"Network Policy","text":"<p>Controls the flow of traffic between pods based on labels and selectors.</p>"},{"location":"resources/glossary/#cni-container-network-interface","title":"CNI (Container Network Interface)","text":"<p>A standard for container networking that allows different networking plugins to be used with container runtimes.</p>"},{"location":"resources/glossary/#coredns","title":"CoreDNS","text":"<p>The DNS server for Kubernetes clusters.</p>"},{"location":"resources/glossary/#service-mesh","title":"Service Mesh","text":"<p>A dedicated infrastructure layer for handling service-to-service communication.</p>"},{"location":"resources/glossary/#mtls-mutual-tls","title":"mTLS (mutual TLS)","text":"<p>A method where both the client and server authenticate each other by verifying digital certificates.</p>"},{"location":"resources/glossary/#storage","title":"\ud83d\udd27 Storage","text":""},{"location":"resources/glossary/#volume","title":"Volume","text":"<p>A directory accessible to all containers in a pod.</p>"},{"location":"resources/glossary/#persistentvolume","title":"PersistentVolume","text":"<p>A piece of storage provisioned for use with Kubernetes clusters.</p>"},{"location":"resources/glossary/#persistentvolumeclaim","title":"PersistentVolumeClaim","text":"<p>A request for storage by a user.</p>"},{"location":"resources/glossary/#storageclass_1","title":"StorageClass","text":"<p>Defines the \"classes\" of storage offered in a cluster.</p>"},{"location":"resources/glossary/#dynamic-provisioning","title":"Dynamic Provisioning","text":"<p>Automatically creates storage when it's requested.</p>"},{"location":"resources/glossary/#static-provisioning","title":"Static Provisioning","text":"<p>Manually creates storage before it's requested.</p>"},{"location":"resources/glossary/#read-once","title":"Read-Once","text":"<p>Volume can be mounted as read-write by a single node at a time.</p>"},{"location":"resources/glossary/#readonlymany","title":"ReadOnlyMany","text":"<p>Volume can be mounted as read-only by many nodes.</p>"},{"location":"resources/glossary/#readwriteonce","title":"ReadWriteOnce","text":"<p>Volume can be mounted as read-write by a single node.</p>"},{"location":"resources/glossary/#readwritemany","title":"ReadWriteMany","text":"<p>Volume can be mounted as read-write by many nodes.</p>"},{"location":"resources/glossary/#security","title":"\ud83d\udd12 Security","text":""},{"location":"resources/glossary/#rbac-role-based-access-control","title":"RBAC (Role-Based Access Control)","text":"<p>A method of regulating access to computer or network resources based on the roles of individual users.</p>"},{"location":"resources/glossary/#pod-security-policy-psp","title":"Pod Security Policy (PSP)","text":"<p>Cluster-level resource that controls security-sensitive aspects of the pod specification.</p>"},{"location":"resources/glossary/#pod-security-admission-psa","title":"Pod Security Admission (PSA)","text":"<p>A built-in admission controller that enforces Pod Security Standards.</p>"},{"location":"resources/glossary/#sealed-secrets","title":"Sealed Secrets","text":"<p>A Kubernetes controller and tool for managing encrypted secrets.</p>"},{"location":"resources/glossary/#network-policy_1","title":"Network Policy","text":"<p>Controls the flow of traffic between pods based on labels and selectors.</p>"},{"location":"resources/glossary/#service-account-token-volume-projection","title":"Service Account Token Volume Projection","text":"<p>Mounts service account tokens as volumes in pods.</p>"},{"location":"resources/glossary/#pod-security-context","title":"Pod Security Context","text":"<p>Security settings for a pod or container.</p>"},{"location":"resources/glossary/#security-context","title":"Security Context","text":"<p>Security settings for a container.</p>"},{"location":"resources/glossary/#capabilities","title":"Capabilities","text":"<p>Linux kernel security features that can be enabled or disabled for a container.</p>"},{"location":"resources/glossary/#apparmor","title":"AppArmor","text":"<p>Linux kernel security module that allows administrators to confine programs to a limited set of resources.</p>"},{"location":"resources/glossary/#selinux","title":"SELinux","text":"<p>Security-Enhanced Linux, a Linux kernel security module.</p>"},{"location":"resources/glossary/#monitoring-and-observability","title":"\ud83d\udcca Monitoring and Observability","text":""},{"location":"resources/glossary/#prometheus","title":"Prometheus","text":"<p>An open-source monitoring system with a dimensional data model, flexible query language, and efficient time series database.</p>"},{"location":"resources/glossary/#grafana","title":"Grafana","text":"<p>An open-source platform for monitoring and observability.</p>"},{"location":"resources/glossary/#alertmanager","title":"Alertmanager","text":"<p>Handles alerts sent by client applications such as the Prometheus server.</p>"},{"location":"resources/glossary/#metrics","title":"Metrics","text":"<p>Quantitative measurements of system behavior.</p>"},{"location":"resources/glossary/#logs","title":"Logs","text":"<p>Records of events that occur in a system.</p>"},{"location":"resources/glossary/#traces","title":"Traces","text":"<p>Records of the path that a request takes through a system.</p>"},{"location":"resources/glossary/#service-level-objectives-slo","title":"Service Level Objectives (SLO)","text":"<p>Service level objectives define the target level of desired reliability and performance.</p>"},{"location":"resources/glossary/#service-level-indicators-sli","title":"Service Level Indicators (SLI)","text":"<p>Service level indicators measure the performance of a service.</p>"},{"location":"resources/glossary/#service-level-agreement-sla","title":"Service Level Agreement (SLA)","text":"<p>Service level agreements define the level of service expected by a customer.</p>"},{"location":"resources/glossary/#apm-application-performance-monitoring","title":"APM (Application Performance Monitoring)","text":"<p>Tools and processes for monitoring the performance of applications.</p>"},{"location":"resources/glossary/#distributed-tracing","title":"Distributed Tracing","text":"<p>A method for monitoring applications in a microservices architecture.</p>"},{"location":"resources/glossary/#opentelemetry","title":"OpenTelemetry","text":"<p>An open-source observability framework.</p>"},{"location":"resources/glossary/#deployment-and-orchestration","title":"\ud83d\ude80 Deployment and Orchestration","text":""},{"location":"resources/glossary/#helm","title":"Helm","text":"<p>The package manager for Kubernetes.</p>"},{"location":"resources/glossary/#chart","title":"Chart","text":"<p>A collection of files that describe a related set of Kubernetes resources.</p>"},{"location":"resources/glossary/#release","title":"Release","text":"<p>A running instance of a chart in a Kubernetes cluster.</p>"},{"location":"resources/glossary/#value","title":"Value","text":"<p>Configuration values for a chart.</p>"},{"location":"resources/glossary/#kustomize","title":"Kustomize","text":"<p>A configuration customization engine for Kubernetes.</p>"},{"location":"resources/glossary/#kustomization","title":"Kustomization","text":"<p>A set of resources that have been customized using Kustomize.</p>"},{"location":"resources/glossary/#argocd","title":"ArgoCD","text":"<p>A declarative, GitOps continuous delivery tool for Kubernetes.</p>"},{"location":"resources/glossary/#flux","title":"Flux","text":"<p>A GitOps operator for Kubernetes.</p>"},{"location":"resources/glossary/#cicd-continuous-integrationcontinuous-deployment","title":"CI/CD (Continuous Integration/Continuous Deployment)","text":"<p>Automated processes for building, testing, and deploying applications.</p>"},{"location":"resources/glossary/#gitops","title":"GitOps","text":"<p>A way of implementing Continuous Delivery for cloud-native applications.</p>"},{"location":"resources/glossary/#canary-deployment","title":"Canary Deployment","text":"<p>A technique to reduce the risk of introducing a new software version by slowly rolling out the change to a small subset of users.</p>"},{"location":"resources/glossary/#blue-green-deployment","title":"Blue-Green Deployment","text":"<p>A deployment strategy that reduces downtime and risk by running two identical production environments.</p>"},{"location":"resources/glossary/#rolling-update","title":"Rolling Update","text":"<p>A deployment strategy that gradually replaces old instances with new ones.</p>"},{"location":"resources/glossary/#rollback","title":"Rollback","text":"<p>Reverting to a previous version of an application.</p>"},{"location":"resources/glossary/#architecture","title":"\ud83c\udfdb\ufe0f Architecture","text":""},{"location":"resources/glossary/#microservices","title":"Microservices","text":"<p>An architectural style that structures an application as a collection of loosely coupled services.</p>"},{"location":"resources/glossary/#monolith","title":"Monolith","text":"<p>A single, unified unit that contains all of the application's code and functionality.</p>"},{"location":"resources/glossary/#serverless","title":"Serverless","text":"<p>A cloud-computing execution model where the cloud provider runs the server and dynamically manages the allocation of machine resources.</p>"},{"location":"resources/glossary/#function-as-a-service-faas","title":"Function as a Service (FaaS)","text":"<p>A cloud computing service that allows users to execute code in response to events without the complex infrastructure.</p>"},{"location":"resources/glossary/#infrastructure-as-code-iac","title":"Infrastructure as Code (IaC)","text":"<p>Managing and provisioning infrastructure through code and software development techniques.</p>"},{"location":"resources/glossary/#platform-as-a-service-paas","title":"Platform as a Service (PaaS)","text":"<p>A cloud computing model that delivers applications over the internet.</p>"},{"location":"resources/glossary/#software-as-a-service-saas","title":"Software as a Service (SaaS)","text":"<p>A software licensing and delivery model in which software is licensed on a subscription basis and is centrally hosted.</p>"},{"location":"resources/glossary/#multi-cloud","title":"Multi-Cloud","text":"<p>Using multiple cloud computing services from different providers.</p>"},{"location":"resources/glossary/#hybrid-cloud","title":"Hybrid Cloud","text":"<p>A computing environment that combines a public cloud and a private cloud.</p>"},{"location":"resources/glossary/#edge-computing","title":"Edge Computing","text":"<p>Distributed computing paradigm that brings computation and data storage closer to the location where it is needed.</p>"},{"location":"resources/glossary/#scaling-and-performance","title":"\ud83d\udcc8 Scaling and Performance","text":""},{"location":"resources/glossary/#horizontal-pod-autoscaler-hpa","title":"Horizontal Pod Autoscaler (HPA)","text":"<p>Automatically scales the number of pods in a deployment, replica set, or stateful set based on observed CPU utilization.</p>"},{"location":"resources/glossary/#vertical-pod-autoscaler-vpa","title":"Vertical Pod Autoscaler (VPA)","text":"<p>Automatically adjusts the resources of pods in a deployment or replica set.</p>"},{"location":"resources/glossary/#cluster-autoscaler","title":"Cluster Autoscaler","text":"<p>Automatically adjusts the size of a Kubernetes cluster based on the resource requests.</p>"},{"location":"resources/glossary/#pod-disruption-budget","title":"Pod Disruption Budget","text":"<p>Ensures that a certain number of replicas of a pod are running during voluntary disruptions.</p>"},{"location":"resources/glossary/#resource-quota","title":"Resource Quota","text":"<p>Limits the amount of resources that can be consumed in a namespace.</p>"},{"location":"resources/glossary/#limit-range","title":"Limit Range","text":"<p>Specifies resource limits and requests for containers in a namespace.</p>"},{"location":"resources/glossary/#quality-of-service-qos","title":"Quality of Service (QoS)","text":"<p>Classes that determine the scheduling and eviction behavior of pods.</p>"},{"location":"resources/glossary/#besteffort","title":"BestEffort","text":"<p>The lowest QoS class for pods that don't specify resource requests or limits.</p>"},{"location":"resources/glossary/#burstable","title":"Burstable","text":"<p>The middle QoS class for pods that specify resource requests but not limits.</p>"},{"location":"resources/glossary/#guaranteed","title":"Guaranteed","text":"<p>The highest QoS class for pods that specify equal resource requests and limits.</p>"},{"location":"resources/glossary/#node-affinity","title":"Node Affinity","text":"<p>Constraints that allow you to schedule pods on specific nodes.</p>"},{"location":"resources/glossary/#pod-affinityanti-affinity","title":"Pod Affinity/Anti-Affinity","text":"<p>Constraints that allow you to schedule pods relative to other pods.</p>"},{"location":"resources/glossary/#tools-and-utilities","title":"\ud83d\udd27 Tools and Utilities","text":""},{"location":"resources/glossary/#kubectl","title":"kubectl","text":"<p>The command-line tool for Kubernetes.</p>"},{"location":"resources/glossary/#minikube","title":"minikube","text":"<p>A tool that makes it easy to run Kubernetes locally.</p>"},{"location":"resources/glossary/#kind","title":"kind","text":"<p>Kubernetes in Docker - a local Kubernetes cluster using Docker container \"nodes\".</p>"},{"location":"resources/glossary/#kubeadm","title":"kubeadm","text":"<p>A tool for bootstrapping a Kubernetes cluster.</p>"},{"location":"resources/glossary/#kops","title":"kops","text":"<p>A production-grade Kubernetes installation, management, and monitoring tool.</p>"},{"location":"resources/glossary/#kubeflow","title":"kubeflow","text":"<p>A machine learning toolkit for Kubernetes.</p>"},{"location":"resources/glossary/#istio","title":"Istio","text":"<p>An open platform to connect, secure, control, and observe microservices.</p>"},{"location":"resources/glossary/#linkerd","title":"Linkerd","text":"<p>A lightweight, service mesh for Kubernetes.</p>"},{"location":"resources/glossary/#calico","title":"Calico","text":"<p>A networking and network security solution for containers and virtual machines.</p>"},{"location":"resources/glossary/#flannel","title":"Flannel","text":"<p>A network fabric for containers, designed to simplify networking across multiple hosts.</p>"},{"location":"resources/glossary/#cilium","title":"Cilium","text":"<p>An open source software for eBPF-based networking, observability, and security.</p>"},{"location":"resources/glossary/#opa-open-policy-agent","title":"OPA (Open Policy Agent)","text":"<p>An open source, general-purpose policy engine.</p>"},{"location":"resources/glossary/#gatekeeper","title":"Gatekeeper","text":"<p>A policy controller for Kubernetes that enables CRD-based admission control.</p>"},{"location":"resources/glossary/#common-commands","title":"\ud83d\udccb Common Commands","text":""},{"location":"resources/glossary/#kubectl-get","title":"kubectl get","text":"<p>Display one or many resources.</p>"},{"location":"resources/glossary/#kubectl-describe","title":"kubectl describe","text":"<p>Show detailed information about a resource.</p>"},{"location":"resources/glossary/#kubectl-create","title":"kubectl create","text":"<p>Create a resource from a file or from stdin.</p>"},{"location":"resources/glossary/#kubectl-apply","title":"kubectl apply","text":"<p>Apply a configuration to a resource.</p>"},{"location":"resources/glossary/#kubectl-delete","title":"kubectl delete","text":"<p>Delete resources by filenames, stdin, resources and names, or by resources and label selector.</p>"},{"location":"resources/glossary/#kubectl-exec","title":"kubectl exec","text":"<p>Execute a command in a container.</p>"},{"location":"resources/glossary/#kubectl-logs","title":"kubectl logs","text":"<p>Print the logs for a container in a pod.</p>"},{"location":"resources/glossary/#kubectl-port-forward","title":"kubectl port-forward","text":"<p>Forward one or more local ports to a pod.</p>"},{"location":"resources/glossary/#kubectl-proxy","title":"kubectl proxy","text":"<p>Run a proxy to the Kubernetes API server.</p>"},{"location":"resources/glossary/#kubectl-scale","title":"kubectl scale","text":"<p>Set a new size for a Deployment, ReplicaSet, Replication Controller, or StatefulSet.</p>"},{"location":"resources/glossary/#kubectl-rollout","title":"kubectl rollout","text":"<p>Manage the rollout of a resource.</p>"},{"location":"resources/glossary/#kubectl-top","title":"kubectl top","text":"<p>Display resource (CPU/memory) usage.</p>"},{"location":"resources/glossary/#kubectl-explain","title":"kubectl explain","text":"<p>Documentation of resources.</p>"},{"location":"resources/glossary/#kubectl-auth","title":"kubectl auth","text":"<p>Inspect authorization.</p>"},{"location":"resources/glossary/#kubectl-config","title":"kubectl config","text":"<p>Modify kubeconfig files.</p>"},{"location":"resources/glossary/#common-acronyms","title":"\ud83c\udfaf Common Acronyms","text":""},{"location":"resources/glossary/#k8s","title":"K8s","text":"<p>Kubernetes (8 letters between K and s).</p>"},{"location":"resources/glossary/#cicd","title":"CI/CD","text":"<p>Continuous Integration/Continuous Deployment.</p>"},{"location":"resources/glossary/#iac","title":"IaC","text":"<p>Infrastructure as Code.</p>"},{"location":"resources/glossary/#sre","title":"SRE","text":"<p>Site Reliability Engineering.</p>"},{"location":"resources/glossary/#sla","title":"SLA","text":"<p>Service Level Agreement.</p>"},{"location":"resources/glossary/#slo","title":"SLO","text":"<p>Service Level Objective.</p>"},{"location":"resources/glossary/#sli","title":"SLI","text":"<p>Service Level Indicator.</p>"},{"location":"resources/glossary/#api","title":"API","text":"<p>Application Programming Interface.</p>"},{"location":"resources/glossary/#cli","title":"CLI","text":"<p>Command Line Interface.</p>"},{"location":"resources/glossary/#gui","title":"GUI","text":"<p>Graphical User Interface.</p>"},{"location":"resources/glossary/#http","title":"HTTP","text":"<p>Hypertext Transfer Protocol.</p>"},{"location":"resources/glossary/#https","title":"HTTPS","text":"<p>Hypertext Transfer Protocol Secure.</p>"},{"location":"resources/glossary/#tcp","title":"TCP","text":"<p>Transmission Control Protocol.</p>"},{"location":"resources/glossary/#udp","title":"UDP","text":"<p>User Datagram Protocol.</p>"},{"location":"resources/glossary/#dns","title":"DNS","text":"<p>Domain Name System.</p>"},{"location":"resources/glossary/#tls","title":"TLS","text":"<p>Transport Layer Security.</p>"},{"location":"resources/glossary/#ssl","title":"SSL","text":"<p>Secure Sockets Layer.</p>"},{"location":"resources/glossary/#json","title":"JSON","text":"<p>JavaScript Object Notation.</p>"},{"location":"resources/glossary/#yaml","title":"YAML","text":"<p>YAML Ain't Markup Language.</p>"},{"location":"resources/glossary/#xml","title":"XML","text":"<p>eXtensible Markup Language.</p>"},{"location":"resources/glossary/#sql","title":"SQL","text":"<p>Structured Query Language.</p>"},{"location":"resources/glossary/#nosql","title":"NoSQL","text":"<p>Not Only SQL.</p>"},{"location":"resources/glossary/#rest","title":"REST","text":"<p>Representational State Transfer.</p>"},{"location":"resources/glossary/#grpc","title":"gRPC","text":"<p>Google Remote Procedure Call.</p>"},{"location":"resources/glossary/#rpc","title":"RPC","text":"<p>Remote Procedure Call.</p>"},{"location":"resources/glossary/#sdk","title":"SDK","text":"<p>Software Development Kit.</p>"},{"location":"resources/glossary/#ide","title":"IDE","text":"<p>Integrated Development Environment.</p>"},{"location":"resources/glossary/#vm","title":"VM","text":"<p>Virtual Machine.</p>"},{"location":"resources/glossary/#vmware","title":"VMware","text":"<p>Virtual Machine Ware.</p>"},{"location":"resources/glossary/#aws","title":"AWS","text":"<p>Amazon Web Services.</p>"},{"location":"resources/glossary/#gcp","title":"GCP","text":"<p>Google Cloud Platform.</p>"},{"location":"resources/glossary/#azure","title":"Azure","text":"<p>Microsoft Azure.</p>"},{"location":"resources/glossary/#vm_1","title":"VM","text":"<p>Virtual Machine.</p>"},{"location":"resources/glossary/#vm_2","title":"VM","text":"<p>Virtual Machine.</p>"},{"location":"resources/glossary/#vm_3","title":"VM","text":"<p>Virtual Machine.</p>"},{"location":"resources/glossary/#common-workflows","title":"\ud83d\udd04 Common Workflows","text":""},{"location":"resources/glossary/#gitops-workflow","title":"GitOps Workflow","text":"<ol> <li>Developer commits code changes to Git repository</li> <li>CI/CD pipeline builds and containerizes the application</li> <li>Container image is pushed to container registry</li> <li>GitOps tool (ArgoCD/Flux) detects changes in Git</li> <li>GitOps tool applies changes to Kubernetes cluster</li> <li>Deployment is rolled out with zero downtime</li> <li>Monitoring and alerting track deployment health</li> </ol>"},{"location":"resources/glossary/#canary-deployment-workflow","title":"Canary Deployment Workflow","text":"<ol> <li>Deploy new version to canary environment</li> <li>Route small percentage of traffic to canary</li> <li>Monitor canary performance and metrics</li> <li>If canary performs well, gradually increase traffic</li> <li>If canary has issues, rollback automatically</li> <li>Once canary receives 100% traffic, remove old version</li> </ol>"},{"location":"resources/glossary/#blue-green-deployment-workflow","title":"Blue-Green Deployment Workflow","text":"<ol> <li>Deploy new version to green environment</li> <li>Run both blue (current) and green (new) versions</li> <li>Route all traffic to green environment</li> <li>Monitor green environment for issues</li> <li>If issues occur, route traffic back to blue</li> <li>Once green is stable, decommission blue environment</li> </ol>"},{"location":"resources/glossary/#troubleshooting-workflow","title":"Troubleshooting Workflow","text":"<ol> <li>Identify the problem (logs, metrics, user reports)</li> <li>Gather information (kubectl describe, kubectl logs)</li> <li>Form a hypothesis about the root cause</li> <li>Test the hypothesis (make changes, observe results)</li> <li>Fix the problem (apply changes, restart services)</li> <li>Verify the fix (check logs, metrics, user feedback)</li> <li>Document the solution and prevention measures</li> </ol>"},{"location":"resources/glossary/#additional-resources","title":"\ud83d\udcda Additional Resources","text":""},{"location":"resources/glossary/#official-documentation","title":"Official Documentation","text":"<ul> <li>Kubernetes Documentation</li> <li>Kubernetes Glossary</li> <li>Kubernetes API Reference</li> </ul>"},{"location":"resources/glossary/#community-resources","title":"Community Resources","text":"<ul> <li>Kubernetes Slack</li> <li>Kubernetes Forums</li> <li>Kubernetes GitHub</li> </ul>"},{"location":"resources/glossary/#learning-resources","title":"Learning Resources","text":"<ul> <li>Kubernetes Basics</li> <li>Kubernetes Certified Administrator (CKA)</li> <li>Kubernetes Certified Application Developer (CKAD)</li> </ul>"},{"location":"resources/glossary/#tools-and-utilities_1","title":"Tools and Utilities","text":"<ul> <li>k9s - Terminal UI for Kubernetes</li> <li>Lens - Kubernetes IDE</li> <li>stern - Multi container log tailing</li> <li>kubectx - Switch between contexts</li> <li>kubectl neat - Clean up Kubernetes YAML files</li> </ul> <p>This glossary provides a comprehensive reference for Kubernetes terminology and concepts. It covers everything from basic concepts to advanced topics, making it useful for beginners and experienced users alike.</p>"},{"location":"resources/troubleshooting/","title":"\ud83d\udd27 Kubernetes Troubleshooting Guide","text":"<p>A comprehensive guide to diagnosing and resolving common Kubernetes issues.</p>"},{"location":"resources/troubleshooting/#table-of-contents","title":"\ud83d\udccb Table of Contents","text":"<ul> <li>Common Pod Issues</li> <li>Networking Problems</li> <li>Storage Issues</li> <li>Performance Problems</li> <li>Security Issues</li> <li>Cluster Problems</li> <li>Debugging Tools</li> <li>Common Error Codes</li> </ul>"},{"location":"resources/troubleshooting/#common-pod-issues","title":"\ud83d\udea8 Common Pod Issues","text":""},{"location":"resources/troubleshooting/#1-pod-crashloopbackoff","title":"1. Pod CrashLoopBackOff","text":"<p>Symptoms: Pod keeps restarting with CrashLoopBackOff status.</p> <p>Diagnosis: <pre><code># Check pod status\nkubectl get pods\n\n# View pod events\nkubectl describe pod &lt;pod-name&gt;\n\n# Check pod logs\nkubectl logs &lt;pod-name&gt; --previous\n\n# Check container logs\nkubectl logs &lt;pod-name&gt; -c &lt;container-name&gt;\n</code></pre></p> <p>Solutions: - Check application logs for errors - Verify resource limits are sufficient - Check image availability and permissions - Verify environment variables and configuration</p> <p>Example Fix: <pre><code># Check if image can be pulled\nkubectl describe pod &lt;pod-name&gt; | grep -A 5 \"Events\"\n\n# Check resource usage\nkubectl top pod &lt;pod-name&gt;\n</code></pre></p>"},{"location":"resources/troubleshooting/#2-pod-pending","title":"2. Pod Pending","text":"<p>Symptoms: Pod stays in Pending state.</p> <p>Diagnosis: <pre><code># Check pod events\nkubectl describe pod &lt;pod-name&gt;\n\n# Check node resources\nkubectl describe nodes\n\n# Check taints on nodes\nkubectl describe nodes | grep Taints\n</code></pre></p> <p>Solutions: - Check if nodes have sufficient resources - Remove taints from nodes if needed - Check if PVC can be bound - Verify node selectors and affinity rules</p> <p>Example Fix: <pre><code># Remove taint from node\nkubectl taint nodes &lt;node-name&gt; &lt;taint-key&gt;:NoSchedule-\n\n# Check PVC status\nkubectl get pvc\n</code></pre></p>"},{"location":"resources/troubleshooting/#3-imagepullbackoff","title":"3. ImagePullBackOff","text":"<p>Symptoms: Pod can't pull container image.</p> <p>Diagnosis: <pre><code># Check image pull events\nkubectl describe pod &lt;pod-name&gt; | grep -A 10 \"Events\"\n\n# Check image registry access\nkubectl get secret &lt;image-pull-secret&gt; -o yaml\n</code></pre></p> <p>Solutions: - Verify image name and tag - Check registry credentials - Ensure registry is accessible - Check image size and pull limits</p> <p>Example Fix: <pre><code># Test image pull manually\ndocker pull &lt;image-name&gt;\n\n# Update image pull secret\nkubectl create secret docker-registry regcred \\\n  --docker-server=&lt;registry-url&gt; \\\n  --docker-username=&lt;username&gt; \\\n  --docker-password=&lt;password&gt;\n</code></pre></p>"},{"location":"resources/troubleshooting/#4-containercreating","title":"4. ContainerCreating","text":"<p>Symptoms: Pod stuck in ContainerCreating state.</p> <p>Diagnosis: <pre><code># Check pod events\nkubectl describe pod &lt;pod-name&gt;\n\n# Check node status\nkubectl get nodes -o wide\n\n# Check kubelet logs\njournalctl -u kubelet -f\n</code></pre></p> <p>Solutions: - Check kubelet status on nodes - Verify container runtime (Docker/Containerd) - Check disk space on nodes - Verify kernel parameters</p> <p>Example Fix: <pre><code># Restart kubelet\nsystemctl restart kubelet\n\n# Check disk space\ndf -h\n</code></pre></p>"},{"location":"resources/troubleshooting/#networking-problems","title":"\ud83c\udf10 Networking Problems","text":""},{"location":"resources/troubleshooting/#1-service-not-accessible","title":"1. Service Not Accessible","text":"<p>Symptoms: Service endpoints are not reachable.</p> <p>Diagnosis: <pre><code># Check service endpoints\nkubectl get endpoints &lt;service-name&gt;\n\n# Check service configuration\nkubectl describe service &lt;service-name&gt;\n\n# Test connectivity\nkubectl exec -it &lt;pod-name&gt; -- wget -qO- &lt;service-name&gt;\n</code></pre></p> <p>Solutions: - Verify service selector matches pod labels - Check service type and port configuration - Verify network policies - Check DNS resolution</p> <p>Example Fix: <pre><code># Test DNS resolution\nkubectl exec -it &lt;pod-name&gt; -- nslookup &lt;service-name&gt;\n\n# Check network policies\nkubectl get networkpolicy\n</code></pre></p>"},{"location":"resources/troubleshooting/#2-ingress-not-working","title":"2. Ingress Not Working","text":"<p>Symptoms: Ingress doesn't route traffic to services.</p> <p>Diagnosis: <pre><code># Check ingress status\nkubectl get ingress &lt;ingress-name&gt;\n\n# Check ingress controller logs\nkubectl logs -n ingress-nginx &lt;ingress-controller-pod&gt;\n\n# Test connectivity\ncurl -H \"Host: &lt;domain&gt;\" http://&lt;ingress-ip&gt;\n</code></pre></p> <p>Solutions: - Verify ingress annotations - Check TLS certificate configuration - Ensure ingress controller is running - Verify domain DNS configuration</p> <p>Example Fix: <pre><code># Check ingress controller status\nkubectl get pods -n ingress-nginx\n\n# Test ingress configuration\nkubectl describe ingress &lt;ingress-name&gt;\n</code></pre></p>"},{"location":"resources/troubleshooting/#3-network-policy-blocking-traffic","title":"3. Network Policy Blocking Traffic","text":"<p>Symptoms: Pods can't communicate with each other.</p> <p>Diagnosis: <pre><code># Check network policies\nkubectl get networkpolicy -o wide\n\n# Test connectivity between pods\nkubectl exec -it &lt;source-pod&gt; -- ping &lt;target-pod&gt;\n\n# Check pod labels\nkubectl get pods --show-labels\n</code></pre></p> <p>Solutions: - Review network policy rules - Verify pod labels match policy selectors - Check ingress/egress rules - Test policy changes incrementally</p> <p>Example Fix: <pre><code># Temporarily disable network policy\nkubectl delete networkpolicy &lt;policy-name&gt;\n\n# Test connectivity without policy\nkubectl exec -it &lt;source-pod&gt; -- wget -qO- &lt;target-service&gt;\n</code></pre></p>"},{"location":"resources/troubleshooting/#storage-issues","title":"\ud83d\udcbe Storage Issues","text":""},{"location":"resources/troubleshooting/#1-pvc-bound-failed","title":"1. PVC Bound Failed","text":"<p>Symptoms: PVC stays in Pending state.</p> <p>Diagnosis: <pre><code># Check PVC status\nkubectl get pvc\n\n# Check PV status\nkubectl get pv\n\n# Check storage class\nkubectl get storageclass\n</code></pre></p> <p>Solutions: - Verify storage class configuration - Check available PVs - Ensure storage backend is accessible - Check PVC resource requests</p> <p>Example Fix: <pre><code># Check storage class provisioner\nkubectl get storageclass -o yaml\n\n# Create PV manually if needed\nkubectl create -f pv.yaml\n</code></pre></p>"},{"location":"resources/troubleshooting/#2-readwriteonce-vs-readonlymany","title":"2. ReadWriteOnce vs ReadOnlyMany","text":"<p>Symptoms: Can't write to mounted volume.</p> <p>Diagnosis: <pre><code># Check PVC access mode\nkubectl get pvc &lt;pvc-name&gt; -o yaml\n\n# Check PV access mode\nkubectl get pv &lt;pv-name&gt; -o yaml\n</code></pre></p> <p>Solutions: - Use correct access mode for workload - Create new PVC with appropriate mode - Use ReadWriteMany for shared storage</p> <p>Example Fix: <pre><code># Create new PVC with ReadWriteOnce\nkubectl create -f new-pvc.yaml\n</code></pre></p>"},{"location":"resources/troubleshooting/#3-volume-mount-issues","title":"3. Volume Mount Issues","text":"<p>Symptoms: Container can't access mounted volume.</p> <p>Diagnosis: <pre><code># Check pod events\nkubectl describe pod &lt;pod-name&gt;\n\n# Check volume mount configuration\nkubectl get pod &lt;pod-name&gt; -o yaml | grep -A 10 volumeMounts\n</code></pre></p> <p>Solutions: - Verify mount path exists - Check permissions on volume - Ensure volume is properly formatted - Test volume access manually</p> <p>Example Fix: <pre><code># Check volume permissions\nkubectl exec -it &lt;pod-name&gt; -- ls -la /mount/path\n\n# Fix permissions if needed\nkubectl exec -it &lt;pod-name&gt; -- chmod 755 /mount/path\n</code></pre></p>"},{"location":"resources/troubleshooting/#performance-problems","title":"\u26a1 Performance Problems","text":""},{"location":"resources/troubleshooting/#1-high-cpu-usage","title":"1. High CPU Usage","text":"<p>Symptoms: Pods or nodes have high CPU usage.</p> <p>Diagnosis: <pre><code># Check resource usage\nkubectl top pods\nkubectl top nodes\n\n# Check pod resource limits\nkubectl get pod &lt;pod-name&gt; -o yaml | grep -A 5 resources\n\n# Check container metrics\nkubectl top pod &lt;pod-name&gt; --containers\n</code></pre></p> <p>Solutions: - Increase resource limits - Optimize application code - Scale horizontally - Use vertical pod autoscaler</p> <p>Example Fix: <pre><code># Update resource limits\nkubectl set resources deployment/&lt;deployment-name&gt; \\\n  --limits=cpu=1000m,memory=2Gi \\\n  --requests=cpu=500m,memory=1Gi\n</code></pre></p>"},{"location":"resources/troubleshooting/#2-memory-issues","title":"2. Memory Issues","text":"<p>Symptoms: Pods are OOMKilled or have high memory usage.</p> <p>Diagnosis: <pre><code># Check memory usage\nkubectl top pods --sort-by=memory\n\n# Check OOM events\nkubectl describe pod &lt;pod-name&gt; | grep -i \"oom\"\n\n# Check memory limits\nkubectl get pod &lt;pod-name&gt; -o yaml | grep -A 5 resources\n</code></pre></p> <p>Solutions: - Increase memory limits - Optimize memory usage - Use memory-efficient images - Implement proper caching</p> <p>Example Fix: <pre><code># Update memory limits\nkubectl set resources deployment/&lt;deployment-name&gt; \\\n  --limits=memory=2Gi \\\n  --requests=memory=1Gi\n</code></pre></p>"},{"location":"resources/troubleshooting/#3-slow-response-times","title":"3. Slow Response Times","text":"<p>Symptoms: Applications are responding slowly.</p> <p>Diagnosis: <pre><code># Check network latency\nkubectl exec -it &lt;pod-name&gt; -- ping &lt;target-service&gt;\n\n# Check database connectivity\nkubectl exec -it &lt;pod-name&gt; -- mysql -h &lt;db-host&gt; -u &lt;user&gt; -p\n\n# Check application logs\nkubectl logs &lt;pod-name&gt; --tail=100\n</code></pre></p> <p>Solutions: - Optimize database queries - Use caching strategies - Scale horizontally - Check network configuration</p> <p>Example Fix: <pre><code># Check database performance\nkubectl exec -it &lt;pod-name&gt; -- mysql -e \"SHOW PROCESSLIST;\"\n</code></pre></p>"},{"location":"resources/troubleshooting/#security-issues","title":"\ud83d\udd12 Security Issues","text":""},{"location":"resources/troubleshooting/#1-rbac-problems","title":"1. RBAC Problems","text":"<p>Symptoms: Service accounts can't access resources.</p> <p>Diagnosis: <pre><code># Check service account\nkubectl get serviceaccount &lt;sa-name&gt;\n\n# Check role bindings\nkubectl get rolebinding &lt;rb-name&gt;\n\n# Test permissions\nkubectl auth can-i create pods --as=system:serviceaccount:&lt;namespace&gt;:&lt;sa-name&gt;\n</code></pre></p> <p>Solutions: - Verify role permissions - Check role bindings - Ensure service account exists - Test permissions incrementally</p> <p>Example Fix: <pre><code># Create role binding\nkubectl create rolebinding &lt;rb-name&gt; \\\n  --role=&lt;role-name&gt; \\\n  --serviceaccount=&lt;namespace&gt;:&lt;sa-name&gt;\n</code></pre></p>"},{"location":"resources/troubleshooting/#2-image-security-issues","title":"2. Image Security Issues","text":"<p>Symptoms: Images have vulnerabilities.</p> <p>Diagnosis: <pre><code># Scan images for vulnerabilities\ntrivy image &lt;image-name&gt;\n\n# Check image signatures\ncosign verify &lt;image-name&gt;\n\n# Check image pull policy\nkubectl get pod &lt;pod-name&gt; -o yaml | grep imagePullPolicy\n</code></pre></p> <p>Solutions: - Use base images with fewer vulnerabilities - Implement image scanning - Use signed images - Update regularly</p> <p>Example Fix\uff1a <pre><code># Update image to latest secure version\nkubectl set image deployment/&lt;deployment-name&gt; \\\n  &lt;container-name&gt;=&lt;new-image&gt;:&lt;tag&gt;\n</code></pre></p>"},{"location":"resources/troubleshooting/#3-network-policy-issues","title":"3. Network Policy Issues","text":"<p>Symptoms: Pods can't communicate due to security policies.</p> <p>Diagnosis: <pre><code># Check network policies\nkubectl get networkpolicy\n\n# Test connectivity\nkubectl exec -it &lt;source-pod&gt; -- wget -qO- &lt;target-service&gt;\n\n# Check pod labels\nkubectl get pods --show-labels\n</code></pre></p> <p>Solutions: - Review network policy rules - Verify pod labels - Test policy changes - Use least privilege principle</p> <p>Example Fix: <pre><code># Create permissive network policy for testing\nkubectl create -f permissive-netpol.yaml\n</code></pre></p>"},{"location":"resources/troubleshooting/#cluster-problems","title":"\ud83c\udfd7\ufe0f Cluster Problems","text":""},{"location":"resources/troubleshooting/#1-node-not-ready","title":"1. Node Not Ready","text":"<p>Symptoms: Node shows NotReady status.</p> <p>Diagnosis: <pre><code># Check node status\nkubectl get nodes\n\n# Check node conditions\nkubectl describe node &lt;node-name&gt;\n\n# Check kubelet status\nsystemctl status kubelet\n</code></pre></p> <p>Solutions: - Restart kubelet service - Check container runtime - Verify network configuration - Check disk space</p> <p>Example Fix: <pre><code># Restart kubelet\nsystemctl restart kubelet\n\n# Check container runtime\nsystemctl status containerd\n</code></pre></p>"},{"location":"resources/troubleshooting/#2-api-server-issues","title":"2. API Server Issues","text":"<p>Symptoms: Can't access Kubernetes API.</p> <p>Diagnosis: <pre><code># Check API server status\nkubectl cluster-info\n\n# Check API server logs\nkubectl logs -n kube-system &lt;api-server-pod&gt;\n\n# Test API connectivity\ncurl -k https://&lt;api-server-ip&gt;:6443/healthz\n</code></pre></p> <p>Solutions: - Check API server resources - Verify certificate validity - Check network connectivity - Restart API server if needed</p> <p>Example Fix: <pre><code># Check API server resources\nkubectl top pods -n kube-system\n</code></pre></p>"},{"location":"resources/troubleshooting/#3-etcd-issues","title":"3. etcd Issues","text":"<p>Symptoms: Cluster state is inconsistent.</p> <p>Diagnosis: <pre><code># Check etcd status\nkubectl get endpoints -n kube-system kube-etcd\n\n# Check etcd logs\nkubectl logs -n kube-system &lt;etcd-pod&gt;\n\n# Check cluster health\nkubectl get componentstatuses\n</code></pre></p> <p>Solutions: - Check etcd disk space - Verify etcd cluster members - Backup etcd data - Restore from backup if needed</p> <p>Example Fix: <pre><code># Check etcd cluster members\nETCDCTL_API=3 etcdctl --endpoints=&lt;etcd-endpoint&gt; member list\n</code></pre></p>"},{"location":"resources/troubleshooting/#debugging-tools","title":"\ud83d\udd27 Debugging Tools","text":""},{"location":"resources/troubleshooting/#1-kubectl-debug-plugin","title":"1. kubectl Debug Plugin","text":"<pre><code># Create debug container\nkubectl debug -it &lt;pod-name&gt; --image=busybox --target=&lt;container-name&gt;\n\n# Create debug pod\nkubectl debug -it &lt;pod-name&gt; --image=busybox --share-processes\n</code></pre>"},{"location":"resources/troubleshooting/#2-lens-ide","title":"2. Lens IDE","text":"<pre><code># Use Lens for visual debugging\n# Download from: https://k8slens.dev/\n# Features:\n# - Visual pod status\n# - Real-time logs\n# - Resource monitoring\n# - Network topology\n</code></pre>"},{"location":"resources/troubleshooting/#3-k9s","title":"3. k9s","text":"<pre><code># Interactive Kubernetes CLI\nk9s\n\n# Common k9s commands:\n# - :pods - View pods\n# - :deploy - View deployments\n# - :logs - View logs\n# - :exec - Execute command\n# - :describe - Describe resource\n</code></pre>"},{"location":"resources/troubleshooting/#4-stern","title":"4. stern","text":"<pre><code># Multi-container log tailing\nstern &lt;pod-name&gt; -n &lt;namespace&gt;\n\n# Filter by container\nstern &lt;pod-name&gt; -c &lt;container-name&gt;\n\n# Filter by namespace\nstern &lt;pod-name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"resources/troubleshooting/#common-error-codes","title":"\ud83d\udea8 Common Error Codes","text":""},{"location":"resources/troubleshooting/#1-error-from-server-forbidden","title":"1. Error from server (Forbidden)","text":"<p>Cause: Insufficient permissions.</p> <p>Solution: <pre><code># Check current context\nkubectl config current-context\n\n# Check permissions\nkubectl auth can-i create deployments\n\n# Create role binding if needed\nkubectl create clusterrolebinding cluster-admin-binding \\\n  --clusterrole=cluster-admin \\\n  --user=&lt;username&gt;\n</code></pre></p>"},{"location":"resources/troubleshooting/#2-error-from-server-notfound","title":"2. Error from server (NotFound)","text":"<p>Cause: Resource doesn't exist.</p> <p>Solution: <pre><code># Check if resource exists\nkubectl get &lt;resource-type&gt; &lt;resource-name&gt;\n\n# Check namespace\nkubectl config current-context\n\n# Create resource if needed\nkubectl create -f &lt;resource-file&gt;\n</code></pre></p>"},{"location":"resources/troubleshooting/#3-error-from-server-alreadyexists","title":"3. Error from server (AlreadyExists)","text":"<p>Cause: Resource already exists.</p> <p>Solution: <pre><code># Check existing resource\nkubectl get &lt;resource-type&gt; &lt;resource-name&gt;\n\n# Apply changes instead of create\nkubectl apply -f &lt;resource-file&gt;\n\n# Delete and recreate if needed\nkubectl delete &lt;resource-type&gt; &lt;resource-name&gt;\nkubectl create -f &lt;resource-file&gt;\n</code></pre></p>"},{"location":"resources/troubleshooting/#4-error-from-server-timeout","title":"4. Error from server (Timeout)","text":"<p>Cause: Operation took too long.</p> <p>Solution: <pre><code># Increase timeout\nkubectl get &lt;resource-type&gt; --watch --timeout=60s\n\n# Check resource status\nkubectl describe &lt;resource-type&gt; &lt;resource-name&gt;\n\n# Check cluster health\nkubectl get nodes\n</code></pre></p>"},{"location":"resources/troubleshooting/#monitoring-and-alerting","title":"\ud83d\udcca Monitoring and Alerting","text":""},{"location":"resources/troubleshooting/#1-prometheus-alerts","title":"1. Prometheus Alerts","text":"<pre><code># Example alert for high CPU usage\ngroups:\n- name: kubernetes-apps\n  rules:\n  - alert: HighCPUUsage\n    expr: sum(rate(container_cpu_usage_seconds_total[5m])) by (pod) &gt; 0.8\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"High CPU usage on {{ $labels.pod }}\"\n      description: \"Pod {{ $labels.pod }} has high CPU usage\"\n</code></pre>"},{"location":"resources/troubleshooting/#2-grafana-dashboards","title":"2. Grafana Dashboards","text":"<pre><code># Import pre-built dashboards\nkubectl apply -f https://raw.githubusercontent.com/kubernetes-monitoring/kubernetes-mixin/master/dashboards/kubernetes.json\n</code></pre>"},{"location":"resources/troubleshooting/#3-logging-setup","title":"3. Logging Setup","text":"<pre><code># Fluentd configuration for logging\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: fluentd-config\ndata:\n  fluent.conf: |\n    &lt;source&gt;\n      @type tail\n      path /var/log/containers/*.log\n      pos_file /var/log/fluentd-containers.log.pos\n      tag kubernetes.*\n      format json\n      time_format %Y-%m-%dT%H:%M:%S.%NZ\n    &lt;/source&gt;\n</code></pre>"},{"location":"resources/troubleshooting/#recovery-procedures","title":"\ud83d\udd04 Recovery Procedures","text":""},{"location":"resources/troubleshooting/#1-pod-recovery","title":"1. Pod Recovery","text":"<pre><code># Restart deployment\nkubectl rollout restart deployment/&lt;deployment-name&gt;\n\n# Scale to zero and back\nkubectl scale deployment/&lt;deployment-name&gt; --replicas=0\nkubectl scale deployment/&lt;deployment-name&gt; --replicas=3\n\n# Delete and recreate pod\nkubectl delete pod &lt;pod-name&gt;\n</code></pre>"},{"location":"resources/troubleshooting/#2-node-recovery","title":"2. Node Recovery","text":"<pre><code># Drain node\nkubectl drain &lt;node-name&gt; --ignore-daemonsets --delete-emptydir-data\n\n# Cordon node\nkubectl cordon &lt;node-name&gt;\n\n# Restart node\nsystemctl restart kubelet\n</code></pre>"},{"location":"resources/troubleshooting/#3-cluster-recovery","title":"3. Cluster Recovery","text":"<pre><code># Check cluster status\nkubectl get componentstatuses\n\n# Check etcd health\nETCDCTL_API=3 etcdctl --endpoints=&lt;etcd-endpoint&gt; endpoint health\n\n# Restore from backup if needed\nvelero restore create restore-1 --from-backup &lt;backup-name&gt;\n</code></pre>"},{"location":"resources/troubleshooting/#best-practices-for-troubleshooting","title":"\ud83c\udfaf Best Practices for Troubleshooting","text":"<ol> <li>Start with the basics: Check pod status, logs, and events</li> <li>Use the process of elimination: Isolate variables one by one</li> <li>Document everything: Keep track of what you've tried</li> <li>Test incrementally: Make small changes and verify</li> <li>Use debugging tools: Leverage k9s, stern, and Lens</li> <li>Monitor continuously: Set up alerts for common issues</li> <li>Learn from incidents: Post-mortem and improve</li> <li>Stay updated: Keep up with Kubernetes best practices</li> </ol>"},{"location":"resources/troubleshooting/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>Kubernetes Troubleshooting Documentation</li> <li>Kubernetes Debugging Guide</li> <li>Kubernetes Troubleshooting Checklist</li> <li>Kubernetes Best Practices</li> <li>Kubernetes Security Best Practices</li> </ul> <p>Remember to always test changes in a non-production environment first and have proper backup procedures in place.</p>"}]}