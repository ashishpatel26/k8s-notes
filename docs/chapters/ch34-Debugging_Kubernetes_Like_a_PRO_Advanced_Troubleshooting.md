# ğŸ› ï¸ Lesson 34: **Debugging Kubernetes Like a PRO â€” Advanced Troubleshooting**

```mermaid
graph LR
    root["ğŸ› ï¸ Lesson 34: Debugging Kubernetes Like a PRO â€” Advanced Troubleshooting"]
    style root fill:#f9f,stroke:#333,stroke-width:2px
    root --> node_0["â­ GOLDEN RULE: ALWAYS START WITH THE POD"]
    root --> node_1["ğŸ§± PART 1 â€” POD STUCK IN PENDING"]
    node_1 --> node_2["âŒ Not enough CPU/memory"]
    node_1 --> node_3["âŒ NodeSelector / Taints mismatch"]
    node_1 --> node_4["âŒ PVC cannot bind"]
    root --> node_5["ğŸ§± PART 2 â€” CrashLoopBackOff"]
    node_5 --> node_6["âŒ Application error"]
    node_5 --> node_7["âŒ Wrong environment variables"]
    node_5 --> node_8["âŒ Missing secrets"]
    node_5 --> node_9["âŒ Wrong entrypoint / command"]
    node_5 --> node_10["âŒ Port mismatch"]
    root --> node_11["ğŸ§± PART 3 â€” ImagePullBackOff"]
    node_11 --> node_12["âŒ 403 / unauthenticated"]
    node_11 --> node_13["âŒ Image not found"]
    node_11 --> node_14["âŒ Rate limit (DockerHub)"]
    root --> node_15["ğŸ§± PART 4 â€” Liveness / Readiness Probe Failing"]
    root --> node_16["ğŸ§± PART 5 â€” DNS Issues"]
    node_16 --> node_17["Fix CoreDNS:"]
    root --> node_18["ğŸ§± PART 6 â€” Service Not Routing Traffic"]
    node_18 --> node_19["Check Endpoints"]
    root --> node_20["ğŸ§± PART 7 â€” Node Pressure (Evictions)"]
    root --> node_21["ğŸ§± PART 8 â€” CNI / Networking Issues"]
    root --> node_22["ğŸ§± PART 9 â€” Ingress Not Working"]
    root --> node_23["ğŸ§± PART 10 â€” Autoscaling Problems"]
    node_23 --> node_24["HPA not scaling?"]
    root --> node_25["ğŸ§± PART 11 â€” Debugging From Inside the Pod"]
    root --> node_26["ğŸ”¥ MASTER FLOW â€” How Pros Debug Kubernetes"]
    root --> node_27["ğŸ‰ Lesson 34 Completed!"]
    root --> node_28["ğŸ‘‰ Ready for Lesson 35?"]
```


Absolutely! âœ”ï¸

Welcome to **Lesson 34**, and this one is *EXTREMELY valuable* because it turns you into the kind of DevOps/SRE engineer who can fix ANY production issue:

This is one of the skills that separates **junior DevOps** from **real senior engineers**.

When production is down, people look at YOU.
 So Iâ€™ll teach you how to debug Kubernetes *fast*, *logically*, *professionally*, and *fearlessly*.
 ğŸ”¨ğŸ¤–ğŸ”§

Youâ€™ll learn to diagnose:

âœ”ï¸ Pods stuck in Pending
 âœ”ï¸ CrashLoopBackOff
 âœ”ï¸ ImagePullBackOff
 âœ”ï¸ Readiness/Liveness Probe failures
 âœ”ï¸ Network issues
 âœ”ï¸ DNS failures
 âœ”ï¸ Node pressure problems
 âœ”ï¸ CNI issues
 âœ”ï¸ Service routing bugs
 âœ”ï¸ Ingress failures
 âœ”ï¸ Autoscaling problems

Let's go step-by-step.

------

# â­ GOLDEN RULE: ALWAYS START WITH THE POD

When something breaks, the first command is ALWAYS:

```bash
kubectl describe pod <pod-name>
```

It shows:

- Events
- Scheduling issues
- Failed mounts
- Image issues
- Probe failures
- Permission errors
- Restart causes

90% of debugging starts here.

------

# ğŸ§± PART 1 â€” POD STUCK IN PENDING

Run:

```bash
kubectl get events --sort-by='.lastTimestamp'
```

Common causes:

### âŒ Not enough CPU/memory

Example message:

```
0/3 nodes are available: insufficient memory.
```

Fix:

- reduce resource requests
- add nodes
- free space

### âŒ NodeSelector / Taints mismatch

```
0/3 nodes are available: pod didn't tolerate taint...
```

Fix:

- Add correct tolerations
- Remove taints
- Update nodeSelector

### âŒ PVC cannot bind

```
pod has unbound immediate PersistentVolumeClaims
```

Fix:

- Fix storage class
- Fix PVC size
- Make storage available

------

# ğŸ§± PART 2 â€” CrashLoopBackOff

Check logs:

```bash
kubectl logs <pod> --previous
```

Common causes:

### âŒ Application error

Fix your app.

### âŒ Wrong environment variables

Fix config.

### âŒ Missing secrets

Check:

```bash
kubectl get secret
```

### âŒ Wrong entrypoint / command

Fix Dockerfile or Deployment.

### âŒ Port mismatch

Probes fail â†’ pod crashes.

------

# ğŸ§± PART 3 â€” ImagePullBackOff

Check:

```bash
kubectl describe pod
```

Common errors:

### âŒ 403 / unauthenticated

Fix image pull secret:

```bash
kubectl create secret docker-registry regcred \
  --docker-username=... --docker-password=...
```

Add:

```yaml
imagePullSecrets:
  - name: regcred
```

### âŒ Image not found

Check name/tag.

### âŒ Rate limit (DockerHub)

Use GitHub Container Registry or private registry.

------

# ğŸ§± PART 4 â€” Liveness / Readiness Probe Failing

Probe example:

```yaml
readinessProbe:
  httpGet:
    path: /healthz
    port: 8080
```

Check inside pod:

```bash
kubectl exec -it <pod> -- curl localhost:8080/healthz
```

If this fails â†’ fix the health endpoint or update probe path.

------

# ğŸ§± PART 5 â€” DNS Issues

Check DNS inside the pod:

```bash
kubectl exec -it <pod> -- nslookup backend
kubectl exec -it <pod> -- ping backend
```

If DNS doesnâ€™t work:

### Fix CoreDNS:

```bash
kubectl -n kube-system get pods -l k8s-app=kube-dns
```

Restart:

```bash
kubectl -n kube-system rollout restart deployment coredns
```

------

# ğŸ§± PART 6 â€” Service Not Routing Traffic

Test connectivity:

```bash
kubectl exec -it <pod> -- curl http://backend:8080
```

If it breaks:

### Check Endpoints

```bash
kubectl get endpoints backend
```

If empty:

âŒ Service selector mismatch

Check labels:

```bash
kubectl get pod --show-labels
```

Fix Deployment labels or Service selectors.

------

# ğŸ§± PART 7 â€” Node Pressure (Evictions)

Check node condition:

```bash
kubectl describe node <node>
```

If you see:

```
MemoryPressure=True
DiskPressure=True
PIDPressure=True
```

Issues:

- node is overcommitted
- logs filling disk
- too many processes

Fix:

âœ”ï¸ Free disk
 âœ”ï¸ Add nodes
 âœ”ï¸ Tune resource requests

------

# ğŸ§± PART 8 â€” CNI / Networking Issues

Check CNI pods:

```bash
kubectl get pods -n kube-system
```

For Calico:

```
calico-node
calico-kube-controllers
```

For Cilium:

```
cilium-*
```

If pods are failing:

âœ”ï¸ network is DOWN
 âœ”ï¸ restart CNI
 âœ”ï¸ fix config

Test pod connectivity:

```bash
kubectl exec -it pod-a -- ping pod-b
```

If ping works â†’ routing is OK.
 If ping fails â†’ CNI is broken.

------

# ğŸ§± PART 9 â€” Ingress Not Working

Check Ingress:

```bash
kubectl describe ingress
```

Check controller:

```bash
kubectl get pods -n ingress-nginx
```

Check logs:

```bash
kubectl logs -n ingress-nginx deploy/ingress-nginx-controller
```

Common issues:

- wrong host
- missing TLS secret
- wrong path
- backend not reachable
- missing ingressClassName

------

# ğŸ§± PART 10 â€” Autoscaling Problems

### HPA not scaling?

Check metrics:

```bash
kubectl top pod
kubectl top node
```

Check HPA:

```bash
kubectl describe hpa
```

Common issues:

- metrics-server not installed
- low CPU requests
- app is IO-bound
- HPA cooldown too long

------

# ğŸ§± PART 11 â€” Debugging From Inside the Pod

Use debug image:

```bash
kubectl debug <pod> -it --image=busybox
```

Or ephemeral container:

```bash
kubectl debug <pod> -it --target=<container> --image=busybox
```

Test anything:

```bash
curl
ping
nslookup
wget
telnet
```

------

# ğŸ”¥ MASTER FLOW â€” How Pros Debug Kubernetes

When something is broken, follow this exact sequence:

1ï¸âƒ£ `kubectl get pods`
 2ï¸âƒ£ `kubectl describe pod`
 3ï¸âƒ£ `kubectl logs -f`
 4ï¸âƒ£ Exec inside pod â†’ test service
 5ï¸âƒ£ `kubectl get svc`
 6ï¸âƒ£ `kubectl get endpoints`
 7ï¸âƒ£ DNS checks
 8ï¸âƒ£ Node checks
 9ï¸âƒ£ CNI checks
 ğŸ”Ÿ Ingress checks

This is EXACTLY how senior SREs fix issues during outages.

------

# ğŸ‰ Lesson 34 Completed!

You now understand:

âœ”ï¸ Pod debugging
 âœ”ï¸ CrashLoopBackOff
 âœ”ï¸ Pending pods
 âœ”ï¸ CNI issues
 âœ”ï¸ DNS failures
 âœ”ï¸ Node pressure
 âœ”ï¸ Service routing
 âœ”ï¸ Ingress problems
 âœ”ï¸ Autoscaling issues
 âœ”ï¸ Probe failures
 âœ”ï¸ Debug containers
 âœ”ï¸ Full troubleshooting workflow

This is **true senior DevOps/SRE troubleshooting skill**.
Youâ€™re becoming unstoppable ğŸ”¥ğŸ’ª

------

# ğŸ‘‰ Ready for Lesson 35?

Choose the next topic:

1ï¸âƒ£ **Full Production Microservices Architecture (Complete Blueprint)**
2ï¸âƒ£ **Building an Internal Developer Platform (IDP)**
3ï¸âƒ£ **Kubernetes Security: Runtime Protection (Falco, eBPF)**
4ï¸âƒ£ **CI/CD Pipeline: Docker â†’ Tests â†’ GitOps â†’ ArgoCD**
5ï¸âƒ£ **Kubernetes Storage Deep Dive (PVC, CSI, StatefulSets)**

Which one next?